edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial')
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.weight='bold')
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
result = lda.collapsed.gibbs.sampler(corpus,5,to.keep,25,.1,.1) # out of the box run
top.words = top.topic.words(result$topics, nwords<-30, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:5) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
abs = PlainTextDocument(ts) # make it plain
corpus = lexicalize(abs) # yup
to.keep = corpus$vocab[word.counts(corpus$documents, corpus$vocab) >= 2] # only stuff that happens, actually
to.keep = to.keep[to.keep!=""&nchar(to.keep)>2] # no short words, or empties
corpus = lexicalize(abs, vocab=to.keep)
result = lda.collapsed.gibbs.sampler(corpus,5,to.keep,25,.1,.1) # out of the box run
top.words = top.topic.words(result$topics, nwords<-30, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:5) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=fruchterman.reingold,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.fruchterman.reingold,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
top.words = top.topic.words(result$topics, nwords<-25, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:5) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
result = lda.collapsed.gibbs.sampler(corpus,nclusts<-10,to.keep,25,.1,.1) # out of the box run
top.words = top.topic.words(result$topics, nwords<-25, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:5) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
top.words
result = lda.collapsed.gibbs.sampler(corpus,nclusts<-10,to.keep,25,.1,.1) # out of the box run
top.words = top.topic.words(result$topics, nwords<-25, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:nclusts) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
result = lda.collapsed.gibbs.sampler(corpus,nclusts<-10,to.keep,25,.1,.1) # out of the box run
top.words = top.topic.words(result$topics, nwords<-10, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:nclusts) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
abs = a$abs
### let's clean ###
doublespace = function(x) { return(gsub("  "," ",x)) }
chunk = paste(a$abs,collapse=" ")
words = unique(unlist(strsplit(doublespace(chunk),split=" ")))
pukeplural = function(x) { # cheap plural removal
return(gsub(search_term,allstring_minus_last,x))
}
for (w in words) {
search_term <- w
lastletter <- substr(w,nchar(w),nchar(w))
allstring_minus_last <- substr(w,1,nchar(w)-1)
if (lastletter=="s" & allstring_minus_last %in% words) {
abs = lapply(abs, pukeplural)
}
}
#stemit = function(x) { # stemmers aren't pretty mostly
#  news = LovinsStemmer(unlist(strsplit(x,split=" ")),control=NULL)
#  return(paste(news,collapse=" "))
#}
#abs = lapply(abs, stemit)
ts = Corpus(VectorSource(abs)) # using tm to strip / clean
ts = tm_map(ts, removeWords, stopwords("english"))
removepunct = function(x) { return(gsub("[[:punct:]]","",x)) }
ts = tm_map(ts, removepunct)
removenum = function(x) { return(gsub("[0-9]","",x)) }
ts = tm_map(ts, removenum)
ts = tm_map(ts, doublespace)
abs = PlainTextDocument(ts) # make it plain
corpus = lexicalize(abs) # yup
to.keep = corpus$vocab[word.counts(corpus$documents, corpus$vocab) >= 2] # only stuff that happens, actually
to.keep = to.keep[to.keep!=""&nchar(to.keep)>2] # no short words, or empties
corpus = lexicalize(abs, vocab=to.keep)
result = lda.collapsed.gibbs.sampler(corpus,nclusts<-10,to.keep,25,.1,.1) # out of the box run
top.words = top.topic.words(result$topics, nwords<-10, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:nclusts) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
result = lda.collapsed.gibbs.sampler(corpus,nclusts<-10,to.keep,25,.25,.1) # out of the box run
top.words = top.topic.words(result$topics, nwords<-10, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:nclusts) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
result = lda.collapsed.gibbs.sampler(corpus,nclusts<-10,to.keep,25,.05,.1) # out of the box run
top.words = top.topic.words(result$topics, nwords<-10, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:nclusts) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
abs = PlainTextDocument(ts) # make it plain
corpus = lexicalize(abs) # yup
to.keep = corpus$vocab[word.counts(corpus$documents, corpus$vocab) >= 3] # only stuff that happens, actually
to.keep = to.keep[to.keep!=""&nchar(to.keep)>3] # no short words, or empties
corpus = lexicalize(abs, vocab=to.keep)
result = lda.collapsed.gibbs.sampler(corpus,nclusts<-10,to.keep,25,.05,.1) # out of the box run
top.words = top.topic.words(result$topics, nwords<-10, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:nclusts) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
abs = PlainTextDocument(ts) # make it plain
corpus = lexicalize(abs) # yup
to.keep = corpus$vocab[word.counts(corpus$documents, corpus$vocab) >= 3] # only stuff that happens, actually
to.keep = to.keep[to.keep!=""&nchar(to.keep)>3] # no short words, or empties
corpus = lexicalize(abs, vocab=to.keep)
result = lda.collapsed.gibbs.sampler(corpus,nclusts<-10,to.keep,25,.05,.05) # out of the box run
top.words = top.topic.words(result$topics, nwords<-10, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:nclusts) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
top.words
abs = a$abs
### let's clean ###
doublespace = function(x) { return(gsub("  "," ",x)) }
chunk = paste(a$abs,collapse=" ")
words = unique(unlist(strsplit(doublespace(chunk),split=" ")))
pukeplural = function(x) { # cheap plural removal
return(gsub(search_term,allstring_minus_last,x))
}
for (w in words) {
search_term <- w
lastletter <- substr(w,nchar(w),nchar(w))
allstring_minus_last <- substr(w,1,nchar(w)-1)
if (lastletter=="s" & allstring_minus_last %in% words) {
print(search_term)
abs = lapply(abs, pukeplural)
}
}
to.keep
to.keep["vi" %in% to.keep]
to.keep[to.keep=="visual"]
doublespace = function(x) { return(gsub("  "," ",x)) }
chunk = paste(a$abs,collapse=" ")
words = unique(unlist(strsplit(doublespace(chunk),split=" ")))
pukeplural = function(x) { # cheap plural removal
return(gsub(search_term,allstring_minus_last,x))
}
for (w in words) {
search_term <- w
lastletter <- substr(w,nchar(w),nchar(w))
allstring_minus_last <- substr(w,1,nchar(w)-1)
if (lastletter=="s" & allstring_minus_last %in% words) {
if (w=="visual") {
print(search_term)
}
abs = lapply(abs, pukeplural)
}
}
abs = a$abs
### let's clean ###
doublespace = function(x) { return(gsub("  "," ",x)) }
chunk = paste(a$abs,collapse=" ")
words = unique(unlist(strsplit(doublespace(chunk),split=" ")))
pukeplural = function(x) { # cheap plural removal
return(gsub(search_term,allstring_minus_last,x))
}
for (w in words) {
search_term <- w
lastletter <- substr(w,nchar(w),nchar(w))
allstring_minus_last <- substr(w,1,nchar(w)-1)
if (lastletter=="s" & allstring_minus_last %in% words) {
if (w=="visual") {
print(search_term)
}
abs = lapply(abs, pukeplural)
}
}
search_term
lastletter
allstring_minus_last
w
abs = lapply(abs, pukeplural)
abs = a$abs
### let's clean ###
doublespace = function(x) { return(gsub("  "," ",x)) }
#stemit = function(x) { # stemmers aren't pretty mostly
#  news = LovinsStemmer(unlist(strsplit(x,split=" ")),control=NULL)
#  return(paste(news,collapse=" "))
#}
#abs = lapply(abs, stemit)
ts = Corpus(VectorSource(abs)) # using tm to strip / clean
ts = tm_map(ts, removeWords, stopwords("english"))
removepunct = function(x) { return(gsub("[[:punct:]]","",x)) }
ts = tm_map(ts, removepunct)
removenum = function(x) { return(gsub("[0-9]","",x)) }
ts = tm_map(ts, removenum)
ts = tm_map(ts, doublespace)
abs = PlainTextDocument(ts) # make
chunk = paste(abs,collapse=" ")
words = unique(unlist(strsplit(doublespace(chunk),split=" ")))
words[1]
words[1:10]
pukeplural = function(x) { # cheap plural removal
return(gsub(search_term,allstring_minus_last,x))
}
for (w in words) {
search_term <- w
lastletter <- substr(w,nchar(w),nchar(w))
allstring_minus_last <- substr(w,1,nchar(w)-1)
if (lastletter=="s" & allstring_minus_last %in% words) {
if (w=="visual") {
print(search_term)
}
abs = lapply(abs, pukeplural)
}
}
abs[1]
abs = PlainTextDocument(ts) # make it plain
chunk = paste(abs,collapse=" ") # cheap plural removal
words = unique(unlist(strsplit(doublespace(chunk),split=" ")))
pukeplural = function(x) {
return(gsub(search_term,allstring_minus_last,x))
}
pukeplural = function(x) {
print(search_term)
print(allstring_minus_last)
return(gsub(search_term,allstring_minus_last,x))
}
for (w in words) {
search_term <- w
lastletter <- substr(w,nchar(w),nchar(w))
allstring_minus_last <- substr(w,1,nchar(w)-1)
if (lastletter=="s" & allstring_minus_last %in% words) {
abs[1] = lapply(abs[1], pukeplural)
}
}
abs[1]
abs = PlainTextDocument(ts) # make it plain
chunk = paste(abs,collapse=" ") # cheap plural removal
words = unique(unlist(strsplit(doublespace(chunk),split=" ")))
pukeplural = function(x) {
print(search_term)
print(allstring_minus_last)
return(gsub(search_term,allstring_minus_last,x))
}
abs[1]
abs = PlainTextDocument(ts) # make it plain
chunk = paste(abs,collapse=" ") # cheap plural removal
words = unique(unlist(strsplit(doublespace(chunk),split=" ")))
pukeplural = function(x) {
print(search_term)
print(allstring_minus_last)
return(gsub(search_term,allstring_minus_last,x))
}
for (w in words) {
search_term <- w
lastletter <- substr(w,nchar(w),nchar(w))
allstring_minus_last <- substr(w,1,nchar(w)-1)
if (lastletter=="s" & allstring_minus_last %in% words & nchar(w)>3) {
abs = lapply(abs, pukeplural)
}
}
chunk = paste(abs,collapse=" ") # cheap plural removal
words = unique(unlist(strsplit(doublespace(chunk),split=" ")))
pukeplural = function(x) {
return(gsub(search_term,allstring_minus_last,x))
}
for (w in words) {
search_term <- w
lastletter <- substr(w,nchar(w),nchar(w))
allstring_minus_last <- substr(w,1,nchar(w)-1)
if (lastletter=="s" & allstring_minus_last %in% words & nchar(w)>3) {
abs = lapply(abs, pukeplural)
}
}
abs[1]
corpus = lexicalize(abs) # yup
to.keep = corpus$vocab[word.counts(corpus$documents, corpus$vocab) >= 3] # only stuff that happens, actually
to.keep = to.keep[to.keep!=""&nchar(to.keep)>3] # no short words, or empties
corpus = lexicalize(abs, vocab=to.keep)
result = lda.collapsed.gibbs.sampler(corpus,nclusts<-10,to.keep,25,.05,.05) # out of the box run
top.words = top.topic.words(result$topics, nwords<-10, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:nclusts) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
corpus = lexicalize(abs) # yup
to.keep = corpus$vocab[word.counts(corpus$documents, corpus$vocab) >= 3] # only stuff that happens, actually
to.keep = to.keep[to.keep!=""&nchar(to.keep)>3] # no short words, or empties
corpus = lexicalize(abs, vocab=to.keep)
result = lda.collapsed.gibbs.sampler(corpus,nclusts<-8,to.keep,25,.1,.1) # out of the box run
top.words = top.topic.words(result$topics, nwords<-20, by.score=TRUE) # out of the box run
edges = data.frame() # let's build the edges for our igraph plot
for (i in 1:nclusts) {
edges = rbind(edges,expand.grid(top.words[,i],top.words[,i])) # cartesian
}
edges[,1] = as.character(edges[,1])
edges[,2] = as.character(edges[,2])
alphabetorder = function(x) {
s = edges[x,]
edges[x,] <<- edges[x,order(s)]
}
sapply(1:dim(edges)[1],alphabetorder)
edges = unique(edges)
edges = edges[edges[,1]!=edges[,2],]
net = graph.data.frame(edges,directed=F)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.kamada.kawai,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.fruchterman.reingold,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.spring,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.svd,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.reingold.tilford,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
plot(net,vertex.shape='none',vertex.size=0,vertex.color='white',layout=layout.auto,
vertex.label.color='black',vertex.label.cex=1,vertex.label.family='Arial',
vertex.label.font=2)
