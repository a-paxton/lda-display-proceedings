this half-day tutorial will cover how to build and deploy on- line experiments using jspsych, psiturk, and amazon mechanical turk (amt). jspsych is an open-source javascript library that facilitates building behavioral experiments in a web browser. psiturk is an open-source python platform that simplifies the process of running an experiment using amt. together, these two software packages reduce the complexity of setting up an online experiment on amt, enabling researchers with little software programming experience to take advantage of online experiments. by the end of the tutorial, participants will have gained hands-on experience in programming and deploying a basic behavioral experiment on amt.
human thought is remarkably flexible: we can think about infinitely many different situations despite uncertainty and novelty. probabilistic models of cognition (chater, tenenbaum, & yuille, 2006) have been successful at explaining a wide variety of learning and reasoning under uncertainty. they have borrowed tools from statistics and machine learn- ing to explain phenomena from perception (yuille & kersten, 2006) to language (chater & manning, 2006). traditional symbolic models (e.g. newell, shaw, & simon, 1958; anderson & lebiere, 1998), by contrast, excel at explaining the productivity of thought, which follows from compositionality of symbolic representations. indeed, there has been a gradual move toward more structured probabilistic models (tenenbaum, kemp, griffiths, & goodman, 2011) that incor- porate aspects of symbolic methods into probabilistic modeling. unfortunately this movement has resulted in a complex “zoo” of bayesian models. we have recently introduced the idea that using programs, and particularly probabilistic programs, as the representational substrate for probabilistic modeling tames this unruly zoo, fully unifies probabilistic with symbolic approaches, and opens new possibilities in cognitive modeling. the goal of this tutorial is to introduce probabilistic models of cognition from the point of view of probabilistic programming, both as a unifying idea for cognitive modeling and as a practical tool.
this half-day workshop will provide information and hands-on experience related to applying for national science foundation (nsf) funding in cognitive science. program officers will discuss the nsf review process and nsf merit criteria. details regarding a range of cognitive science research programs will be covered, including cognition, computation, development, education, and neuroscience. in addition, as an interactive activity, attendees will participate in simulated review panels using actual cognitive science grant proposals.the target audience of this workshop is anyone who intends to seek funding for cognitive science research, including graduate students, postdoctoral scholars, new faculty, and experienced researchers.
recent years have witnessed an increasing interest in developing computational models of emotion and emotion-cognition interaction, within the emerging area of computational affective science.  at the same time, emotion theorists and clinical psychologists have been recognizing the importance of moving beyond descriptive characterizations of affective disorders, and identifying the underlying mechanisms that mediate both psychopathology and the processes mediating therapeutic action.  computational models of cognition-emotion interactions have the potential to facilitate more accurate assessment and diagnosis of affective disorders, and to provide a basis for more efficient and targeted approaches to treatment, through an improved understanding of the mechanisms of therapeutic action. 
this half-day workshop will bring together researchers in cognitive science and computer science with an interest in irony. irony detection is an especially difficult problem for natural language processing. unlike other types of classification tasks, the difficulty of identifying irony is not alleviated by 'throwing more data' at the problem. rather, it seems a different kind of data is needed: contextual data. we also need new models that can exploit this data. in this workshop, which capitalizes on the collocation of the aaai and cogsci conferences, we invite cognitive scientists and computer scientists to engage in a dialogue around new machine learning models for irony detection and new methods and tools for testing predictions of cognitive theories of irony against large-scale data sets. we will also introduce the reddit irony corpus, a hand-annotated corpus of ironic utterances culled from internet posts. organizers: byron wallace (brown) and laura kertz (brown). invited speakers: greg bryant (ucla), ellen riloff (university of utah), vera tobin (case western).
growth curve analysis (multilevel regression) offers a sta-tistical framework for analyzing longitudinal or time course data and for quantifying differences between individuals in the context of a model of the overall group effects. these methods have been known to statisticians for many years (e.g., wishart, 1938), but they have only recently become a prominent statistical tool in the cognitive sciences. interest in using these statistical methods to analyze cognitive science data has outpaced cognitive scientists’ knowledge of how to implement them. this one-day tutorial will provide a hands-on introduction to using multilevel regression to analyze longitudinal or time course data and individual differences in the cognitive sciences. the focus will be on practical aspects of implementation and common pitfalls, rather than statistical theory.
the lack of materials on the details of running human experiments can lead to a gap between theory and practice, which is particularly acute in cognitive science experiments done outside of psychology depart¬ments. the details about how to run the studies themselves, how to interact with subjects and other tacit knowledge about how to run a study, are often not available and either learned through trial and error, or available only through apprenticeship in a psychology or hci lab. researchers in psychology thus often end up appalled by the lack of this common but undocu¬mented sense when behavioral research is performed and reported by researchers outside of psychology.  this tutorial provides practical advice on how to run studies for beginning students and researchers coming starting to run studies. 
this workshop serves to update both the act-r community and the modeling community at large about recent advances in the act-r architecture. for researchers already using act-r, the workshop provides a venue for presenting and hearing about recent changes to and novel applications of the architecture. for others working with (non-act-r) computational cognitive models, the workshop provides an overview of application domains addressed by the architecture, and encourages sharing of ideas that benefit act-r and other frameworks alike.
deep learning systems rely on many layers of processing to perform sensory processing tasks like visual object recognition, speech recognition, and natural language processing (bengio & lecun, 2007). by learning simpler features in lower layers, and composing these into more complex features in higher layers, deep networks take advantage of the compositional structure of many real world domains and have realized impressive performance in a range of engineering applications, from visual object classification (krizhevsky, sutskever, & hinton 2013; ciresan, meier, & schmidhuber, 2012) to speech recognition (mohamed, dahl, & hinton, 2012) and natural language processing (collobert & weston, 2008). how might deep learning models illuminate phenomena of interest to cognitive scientists such as perceptual learning, language acquisition, cognitive development, and category formation? how does depth impact both the dynamics of learning in a neural network, and the content of what is learned? this workshop will explore the implications of deep learning for our understanding of the brain and mind through a series of invited talks from established researchers in the field.
cognitive science and the arts are natural partners. the arts are produced by the mind, the brain, and the body and comprehended, interpreted, and appreciated by the mind, the brain, and the body. the arts make special contributions to cognitive science by providing a rich, natural, multi-sensory, multi-cultural arena for study and analysis. this workshop will bring together people who have been studying the connections of cognitive science and the arts from many different perspectives. 
the objective of this tutorial is to provide participants with anaccessible introduction to mixture models (mms) and hidden markovmodels (hmms) and the necessary skills to apply them in their ownresearch. these models are particularly useful to analyse aspects ofcognition which are best understood in terms of discrete types andstates (e.g., when people are expected to apply distinct strategieswhen performing a task). mms and hmms allow one to extract suchtypes/states even when they are not known exactly beforehand. we willprovide an intuitive introduction to the underlying theory of mms andhmms and will show how to apply the models in practice using freelyavailable software. throughout the tutorial, the techniques areillustrated with real data relevant to a cognitive science audience.participants are encouraged to bring their laptop to follow theexamples and apply the techniques to their own data.nb: this tutorial is identical to the one presented last year at cogsci in berlin. 
this full day tutorial is an exposition of a rapidly growing new alternative approach to building computational models of cognition and decision based on quantum theory. the cognitive revolution that occurred in the 1960’s was based on classical computational logic, and the connectionist/neural network movements of the 1970’s were based on classical dynamical systems. these classical assumptions remain at the heart of both cognitive architecture and neural network theories, and they are so commonly and widely applied that we take them for granted and presume them to be true. what are these critical but hidden assumptions upon which all traditional theories rely? quantum theory provides a fundamentally different approach to logic, reasoning, probabilistic inference, and dynamical systems. for example, quantum logic does not follow the distributive axiom of boolean logic; quantum probabilities do not obey the disjunctive axiom of kolmogorov probability; quantum reasoning does not obey the principle of monotonic reasoning. it turns out that humans do not obey these restrictions either, which is why we consider a quantum approach. 
numeracy is a paradigmatic example of the close dovetailing of culture, language, and cognition. the two systems central to the numerical competence — one for the exact representation of small numbers and one for the approximation of larger numbers — are relatively old in phylogenetic terms and available almost from birth. together, they provide the basis for the specifically human ability to also assess larger numbers in an exact manner (dehaene, 1997; feigenson et al., 2004). yet, while several scholars consider numeracy a core domain of knowledge (spelke & kinzler, 2007), its full development seems to presuppose cultural and linguistic input in the form of counting sequences, as indicated by studies on two amazonian groups (gordon, 2004; pica et al., 2004). if, however, number representations are absent from both culture and language, their relative relevance for numerical cognition cannot be assessed unambiguously. this symposium attempts to advance this field of research, which is increasingly recognized as one of prime interest for cognitive science. it brings together researchers, who have contributed considerably to the expanding knowledge on numerical cognition. 
drawing is a fundamental aspect of human communicative expression, and sequential images have been used to convey information since at least cave paintings. however, only until recently has increased research turned towards studying the cognition of visual narratives—especially those found in comics. the most examined question about visual narratives has asked: how do readers make meaning out of a sequence of images? such an inquiry must balance the understanding of meaning within and across individual images, the generation of inferences from such content, and the engagement of such phenomena within the physical layouts of a page, possibly in multimodal interactions.
when interpreting a speaker’s utterance, listeners routinely go beyond the information that is linguistically encoded and draw pragmatic inferences about what the speaker intended to convey. a core aspect of pragmatic inference is that it requires listeners to take into account alternative utterances that a speaker could have produced, but didn’t. for example, a listener who believes that the more informative "alex ate all of the cookies" was an alternative a speaker could have used instead of her actual utterance "alex ate some of the cookies" will likely expect there to be cookies left over. similarly, if a speaker says of alex that "he caused the car to stop", a listener will likely infer that he did so in a non-stereotypical way, since she could have instead uttered the simpler, more frequent, "he stopped the car".
surprise is a ubiquitous phenomenon that both draws on cognition and affects cognition, in a number of different ways. for example, in artificial intelligence an agent in a changing and imperfectly-known environment has been argued to need a surprise mechanism to survive. this symposium brings together researchers in education, computer science, cognitive psychology, and business to explore the relationship between surprise and cognition, and how it might be harnessed across domains. we will open with a touchstone challenge: how can surprising information be recruited to promote learning? (munnich & ranney) then we will explore several perspectives on surprise, ranging from violation of expectations created through repetition (loewenstein) to a focus on the information content of surprising events (maguire & maguire), to the apparently conflicting roles surprise may play in judgment (may, smith-rodden, & ash). our final speakers (foster & keane) will synthesize these approaches, and present a broad framework for future research on surprise within the cognitive sciences.
how do different modalities like language, gesture, and mental imagery interact to support symbolic representation? we investigate the unique case study of “mental abacus” (ma). by visualizing a physical abacus, supporting computations with gesture, and translating responses in a verbal format, ma users perform arithmetic calculations with astonishing speed and accuracy. we explore the nature of this expertise, and how different systems interact to create a multimodal symbolic system.
across a diverse assortment of topics, competitions have been established to motivate and focus scientists and engineers, as well as students interested in such careers, on ambitious objectives. examples include the famous robocup robotic soccer tournaments, the international conference on functional programming (icfp) contests, and the high performance computing (hpc) challenges.  the national institute of standards and technology (nist) speaker recognition evaluations, although officially considered not to be competitions, also provide intriguing examples of “crowd-sourced” improvements in methodology and capability. whether we refer to them as competitions, challenges, tournaments, or evaluations, the purpose these recurring annual events serve is to create opportunities for a broad cross-section of interested and capable people to participate in the process of accelerating scientific and technological progress.  
tetris is the video game most used as a research paradigm by the cognitive science community (mayer, in press). collectively, the members of this symposium have and are using tetris to study several phenomena that we each believe is just slightly out of reach but in sight of contemporary cognitive theory.
how does comparison affect the way we think of others? comparison has been shown to be a powerful learning tool in a variety of conceptual domains, ranging from basic spatial relations, to concepts in algebra and heat flow (e.g., gentner, 2010). comparison recruits a structure-mapping process that highlights common relational structure between two situations. it helps novice learners see meaningful similarities and differences which can then be transferred to novel situations. this process can help infants and children move beyond the particular features of any one situation and gain a more abstract understanding of complex concepts.while comparison has been established as an important tool in cognitive development, less work has illustrated how it may function as a key process in the social domain. the goal of this symposium will be to show how these benefits of comparison can also influence the development of social cognition.
cognitive science aims to understand how humans and animals process information and to build models of these processes – often referred to as process models. however, there seems to be no consensus about what constitutes a process model or which process models are useful (see e.g., pohl, 2011 for the recognition heuristic model). this symposium will discuss the moot point process models from various perspectives. it brings together researchers who develop and work with different types of models, such as act-r, probabilistic computational models, quantum probability, or fmri data. focusing on models of judgment and decision making, they will present and discuss the level and scope of their models, which are all seen as candidates for a “process model”.
the controversy that followed the publication of bem’s (2011)surprising results had the merit of focusing discussions on thevalidity of the current paradigm in psychological science. ithas been argued that a tendency of journals to avoid publishingnull results, in addition to the further extinguishing of nullresults through questionable researcher practices, is leading tothe promulgation of a multitude of ‘undead’ theories that havelittle basis in fact (ferguson & heene, 2012; francis, 2012). atthe same time, the field of ai has met with success preciselyby abandoning theory, prompting noam chomsky to remarkthat it is deviating from anything previously seen in the historyof science (see cristianini, 2014). in this symposium thespeakers consider whether current theories offered by psychologicalscience are valuable, whether there might be inherentobstacles which are preventing the identification of valuabletheories, and whether psychological theory even matters at all.
social life constantly requires us to decipher information about others into inferences about their emotional states: for example, we have to reason about what makes our romantic partners happy (a surprise gift?) or angry (not doing one’s chores?), and what they would do in those emotional states, in order to plan our upcoming interactions. such affective cognition, or our ability to reason about others’ emotions, scaffolds everything from cooperation to the maintenance of social relationships. affective cognition lies in the intersection of two foundational social cognitive topics, theory of mind (tom; the ability to reason about others’ mental states) and empathy (the ability to feel and understand others’ emotions). although the past decade has seen much progress in understanding tom and empathy using neuroscience (koster-hale & saxe, 2013; zaki & ochsner, 2012), developmental (meltzoff, 2011), and computational (baker, saxe, & tenenbaum, 2009; goodman & stuhlmuller, 2013) approaches, somewhat less attention has been paid specifically to affective cognition and some of its foundational cognitive questions. how do we represent (cognitively and neurally) others’ emotional states? how do we reason with those representations? how do we make predictions and inferences about others’ future actions or desires based on their emotions? finally, how does affective cognition shift across development? the aim of the symposium is to answer these, and other relevant questions, at the forefront of this field.
this symposium is a venue for discussing the implicationsof embodied cognition research for mathematics andcomputing education. our goal is to bring five themestogether that we think are complementary in understandingwhat embodiment holds for math and computing education:(1) empirical studies: behavioral, neuroscience, andneuropsychological work on sensorimotor groundings ofhigher-cognition, (2) the impact of perspectives inembodied cognition on a philosophy of mathematics, (3)embodied interaction & ubiquitous computing: recenttrends in human-computer interaction that propose physicaland social embedding in the world as basis for interaction,(4) embodied interaction and the arts: trends in aestheticcomputing that result in crafting artistically-derivednotations and representations of mathematics andcomputing, and (5) embodied learning: wide range ofapproaches in education that view bodily involvement as acrucial aspect of the learning process. by accounting forwork in these five areas we will bridge empirical andphilosophical studies on embodiment with learning andcommunication design work. our goal is to present acomprehensive story of embodiment of mathematicalcognition by covering and relating multiple levels, fromsensorimotor neural circuits that support mathematicalcognition to technological external representations thatfacilitate learning of mathematical concepts and ideas.
creativity is the generation of products and ideas that are new, valuable, and surprising. interdisciplinary research in cognitive science makes it clear that creativity does not have to be the mysterious result of divine inspiration. rather, we can investigate the mental processes that have creative results. this symposium will discuss creativity from a combination of disciplinary vantage points, including philosophy, psychology, neuroscience, and computer modeling. we will try to answer questions such as the following: what are the most important cognitive processes involved in producing creative results? do these cognitive processes operate in the same way across the many domains of creativity, including science, technology, the arts, and social innovation? how can understanding of cognitive processes be used to enhance creativity?  is creativity amenable to computer modeling? is there an optimal level of creativity at the individual and social level?
what are the origins of our ability to perceive and reason about time? the human experience of time is multifaceted: duration perception on the order of seconds; words (e.g. “hour”) and grammatical features (e.g. tense) that encode specific aspects of temporal experience; reasoning about duration, sequences, and causality. while some of these abilities are present early in development, others do not emerge for many years. there is an active debate about the origins of these varied facets of temporal cognition. for instance, what are their evolutionary and developmental sources? do certain temporal capacities distinguish us from non-human animals? is our understanding of time built on a spatial foundation, or do both space and time rely on a shared, domain-general representational system? the time is ripe for an integrated approach to this foundational human capacity. this symposium brings together researchers whose work has presented varied perspectives on the psychological origins of time, from perception to conceptualization.
previous eye tracking findings show that people preferentially direct their attention to the target of a recently depicted event compared with the target of a possible future event during the comprehension of a spoken sentence relating to the recent or future event (e.g., abashidze, knoeferle, carminati, & essig, 2011; knoeferle & crocker, 2007). this gaze pattern emerged even when the frequency of occurrence of future and recent events did not differ within the experiment, knoeferle, carminati, abashidze, & essig, 2011, experiment 2). to further test the robustness of the recent event preference, the current studies introduced a frequency bias in favor of the future over the recent event (experiment 1: 88% future vs. 12% past events in combination with future and past sentences; experiment 2: 75% future vs. 25% past event). we found that increasing the frequency of the future event did result in earlier fixations to the target of the future event than previously observed (in experiment 2 of knoeferle, carminati, abashidze, & essig, 2011). however, in the current studies we essentially replicated the same overall preference to look at the target of the recent event throughout sentence presentation. a memory test supported these results. thus, within-experiment frequency appears to modulate the recent event preference to some extent, but cannot override it. we propose that an epistemic bias of the human mind favors assertions about past events over future ones.  
the neural network version of the gaussian activation model of interval timing (gamit-net) is a simple recurrent network that unifies retrospective and prospective timing in a single framework. it has two parts. firstly, a time-dependent signal is generated by a spreading gaussian activation. next, a simple recurrent network (srn) combines information from the gaussian and its own internal state during a timing task to generate time estimates. this model captures the scalar property of interval timing (gibbon, 1977). furthermore, under high cognitive load the gaussian fades faster while the internal state is updated less often. these factors interact to account for the surprising finding that retrospective estimates increase under cognitive load while prospective estimates decrease (block, hancock & zakay, 2010).
gaze and speech are both important modes of communication for human-robot interactions. however, few studies to date have explored the effects of conflict in a robot's multi-modal communication. in this paper, we investigate how such speech-gaze conflicts affect  performance on a cooperative referential task. participants play a selection game with a robot, in which the robot instructs them to select one object from among a group of available objects. we vary whether the robot's gaze is congruent with its speech, incongruent with its speech, or absent, and we measure participants' response times to the robot's instructions. results indicate that congruent speech facilitates performance but that incongruent speech does not hinder performance. we repeat the study with a human actor instead of a robot to investigate whether human gaze has the same effect, and find the same results: in this type of activity, congruent gaze helps performance while incongruent gaze does not hurt it. we conclude that robot gaze may be a worthwhile investment in such situations, even when gaze behaviors may be unreliable.
effectively solving the problem of when and where to forage is critical for survival in many animal species. the task is further complicated when there are other agents, potentially competing for the same limited resources. previous models of foraging consider agents either in isolation or in groups but without competition. here, we present a novel bayesian model for competitive foraging, socially aware bayesian agent (saba), that takes into explicit account the presence of other agents for both learning and decision-making. for comparison, we also implement a simple naive agent model that completely ignores the presence of other agents. we find that although all models perform well in a stationary environment, converging quickly to the optimal population-level solution, only saba with the stochastic foraging policy can readily adapt when the environment is non-stationary. these results represent a first step toward cognitively sophisticated representations for learning and decision-making in competitive foraging.
in this paper we look at the well known phenomenon of conjunction fallacies (tversky & kahneman, 1983) from a linguistic perspective. we are particularly interested in understanding the impact of this phenomenon on our understanding of compositionality, a core assumption of contemporary linguistic theories about language meaning. we will argue that contra hertwig, benz, and krauss (2008), conjunction fallacies do not arise because of the ambiguity of coordinating conjunctions such as and, but rather because there are two different strategies available for computing the composite likelihood of a collection of events. crucially, in our analysis the two strategies are two variants of the same underlying general structure that simultaneously allows subjects 1. to reason in purely logical terms; 2. to follow the rules of probability and 3. to commit fallacies depending on the conditions under which they evaluate linguistic expressions relating uncertain events. we will explain the choice between the two strategies in terms of cognitive/computational economy and the consequences of overestimating the likelihood of an event.
to generalize from one experience to the next in a world where the underlying structures are ever-changing, people construct clusters that group their observations and enable information to be pooled within a cluster in an efficient and effective manner. despite substantial computational work describing potential domain-general processes for how people construct these clusters, there has been little empirical progress comparing different proposals to each other and to human performance. in this article, i empirically test some popular computational proposals against each other and against human behavior using the markov chain monte carlo with people methodology. the results support two popular bayesian nonparametric processes, the chinese restaurant process and the related dirichlet process mixture model.
it is proposed that studying individual tasks in isolation is a solution to fodor's problem: how can we break down the empirical project in psychology into tractable units? the task-oriented approach is in this sense an alternative to the modular view of the mind. i propose a definition of a task as a researcher-defined unit of study that corresponds to a reconfiguration of resources in an animal-enviroment system; this reconfiguration: is meaningful to a perceiver-actor; is amenable to precise characterization; specifies criteria for succesful completion of the task; and provides a guide to researchers on how to generalize empirical conclusions drawn from the study of a given phenomenon. the task-oriented approach is well-suited to the study of certain phenomena that the standard brain-oriented approach struggles to characterize, such as collaborative activity. framing the dichotomy between the approaches in terms of methodology allows us to avoid fruitless ontological discussions about external content.
understanding visual attention in children could yield insight into how the visual system develops during formative years and how children's overt attention plays a role in development and learning. we are particularly interested in the role of hands and hand activities in children's visual attention. we use head-mounted cameras to collect egocentric video and eye gaze data of toddlers during playful social interaction with their parents, and developed a computer vision system to track and label different hands within the child's field of view. we report detailed results on appearance frequencies and spatial distributions of parents' and children's hands both in the child's field of view and as the target of the child's attentional fixation.
we examine people’s preferences about whether to engage in discretionary spending vs. save their money and find that re-duced spending in the present requires the combination of both being motivated to provide for one’s future self (valuing the fu-ture) and actively considering long-term implications of one’s choices (awareness of the future). feeling more connected to the future self—thinking that the important psychological prop-erties that define your current self are preserved in the person you will be in the future—provides the motivation for people to make far-sighted choices by changing the valuation of future outcomes. however, this change only reduces spending when opportunity costs are highlighted.
many adults struggle with second language acquisition, but learn new words in their native language relatively easily. most second language words do not follow native language patterns, but those that do may be easier to learn because they make use of existing language knowledge. twenty english monolinguals learned to recognize and produce 48 novel written words in five repeated testing blocks. half of the words were wordlike (e.g., 'nish') in form (high neighborhood density, high orthotactic probability), while half were not (e.g., 'gofp'). participants were more accurate at recognizing and producing wordlike compared to unwordlike items. in addition, participants were faster to respond correctly in wordlike trials. english vocabulary size predicted wordlike learning, while phonological memory predicted learning for both wordlike and unwordlike items. results suggest that existing language knowledge affects acquisition of novel written vocabulary, with consequences for second language instruction.
in memory-based models of human sentence processing it is assumed that the completion of a dependency between a syntactic head and its dependents is a major source of processing difficulty in non-ambiguous sentences, and that this integration cost is a function of the distance between the two elements. however, it remains open how to measure the distance between two dependent elements. while many current models employ a linear distance measure, we instead propose to measure the distance between a head and its dependents as the path in the phrase structure tree connecting the two elements. we evaluate this structural distance as a measure of dependency integration and show that it is a better predictor of human reading times than other measures. moreover, we find that evaluated on reading data from naturally occurring texts, dependency integration is not actually a cost, as higher dependency integration distances led to lower reading times.
cognitive biology refers to investigations of cognitive pro-cesses in a wide range of model organisms from bacteria to plants and animals. although this research has generally been beyond the scope of mainstream cognitive science, i argue that cognitive science would benefit from integrating investi-gations into model organisms and focus on what can be learned from surprising model organisms—bacteria and in-vertebrates. evolution is a highly conserved process, and the mechanisms developed in our common ancestors with these species provide the foundation for many of our cognitive ac-tivities. since these organisms lack some of the complications that have evolved in us, research on them can help reveal key features of our cognitive mechanisms.
cognitive scientists have shown increased interest in diagrams in recent years, but most of the focus has been on spatial representation, not conventions for representing time. we explore a variety of ways in which time is represented in diagrams by one research community: scientists investigating circadian rhythms at the behavioral and molecular levels. diagrams that relate other variables to time or indicate a mechanism’s states across time use one or two spatial dimensions or circles to represent time and sometimes include explicit time markers (e.g., the hours on a clockface).
does the cognitive naturalness of concepts affect the acquisitional path of meaning? in this paper, we explore the use of crosslinguistically elicited data to approximate cognitive naturalness, following gentner and bowerman’s (2009) typological prevalence hypothesis. using the domain of topological spatial relations as a case study, we show how this kind of data allows us to simulate developmental patterns of order of acquisition and overgeneralization in dutch. this result suggests that the typological prevalence hypothesis can be computationally operationalized and evaluated, that modeling semantic acquisition without hand-coded semantic primitives is possible, and finally, that crosslinguistic data provides a good source of information to do so.
as learning technologies proliferate, it is important for research to address how to best align instruction to educational goals. for example, recent evidence indicates that working collaboratively may have unique benefits for facilitating the acquisition of conceptual understanding, as opposed to procedural fluency (mullins, rummel & spada, 2011). to investigate this effect, we leverage and expand upon a new methodology, dual eye-tracking, to understand how collaborators’ joint attention may impact learning in a collaboration-enabled intelligent tutoring system for fractions. we present results from a study in which 28 pairs of 4th and 5th grade students completed a set of either conceptually- or procedurally-oriented instructional activities in a school setting. results indicate that students collaborating exhibited learning gains for conceptual knowledge, but not for procedural knowledge, and that more joint attention was related to learning gains. these results may inform the design of future learning technologies, and illustrate the utility of using dual eye-tracking to study collaboration. 
we combine two recent probabilistic approaches to natural language understanding, exploring the formal pragmatics of communication on a noisy channel. we show that nominal amounts of actual noise can be leveraged for communicative purposes. common knowledge of a noisy channel leads to the use and correct understanding of sentence fragments. prosodic emphasis, interpreted as an intentional action to reduce noise on a word, results in strengthened meanings.
we investigate whether holism presents a problem for inductive inference by examining the relationship between the size of a bayesian network that represents human conceptual knowledge and the computational complexity of probabilistic inference in that network. we find that, despite prior claims, holism may not be a problem for inductive inference, as computational cost does not increase exponentially as the network grows. while the network we analyze is holistic, it has a modular organization and grows in a way that potentially makes efficient inductive inference possible.
this paper models choice deferral using a sequential sampling and accumulation theory of preferential choice. it assumes that choice options are accepted or rejected if accumulators reach an upper or lower threshold, and that choice is deferred if these thresholds are not crossed by a fixed time. the proposed model can explain a wide range of findings regarding the determinants and consequences of choice deferral, including the relationship of deferral with choice option conflict, choice option desirability, choice option extremity, and the attraction and compromise effects.
infants learning words in a bilingual language environment face a number of difficulties that may alter the number and kinds of words learned early in life. the research described here investigates several aspects of word learning that may differ between bilinguals and monolinguals. using a dataset of 353 infants between the ages of 6 months and 7 years old, approximately half of which are bilingual, we examined three aspects of early word learning: 1) the rate of word learning, 2) the comparative structure of the english semantic network for monolingual and bilingual language learners and 3) how word acquisition in one language is affected by the other in bilingualchildren. our results suggest that bilingual language learning follows the same pattern of acquisition as monolingual language learning in almost every respect but one. though a model of language acquisition for monolingual children is a good predictor of bilingual acquisition, simulations based on this model under-predicts bilingual translational equivalents for many bilingual children. this suggests that learning a word in one language may facilitate its acquisition in a second language.
diagrams and other visual explanations are widely used in instruction, in media, in presentations, in public places, and more because they communicate effectively and improve learning and performance. they use space and elements in space to represent meanings more directly than purely symbolic words. can creating visual explanations also promote learning? in two studies, students were taught a stem phenomenon. half created visual explanations and half created verbal explanations; afterwards their knowledge was tested. those who had created visual explanations performed better in a post-test than those who created verbal explanations.  visual explanations provide a check for completeness and coherence as well as a platform for inference, notably from structure to process. 
we present the results of two studies of the use of spatial reference frames in speakers of 11 linguistic varieties. a series of mixed-models linear regression analyses of the responses to a referential communication task shows the significant factors in predicting frame use to be the participants’ first and second-language, their literacy, the local topography and population density. this suggests that language can play an irreducible role in the transmission of practices of spatial reference and that such practices may be diffused through language contact. however, in a recall memory experiment, only speakers of varieties with an egocentric linguistic bias preferred egocentric responses. both speakers of languages with a geocentric bias and speakers of varieties without a clear bias preferred geocentric responses. this unexpected finding is in line with a hypothetical mild innate pan-simian bias for geocentric cognition, which can be superseded by a learned egocentric bias.
effective communication entails the strategic presentation of evidence; good communicators present representative evidence to their listeners—evidence that is both consistent with the concept being communicated and also unlikely to support another concept a listener might consider. the present study examined whether preschool-age children effectively select evidence to manipulate others’ semantic knowledge, by testing how children choose evidence in a teaching or deception task. results indicate that preschoolers indeed effectively select evidence to meet specific communicative goals. when asked to teach others, children selected evidence that effectively spanned the concept of interest and avoided overly restrictive evidence; when asked to deceive others into believing a narrower concept, they selected evidence consistent with the overly restricted belief. thus, results support the idea that preschool children possess remarkable abilities to select the best evidence to manipulate what others believe.
previous theoretical work has proposed the use of markov chain monte carlo as a model of exploratory search in memory. in the current study we introduce such a model and evaluate it on a semantic network against human performance on the remote associates test (rat), a commonly used creativity metric. we find that a family of search models closely resembling the metropolis-hastings algorithm is capable of reproducing many of the response patterns evident when human participants are asked to report their intermediate guesses on a rat problem. in particular we find that when run our model produces the same response clustering patterns, local dependencies, undirected search trajectories, and low associative hierarchies witnessed in human responses. 
abstract concepts are characterized by their underlying structure rather than superficial features. variation in the examples used to teach abstract concepts can draw attention towards shared structure and away from superficial detail, but too much variation can inhibit learning. the present study tested the possibility that increasing attention to underlying structural relations could alleviate the latter difficulty and thereby increase the benefits of varied examples. participants were trained with either varied or similar examples of a mathematical concept, and were then tested on their ability to apply the concept to new cases. before training, some participants received pretraining aimed at increasing attention to the structural relations underlying the concept. the relative advantage of varied over similar examples was increased among participants who received the pretraining. thus, preparation that promotes attention to the relations underlying abstract concepts can increase the benefits of learning from varied examples.
the timing and order in which a set of events occur strongly influences whether people judge them to be causally related. but what do people think particular temporal patterns of events tell them about causal structure?  and how do they integrate multiple pieces of temporal evidence?  we present a behavioral experiment that explores human causal structure induction from multiple temporal patterns of observations. we compare two simple bayesian models that make no assumptions about delay lengths, assume that causes must precede their effects but differ in whether they assume simultaneous events can also be causally connected.  we find that participants' judgments are in line with the model that rules out simultaneous causation.  variants of this model that assume people update their beliefs conservatively provide a close fit to participants' judgments.  we discuss possible psychological bases for this conservative belief updating and how we plan to further explore how people learn about causal structure from time.
in a series of analyses over mega datasets, jones, johns, & recchia (2012) and johns et al. (2012) found that a measure of semantic distinctiveness (sd), which takes into account the semantic variability of a word’s contexts, provides a better fit to both visual and spoken word data than traditional measures, such as word frequency or raw context counts. the present study offers strong empirical support for this account’s extensibility to natural language. in a self-paced reading experiment, subjects were incidentally exposed to novel words as they rated short selections from articles, books, and newspapers. when novel words were encountered across distinct discourse contexts, subjects were both faster and more accurate at recognizing them than when they are seen in redundant contexts. however, learning across redundant contexts promoted the development of more stable semantic representations. these findings are predicted by a model of sd trained on the same materials as our subjects.
in studies of false recognition, subjects not only endorse items that they have never seen, but they also make subjective judgments that they remember experiencing them. this is a difficult problem for most dual process models of recognition memory, as they propose that false memories should be based on familiarity, not recollection. we present a new computational model of recollection based on the recognition through semantic synchronization model of johns, jones, & mewhort (2012), and fuzzy trace theory (brainerd & reyna, 2002). in addition to standard and false recognition, the model successfully explains multiple studies on both true and false recollection.  
theories of language have generally assumed that abstraction of the linguistic input is necessary in order to create higher-level representations of the workings of a language (i.e. a grammar). however, the importance of individual experiences with language has recently been emphasized by many, including usage-based theories (tomasello, 2003). based upon this, a formal exemplar model of language is described, which stores instances of sentences across a natural language corpus, using recent advances from models of semantic memory. this memory store is used to generate expectations about the future structure of sentences. the model can successfully capture a variety of different behavioral results. this work provides evidence that much of language processing may be bottom-up in nature, based upon the storage and retrieval of individual experiences with language.
this study examined the role of procedural memory in adult second language (l2) development. participants were trained on an artificial language under either explicit or implicit conditions. development in the l2 was assessed by grammar tests at two time points. measures of procedural memory were administered and were used to create high and low procedural groups. results revealed an advantage in l2 development for learners with high procedural memory when trained in the implicit condition. overall, this study suggests that procedural memory may be an important factor in adult l2 development but its role may differ under different learning contexts.
in this paper, we develop a novel formalization of fuzzy trace theory (ftt), a leading theory of qualitative risky decision-making. our model is the first to explicitly formalize and integrate the concepts of gist and the gist hierarchy.  domain knowledge constrains the space of possible decision problems, explaining which gists are chosen in which contexts.  we test our model against risky-choice framing and allais paradox problems, and manipulations of these problems.  our results also confirm new predictions regarding how problem manipulations can enhance or attenuate framing effects.
mathematics requires thinking but also pattern recognition. recent research indicates that perceptual learning (pl) interventions facilitate discovery of structure and recognition of patterns in mathematical domains, as assessed by tests of mathematical competence. here we sought direct evidence that a brief perceptual learning module (plm) produces changes in basic information extraction. accuracy and speed of undergraduate participants’ encoding of equations was assessed in a psychophysical task at pretest and delayed posttest. in between, the experimental group completed an algebraic transformations plm, which involved identifying valid transformations of equations. relative to controls, plm participants showed reliable changes in encoding equations, detectable psychophysically 24 hours later. encoding improvements were shown robustly by participants who were initially less proficient at algebra and were negligible for participants who were initially proficient. these results provide direct evidence for durable changes in information encoding produced by a pl intervention targeting a complex mathematical skill.
studies on covert attention usually monitor participants’ eye movements in order to prevent participants from moving their eyes away from a central fixation point. however, given our frequently dynamic attention behavior, keeping the gaze on a fixation point may be effortful and require attentional resources. if so, then trying to maintain fixation should interfere with covert attention orienting because both maintaining fixation and attention orienting require attentional resources. here we present two eye tracking experiments showing that the amount of attentional resources involved in maintaining fixation affects how an arrow orients covert attention. 
previous work shows that experience with the directionality of a writing system (e.g., left-to-right in english) affects constituent ordering during spoken language production. speakers of languages with left-to-right writing systems exhibit the same directionality bias in the sequential mentioning of objects when describing pictures with multiple objects. this tendency has been considered a general neuropsychological property. we present evidence inconsistent with this view.  two picture description experiments examined a highly bilingual population of speakers of spanish and yucatec maya in mexico. these speakers are literate in spanish, but less so or non-literate in yucatec (both left-to-right). when speaking spanish, participants exhibited a significant left-to-right bias, consistent with the neuropsychological hypothesis. however, when speaking yucatec, no such bias was observed. this suggests that the effects of writing systems on speech production are specific to the language associated with the writing system and thus not a general neuropsychological property.
formal models of categorization are psychological theories that try to describe the process of categorization in a lawful way, using the language of mathematics. their mathematical formulation makes it possible for the models to generate precise, quantitative predictions. sustain (love, medin & gureckis, 2004) is a powerful formal model of categorization that has been used to model a range of human experimental data, describing the process of categorization in terms of an adaptive clustering principle. love et al. (2004) suggested a possible application of the model in the field of object recognition and categorization. the present study explores this possibility, investigating at the same time the utility of using a formal model of categorization in a typical machine learning task. the image categorization performance of sustain on a well-known image set is compared with that of a linear support vector machine, confirming the capability of sustain to perform image categorization with a reasonable accuracy, even if at a rather high computational cost.
filtering words through our fingers as we type appears to be changing their meanings. on average, words typed with more letters from the right side of the qwerty keyboard are more positive in meaning than words typed with more letters from the left: this is the qwerty effect (jasmin & casasanto, 2012), which was shown previously across three languages. in five experiments, here we replicate the qwerty effect in a large corpus of english words, extend it to two new languages (portuguese and german), and show that the effect is mediated by space-valence associations encoded at the level of individual letters. finally, we show that qwerty appears to be influencing the names american parents give their children. together, these experiments demonstrate the generality of the qwerty effect, and inform our theories of how people’s bodily interactions with a cultural artifact can change the way they use language.
the current paper presents two act-r models of a delayed match-to sample task, and performs equivalence testing against human performance data to evaluate them.  success of an episodic model which avoids interference from previously encountered visual stimuli, and implements a serial search and rehearsal strategy lends insight into how individuals may encode, maintain and retrieve visual information.    
recollection of events can be improved with the use of active strategies. in the current study, we examined if naming could serve as a mnemonic device for both children and adults to remember shapes that they explored haptically. participants either named the shape during the encoding phase (naming condition), or they determined the “likability” of the shape (liking condition). during the retrieval phase, participants had to trace shapes again. here, the task was to name each shape and to determine whether they remember tracing it previously. results showed that memory performance was significantly better for adults than for children. more importantly, while there was no difference in memory performance between conditions, naming consistency was found to be the best individual predictor of correct recognition memory performance. findings are discussed in the context of the developmental similarity and differences between haptic and olfactory memory.
ideas are often generated from inspiration sources (e.g., prior experiences with the world, solutions to analogous problems). these sources may have benefits but also pitfalls (e.g., difficulty thinking of alternative approaches). in this paper, we investigate whether and how features of inspiration sources predict their impact on creative outcomes. in particular, we examine the popular but unevenly supported hypothesis that conceptually distant sources of inspiration provide the best in-sights for creative production. we test this hypothesis in the context of a web-based real-world creativity platform, while addressing key methodological issues in prior empirical studies (e.g., truncated time scale, low statistical power, problem variation). through a text analysis of many hundreds of concepts, we test whether greater conceptual distance between a concept's cited sources and the problem domain increases its probability of creative success (in this case, being shortlisted by an expert panel as a promising creative concept). we found that concepts that cite sources had greater success than those that did not cite sources of inspiration. however, in-creases in mean conceptual distance of sources actually decreased the probability of success, suggesting that far sources do not uniquely boost creativity and that an overreliance on far sources may even harm creativity. this negative effect of distance was robust across authors and different design problems on the platform. in light of these findings, we revisit theories of creative inspiration and general creative cognition.
can mathematical competence be measured by analyzing the patterns of pauses between written elements in the freehand copying of mathematical equations? twenty participants of varying levels of mathematical competence copied sets of equations and sequences of numbers on a graphics tablet.  the third quartile of pauses is an effective measure, because it re-flects the greater number of chunks and the longer time spent per chunk by novices as they processed the equations.  to compensate for individual differences in speeds of elementary operations and skill in writing basic mathematical symbols, variants on the measure were devised and tested. 
logically symmetrical predicates are frequently interpreted, by adults, asymmetrically.  adults prefer to say, for example, “my brother met the president,” over, “the president met my brother.”  this is because directional syntax contains figure and ground thematic roles, requiring the more important or prominent item be placed in the ground (second) position.  to date, little is known about the development of this asymmetric interpretation.  to address this, in experiments 1 and 2 we asked whether children prefer to relate figures to grounds when expressing spatial relations (e.g., “the bicycle is next to the building”) and similarity (e.g., “a zebra is like a horse”).  children as young as 4 showed emergent preference for this framing.  in experiment 3, we asked whether children ages 4 to 8 infer grounds to have higher skill and status in more specific comparisons (e.g., “the blicket cooks as well as the toma”).  we also asked whether including the modal can (e.g., “the blicket can play soccer like the toma”) or the comparative as well as (e.g., “the blicket plays soccer as well as the toma”) would strengthen this inference.  children ages four through eight tended to associate grounds with higher status and skill in comparisons containing the modal can, but only the older children seemed affected by the comparative as well as.  this work has implications for attempts to counter stereotypes: saying that girls do science as well as boys, for example, may imply that boys set the standard.
traditional parallel and serial descriptions of the visual search process are often inadequate when describing recent findings. accordingly, literature and computational models have evolved from a dichotomous parallel and serial explanation to an account of search efficiency that is graded and continuous. in our current experiment, we replicate findings showing concurrent incremental information processing, via auditory spoken language, mediates visual search and improves search efficiency (spivey et al., 2001; reali et al., 2006; chiu & spivey, 2012). novel to this study is the use of eye-tracking to investigate the role of language in mediating and improving strategies for visual search. we find evidence that search is best described as a purely parallel mechanism that immediately and rapidly integrates linguistic and visual information. this finding supports an interactive account of visual attention and spoken language.
lateralization touches virtually every function we think makes us human and interacts fundamentally with development. here we connect lateralized function to anatomical asymmetries, and connect those anatomical asymmetries to temporal asym- metries in development.our differential encoding (de) model (cipollini, hsiao, & cottrell, 2012; hsiao, cipollini, & cottrell, 2013; hsiao, shahbazi, & cottrell, 2008) shows that lateralization in visual processing of spatial frequencies can be explained by a postulated asymmetry in the spatial spread of connections within retinotopic visual cortex. here, we present three new modeling results supporting our previous conclusions. first, we show that our model results persist when trained on natural images, warped to match physical distortions of v1, showing that greater biological realism does not diminish our results. second, we show that the hypothesized anatomical asymmetry can emerge from normal development, due to 1) the known temporal asymmetry in developmental pruning, coupled with 2) known acuity changes. this results in the two hemispheres being trained with images of different spatial frequency con- tent. third, results from this developmental model suggest that the lh is not specialized for hsf processing; rather, the rh is specialized for lsf processing to the detriment of hsf processing.
how do people choose interventions to learn about a causal system? here, we tested two possibilities: an optimal information sampling strategy which aims to discriminate between multiple hypotheses, and a second strategy that aims to confirm individual hypotheses. we show in experiment 1 that individual behavior is best fit using a mixture of these two options. in a second experiment, we find that people are able to adaptively alter the strategies they use in response to their expected payoff in a particular task environment.
motion lines depict the path of a moving object, most popularly in comics. some have argued that motion lines depict the “streaks” in the visual system when a viewer tracks an object (burr, 2000). however, previous research has not used motion lines’ natural context of comics, has only depicted a limited number of actions (usually just running), and used only offline measurements like recall or ratings. here, we compared panels in comic strips with normal motion lines and those depicting either no lines or reversed, anomalous lines. in experiment 1, images with normal lines were faster than no lines, which were viewed faster than anomalous lines. in experiment 2, erps showed that the absence of normal lines elicited a posterior positivity distinct from the frontal positivity evoked by the presence of anomalous lines. these results suggest that motion lines aid in the comprehension of depicted events as conventionalized visual signs.
pointing is a foundational building block of human communication, but does it take the same form from one culture to the next? index finger pointing is often assumed to be universally privileged. use of non-manual pointing morphologies has been attested around the world but it has never been clear how central these variants are in the communities in which they occur. using a novel referential communication task, we investigated pointing preferences in two cultures: in the yupno of papua new guinea and in the us. our task prompted similar rates of pointing in both groups, but the yupno participants produced more non-manual pointing (nose- and head-pointing) than manual pointing, while the us participants stuck unwaveringly to index finger pointing. the motivation for these starkly contrasting patterns requires further investigation, but it is clear they constitute fundamentally different ways of carrying out one of our most distinctively human communicative acts. 
the systematic conjunction and disjunction fallacies seen in people’s probability judgments appear to show that people do not reason according to the rules of probability theory. in an experiment examining people’s judgments of the probability of different medical conditions, we find evidence againstthis view. in this experiment people’s probability judgments closely followed the fundamental ‘addition rule’ of probability theory. this close match to probability theory comes alongside frequent occurrence of the conjunction and disjunction fallacies in those same probability judgments. these results support a model where people reason about probability via probability theory but are subject to random variation or noise in the recall of items from memory. in this model the effect of random variation is cancelled out by the mathematical form of the addition rule, producing agreement with probability theory; however, noise is not cancelled out for conjunctive or disjunctive comparisons, producing conjunction and disjunction fallacy responses.
many models used to explain accuracy and response time in recognition memory have separated retrieval from decision: retrieval produces a value of memory strength that drives a decision process characterized by evidence that does not change until a decision is reached. cox and shiffrin (2012) have used an alternative dynamic approach that assumes these stages interact: as time passes after presentation of a test item, more information joins a probe of memory, changing the response from memory over time; the evidence that drives a decision thus changes from moment to moment. this model is consistent with many findings in recognition memory and has been used to explain puzzling "fluency" effects (cox, lewis, & shiffrin, 2013). here, we apply the model to two large-scale studies of accuracy and response time in recognition memory, showing that the model performs comparably with existing separate-stage models while affording richer conceptual interpretations of findings concerning word frequency effects and speed/accuracy trade-offs.
how do people remember individual values from a set of numbers? previous research has demonstrated seemingly conflicting findings. in some tasks, participants implicitly aggregate number sets (morris & masnick, in press), but in other tasks, participants recognized individual values, even for sets of eight, at levels greater than chance (cravalho, morris, was, & masnick, 2013). in the current paper, we investigated the possibility that these differences are driven by the strategies participants use to achieve different processing goals. the current paper describes three experiments in which participants were given the goal of correctly recognizing individual numbers presented in number sets of varying sizes (four, six, and eight). the results suggest that participants used individuation strategies in which they attended to diagnostic information while encoding numbers (e.g., the ones column in a set of numbers) and that we can explicitly individuate sets larger than four with the use of effective strategies.
a great deal of work in cognitive science has focused on how learning and memory can interact through proactive and retroactive interference effects. however, the mechanisms underlying these effects are still debated, and little is known regarding how interference affects learning in human development. this work addresses these questions by comparing children’s and adults’ performance on a new associative learning task in which information was either unique or overlapping across three phases. robust interference effects were found foroverlapping, but not unique information. additionally, proactive interference was comparable between age groups, while retroactive interference was more robust in child participants. results of two experiments suggest that interference is likely not driven primarily by differences in consolidation or active inhibitory processes, but may be inﬂuenced by conﬁgural encoding processes.
right-handers tend to associate “good” with the right side of space and “bad” with the left. this implicit association appears to arise from the way people perform actions, more or less fluently, with their right and left hands. here we tested whether observing manual actions performed with greater or lesser fluency can affect observers’ space-valence associations. in two experiments, we assigned one participant (the actor) to perform a bimanual fine motor task while another participant (the observer) watched. actors were assigned to wear a ski glove on either the right or left hand, which made performing the actions on this side of space disfluent. in experiment 1, observers stood behind the actors, sharing their spatial perspective. after motor training, both actors and observers tended to associate “good” with the side of the actors’ free hand and “bad” with the side of the gloved hand. to determine whether observers’ space-valence associations were computed from their own perspectives or the actors’, in experiment 2 we asked the observer to stand face-to-face with the actor, reversing their spatial perspectives. after motor training, both actors and observers associated “good” with the side of space where disfluent actions had occurred from their own egocentric spatial perspectives; if “good” was associated with the actor’s right-hand side it was likely to be associated with the observer’s left-hand side. results show that vicarious experiences of motor fluency can shape valence judgments, and that observers spontaneously encode the locations of fluent and disfluent actions in egocentric spatial coordinates.
learned categorical perception (cp) effects were assessed using three different measures and two sets of stimuli differing in discriminability, both of which varied on one category-relevant and one category-irrelevant dimension.  two different kinds of analysis produced patterns of results that depended on both of these variables and show that categorical perception effects are sensitive to variations in assessment task and stimulus discriminability. only the similarity-rating task produced evidence of between-category expansion effects, suggesting that participants used different strategies for subjective and objective tasks. generally, there was evidence that category training caused a decrease in the salience of category-irrelevant variation, but when the assessment task cued participants to category-irrelevant differences they were equally apt at identifying category-irrelevant variation as a control group. 
a rarely discussed but important issue in research on pragmatic inference is the choice of dependent measure for estimating the robustness of pragmatic inferences and their sensitivity to contextual manipulations. here we present the results from three studies exploring the effect of contextual manipulations on scalar implicature. in all three studies we manipulate the salient question under discussion and the perceptual availability of relevant set sizes. the studies differ only in the dependent measure used: exp. 1 uses truth judgements, exp. 2 uses word probability ratings, and exp. 3 uses a direct measure of sentence interpretation. we argue that the first two are effectively measures of production, and find they are sensitive to our contextual manipulations. in contrast the interpretation measure shows no effect of context. we argue that this methodologically troubling finding can be understood and predicted by using the framework of probabilistic pragmatics.
there is some evidence for both the hypothesis that discourseconnectors facilitate text comprehension and the hypothesisthat processing discourse connectors is highly incremental.less, however, is known about the way in which differentdiscourse connectors help comprehension and whether theycan elicit predictions of upcoming contents. in the presenterp studies on german and english we investigated theeffect of congruency and connector type (causal / concessive)on the prediction of a target referent (2x2 design). we found afronto-central positivity for the concessive connectorcompared to the causal condition and an n400-like effect forthe target noun phrase for incongruent compared to congruentconditions. our results suggest an effect of context-updatingat the connector (frontal positivity) and provide evidence forprediction of upcoming content based on the discourseconnector.
we propose a model to compute two measurements of semantic efficiency of verbs as action labels. it is based on the exploration of the specific structure of synonymy networks of verbs. we use these measurements to analyse and compare the semantic efficiency of [children/adults] productions in action labelling tasks, in french and mandarin. the combination of these two measurements leads to a generic score of semantic efficiency, skillex. assigned to participants of the approx protocol experiment, this score enables us to accurately classify them into children and adults categories, be they french or mandarin native speakers. 
when we reason about the physical world, we don't just think about physical facts. for example, in judging why an object exists, or belongs to a particular category, we often appeal to intentions, functions, and purpose (e.g., “knives exist for cutting”). such “teleological” thinking is common, but intuitively it has limits: for example, whether an object exists appears to depend only on the objective physical state of the world. in contrast, we present evidence that intentions can influence people’s judgments of whether an everyday object exists. participants read stories about an object being disassembled. controlling for the physical status of the object, people's judgments about whether the object existed were sensitive to the purpose guiding the disassembly. these results serve as a case study in the psychological power of intentions: apparently straightforward judgments about the physical world can be shaped by the state of the mental-world. 
numerous experiments show that space and musical pitch are closely linked in people's minds. however, the exact nature of space-pitch associations and their neuronal underpinnings are not well understood. in an fmri experiment we investigated different types of spatial representations that may underlie musical pitch. participants judged stimuli that varied in spatial height in both the visual and tactile modalities, as well as auditory stimuli that varied in pitch height. in order to distinguish between unimodal and multimodal spatial bases of musical pitch, we examined whether pitch activations were present in modality-specific (visual or tactile) versus multimodal (visual and tactile) regions active during spatial height processing. judgments of musical pitch were found to activate unimodal visual areas, suggesting that space-pitch associations may involve modality-specific spatial representations, supporting a key assumption of embodied theories of metaphorical mental representation.
the artificial grammar learning (agl) paradigm provides ameans to study the nature of syntactic processing and implicitsequence learning. with mere exposure and without performance feedback, human beings implicitly acquire knowledgeabout the structural regularities implemented by complex rulesystems. we investigate to which extent a generic cortical microcircuit model can support formally explicit symbolic computations, instantiated by the same grammars used in the human agl literature and how a functional network emerges, in a self-organized manner, from exposure to this type of data.we use a concrete implementation of an input-driven recurrentnetwork composed of noisy, spiking neurons, built accordingto the reservoir computing framework and dynamically shapedby a variety of synaptic and intrinsic plasticity mechanismsoperating concomitantly. we show that, when shaped by plasticity, these models are capable of acquiring the structure ofa simple grammar. when asked to judge string legality (in amanner similar to human subjects), the networks perform at aqualitatively comparable level.
in the experiment reported here, 30 participants made a lexical decision on 120 spoken words and 120 spoken non-words. the words had either an upward (e.g. ‘moon’) or downward (e.g. ‘sewer’) spatial association, or they were neutral in this respect (e.g. ‘letter’). participants made their lexical decisions by fixating a target located either above or below the centre of the screen, counterbalanced across participants. saccade launch latencies to targets in a congruent spatial location (e.g., hearing ‘moon’ and looking up to confirm that the stimulus is a word) were significantly faster than those to targets in an incongruent location (e.g., hearing ‘moon’ and looking down to confirm that it is a word). crucially, saccade launch latencies to incongruent target locations did not differ from those launched after hearing neutral words. our results extend earlier findings (dudschig et al., 2013) by showing that language-related spatial associations facilitate eye movements towards congruent locations rather than inhibiting eye movements towards incongruent locations.
much of the knowledge people acquire is structured: number systems, taxonomies; chemical structures. learning using the individual components that compose a structured theory may be difficultdue to the memory load induced by remembering the entities and their relations. though much research has demonstrated the effects of ordering on category learning, to our knowledge, none has been conducted on the learning of relational structures. in three experiments we explore the effects of different orderings in learning different relational structures, finding that ordering affects learning, only orderings that tend to eliminate simpler alternative structures are better, and that the complexity of learning appears to be driven by the number of relations, as opposed to the number of nodes. 
although comparison and explanation have typically been studied independently, recent work suggests connections between these processes. three experiments investigated effects of comparison and explanation on analogical problem solving. in experiment 1, explaining the solutions to two analogous stories increased spontaneous transfer to an analogical problem. in experiment 2, explaining a single story promoted analogical transfer, but only after receiving a hint that may have facilitated comparison. in experiment 3, irrelevant stories were interspersed among the two story analogs to block unprompted comparison; prompts to compare were effective, but prompts to explain were not. this pattern suggests that effects of explanation on analogical transfer may be greatest when combined with comparison. 
linguistic expressions indicating uncertainty of states of knowledge or beliefs, such as “possible” or “might suggest”, are usually dealt with in the psycholinguistic community under the heading of ‘verbal probabilities’. despite a remarkable level of quantitative and experimental rigor, studies dealing with this phenomenon suffer from several methodological shortcomings: the selection of items under scrutiny usually lacks empirical justification besides subjective preferences, the items are often investigated in isolation, i.e. without sufficient linguistic context and focus is typically on only few word classes, usually adjectives and adverbs. our study introduces a rigorous empirical, corpus-based criterion for the selection of relevant items, thus balancing the variety of word classes and, as a consequence, enlarging the lexical diversity dealt with in this area of research. we also collect preliminary evidence for the impact discourse context has on the properly adjusting verbal probabilities.
selective sustained attention (ssa) is vital for higher order cognition. although endogenous and exogenous factors influence ssa, assessment of the degree to which these factors influence performance and learning is often challenging. we report findings from the track-it task, a paradigm that aims to assess the contribution of endogenous and exogenous factors to ssa within the same task. behavioral accuracy and eye-tracking data on the track-it task were correlated with performance on a learning task. behavioral accuracy and fixations to distractors did not predict learning when exogenous factors supported ssa. in contrast, fixations to distractors were negatively correlated with learning when endogenous factors supported ssa. similarly, higher behavioral accuracy was correlated with greater learning when endogenous factors supported ssa. these findings suggest that although children showed equivalent levels of distractibility when exogenous and endogenous factors supported ssa, different conditions of the track-it task likely engaged different attentional control mechanisms.
using corpus-based methods inspired by recurrence quantification analysis, we investigate the patterns that shape coordination in dialogue, in particular during the process of language acquisition. we show that the turn-by-turn temporal development of conversation is a key factor influencing when and how interlocutors match each other’s linguistic representations. although there is continuity between child-adult and adult-adult dialogue with respect to alignment of semantic representations, our results show important differences regarding syntactic alignment in adjacent turns, with adults showing less cross-speaker syntactic matches than expected by chance.
in this paper we introduce an inductive bias for language acquisition under a view wherelearning of the various levels of linguistic structure takes place interactively. the bias encourages the learner to choose sound systems that lead to more "semantically coherent'' lexicons. we quantify this coherence using an intrinsic and unsupervised measure of predictiveness called "self-consistency." we found self-consistency to be optimal under the true phonemic inventory and the correct word segmentation in english and japanese.
the goal of the present effort was to revisit miller’s (1982) claim that audio-visual stimuli are processed by a coactive architecture. we replicated miller’s analysis and extended it using both group and individual level measures from systems factorial technology (sft; townsend & nozawa, 1995). similar to previous findings, some participants exhibited redundancy gain beyond that predicted by independent parallel processing.  however, the majority of participants performed no better than would be predicted by an independent parallel model, and some even performed worse than independent parallel. furthermore, the variation observed across individual participants suggests that individual level performance measures are at least as important as group measures for the robust interpretation of human information processing data.
what makes a good teacher, and how should we structure classrooms to promote effective teaching? this paper investigates the idea that a good teacher is a good communicator, using models of optimal pragmatic communication to explore the dynamics of classroom learning. the proposed model de- scribes teaching as choosing examples of a concept to present to students in order to maximize their information gain. under this model, the key challenge for the teacher is communicating to a heterogenous audience. a number of results emerge naturally, including decreases in performance with increases in class size and increases in performance based on tailoring instruction to groups of students based on prior knowledge or ability.
many natural language quantifiers are classically associated with a stringent binary semantics, and similarly categorical pragmatic enrichments. but much experimental data shows that intuitions about apropriateness of use seem to be more fuzzy and more subtle, yet highly regular nonetheless. to account for these gradient typicality judgements, i sketch a new probabilistic model of gricean speakers that incorporates a gradient notion of utterance alternatives. focusing on scalar quantifier some, the model is a proof of concept, against expressed views to the contrary, that typicality and scalar inferences can be treated on a par.
problem solving research is in need for re-thinking main questions. the purpose of this paper is a stock-taking of some of the identified problems, to discuss potential remedies for them, and to look for future perspectives. i see three areas for discussion: (1) what are the phenomena to be explained? (2) what methods should be used? what methodology is appropriate to the subject? (3) what is the progress in theory since the legendary work from newell and simon (1972)? what can we expect from new data sources? how can we relate data to theoretical assumptions?
it has been suggested that the origins of cognitive modernity in the middle/upper paleolithic following the appearance of anatomically modern humans was due to the onset of dual processing or contextual focus (cf), the ability to shift between different modes of thought: an explicit mode conducive to logical problem solving, and an implicit mode conducive to free-association and breaking out of a rut. mathematical and computational models of cf supported this hypothesis, showing that cf is conducive to making creative connections by placing concepts in new contexts. this paper proposes that cf was made possible by mutation of the foxp2 gene in the paleolithic. foxp2, once thought to be the “language gene”, turned out not to be uniquely associated with language. in its modern form foxp2 enabled fine-tuning of the neurological mechanisms underlying the capacity to shift between processing modes by varying the size of the activated region of memory.
creating consensus and facing the challenges of climate change requires effective climate communication. however, consensus about issues relating to climate science is unlikely to happen when there isn’t a clear public consensus about which name is more appropriate, “climate change,” or “global warming,” and what those terms mean. previous research has shown that perceptions of these terms varies, depending on factors such as the audience’s political affiliation. to investigate this further, we analyzed two corpora from partisan online news using a high dimensional semantic analysis. this study found that while there is substantial semantic overlap between the terms “climate change” and “global warming,” there is less overlap in the conservative media corpus. the results also show that there was a larger proportion of conservative articles that preferred to use “global warming” exclusively, whereas progressive articles tended to use “global warming” to supplement “climate change.”
we investigate the effects of problem schema type (complementary events versus independent events) on participants’ tendency to adopt probability matching or maximizing strategies across repeated decisions. these two general problem types were compared in an online study (n=300), using a between-subjects design. we also varied abstraction level of the problem story context, using abstract contexts, contexts involving physical randomizing devices, and “real-world” social/pragmatic contexts. participants made a binary choice on each of 20 trials, receiving trial-by-trial outcome feedback. maximization was consistently higher for independent events contexts than for complementary, while abstraction level of the context had no significant effect on the prevalence of maximizing behavior. the results support our hypothesis that people may find it especially difficult to discover the maximizing strategy for problems exemplifying the complementary-outcomes schema. in contrast, when the problem involves choosing between two distinct objects or entities (a common instantiation of the independent events schema) it seems to be easier to maximize, perhaps due to cueing of a pragmatic “pick the winner” schema.
recent studies of probabilistic reasoning have postulated general-purpose inference algorithms that can be used to answer arbitrary queries. these algorithms are memoryless, in the sense that each query is processed independently, without reuse of earlier computation. we argue that the brain operates in the setting of amortized inference, where numerous related queries must be answered (e.g., recognizing a scene from multiple viewpoints); in this setting, memoryless algorithms can be computationally wasteful. we propose a simple form of flexible reuse, according to which shared inferences are cached and composed together to answer new queries. we present experimental evidence that humans exploit this form of reuse: the answer to a complex query can be systematically predicted from a person's response to a simpler query if the simpler query was presented first and entails a sub-inference (i.e., a sub-component of the more complex query). people are also faster at answering a complex query when it is preceded by a sub-inference. our results suggest that the astonishing efficiency of human probabilistic reasoning may be supported by interactions between inference and memory.
in this paper, we demonstrate that people’s causal judgments are inextricably linked to counterfactuals. in our experiments, participants judge whether one billiard ball a caused another ball b to go through a gate. our counterfactual simulation model predicts that people arrive at their causal judgments by comparing what actually happened with the result of mentally simulating what would have happened in the relevant counterfactual world. we test our model against actualist theories of causation which aim to explain causation just in terms of what actually happened. our experimental stimuli contrast cases in which we hold constant what actually happened but vary the counterfactual outcome. in support of our model, we find that participants’ causal judgments differ drastically between such cases. people’s cause and prevention judgments increase with their subjective degree of belief that the counterfactual outcome would have been different from what actually happened.
the primitive elements of skill theory proposes a set of approximately 2000 primitive information processing elements (prims) (taatgen, 2013) that compose all cognitive acts by combining and recombining to produce learning and transfer. by this theory, learning is transfer and transfer results from learning as the primitive elements combine to form new elements based on task demands and these more complex elements are reused later in learning (thereby producing increase in skill) and repurposed by different tasks (thereby producing transfer). we illustrate prims in this paper by producing two models of the balance beam task (bbt) and of the take the best heuristic (ttb). although bbt and ttb do not, on the surface, possess much in common, when run in a transfer paradigm (ttb-to-bbt or bbt-to-ttb) each model harvests prims created by its predecessor, thereby demonstrating positive transfer.
we study analogical reasoning in adults using an eye tracking methodology. in previous experiments, we studied the time course of analogy-making, looking at proportion of looking times and transitions. the main purpose of the present experiment is to test whether adults would adapt their search strategies to the difficulty of the analogical problems (easy vs. difficult problems). difficult problems might have an impact on participants' visual strategies used by participants (bethell-fox et al., 1984) looking-time durations and the number of key item-to-item transitions confirmed differences between the two conditions. we discuss the results in terms of conceptions of analogical reasoning.
prior work has found that selective sustained attention (ssa) is related to young children’s task performance and to various indices of academic achievement (e.g., course grades, standardized test scores). however, experimental research demonstrating a link between learning and ssa is lacking. additionally, much of the existing work is not able to partial out variance in children’s learning performance due to individual difference factors. this work examines the putative relationship between ssa, measured as the proportion of time spent off-task, and young children’s learning outcomes by yoking measures of time off-task to immediate measures of learning, while controlling for the variance in children’s learning performance due to individual difference factors such as iq, working memory, processing speed, and inhibitory control. 
does language influence the production and perception of gestures? the metaphorical use of language in representing time is deeply interlinked with actions in space, such as gestures. in chinese, speakers can talk and gesture about time as if it were horizontal, sagittal, or vertical. in english, speakers rarely employ the vertical plane. two experiments showed that the verbal use of vertical spatial metaphors had an online influence on the production and perception of gestures by late chinese-english bilinguals. participants produced more vertical gestures when talking about time references by use of vertical spatial metaphors, e.g. ‘shàng-zhōu’ (literally: ‘above week’, meaning ‘last week’), and they preferred vertical gestures to horizontal gestures when perceiving time references with vertical spatial metaphors. gestures are not only shaped by the language specific conceptualisation, but are also sensitive to the changes in linguistic choices, both in production and perception.
optimal stopping problems require people to choose from a sequence of values, under the constraint that they cannot return to an earlier option once it is rejected. we study how people solve optimal stopping problems when the distribution of values they must choose from is not uniform, but is constructed to contain many high values or many low values. we present empirical evidence that people adapt to both sorts of environments, and make decisions consistent with using threshold-based models. we then fit a threshold model to our data, inferring the threshold people use, and finding they usually decrease their thresholds faster than is optimal as the sequence progresses. we also present empirical and model-based evidence that people generally do not adjust their thresholds on the basis of the values they see.
previous developmental research on pedagogy has focused on children’s inferences as learners. here we look at children’s inferences as teachers.  we explore the hypothesis that young children consider the goal of the learner and rationally provide evidence that is both informative and cost-efficient. given a toy with an ambiguous causal structure, children selectively performed costly actions to provide disambiguating evidence only when the learner wanted to know how the toy worked; when the learner only wanted to see the toy’s effects, children chose less costly actions. these results suggest that children flexibly modify their behaviors as teachers by considering what learners need to know.  
children are sensitive to whether informants provide sufficient information for accurate learning (gweon et al., 2011). do children think that informants should always provide as much information as possible? here we show that children consider other’s prior knowledge and the cost of information to decide how much information is appropriate. we showed children toys that had 20 identical buttons, three of which played music. given a choice between an informant who demonstrated all 20 buttons (exhaustive informant) or just the three that played music (selective informant), children preferred the exhaustive informant only when the learner was naïve about how many buttons worked and could be mislead by a selective demonstration (experiment 1). given an opportunity to teach themselves, children were more likely to provide exhaustive information when the learner did not know how many buttons worked on the toy (experiment 2). these results suggest that young children consider others’ prior knowledge to balance the cost and the benefit of information in learning from others and in teaching others. 
theories of how cognitive biases arise rely on heuristics that influence attention and reasoning. these heuristics serve as a post-hoc description of how attention and reasoning is weighted to produce the patterns of deviation in judgment. we are unaware of any process account of how these heuristics arise. in this article, we present several simulations of classic studies of the availability heuristic and describe how the availability heuristic arises through distributed symbolic representations and simple process interactions in an existing model of relational reasoning and concept development (discovery of relations by analogy; doumas, hummel, & sandhofer, 2008).
when people use mental imagery, how do they decide which images to generate? to answer this question, we explored how mental simulation should be used in the classic psychological task of determining if two images depict the same object in different orientations (shepard & metzler, 1971). through a rational analysis of mental rotation, we formalized four models and compared them to human performance. we found that three models based on previous hypotheses in the literature were unable to account for several aspects of human behavior. the fourth is based on the idea active sampling (e.g., gureckis & markant, 2012), which is a strategy of choosing actions that will provide the most information. this last model provides a plausible account of how people use mental rotation, where the other models do not. based on these results, we suggest that the question of “what to simulate?” is more difficult than has previously been assumed, and that an active learning approach holds promise for uncovering the answer.
when learning addition, children appear to perform a remarkable feat: as they practice counting out sums on their fingers, they discover more efficient strategies while avoiding conceptually flawed procedures. existing models that seek to explain how children discover good strategies while avoiding bad ones postulate metacognitive filters that reject faulty strategies. however, this leaves unexplained how the domain-specific knowledge required to evaluate a strategy might be acquired prior to addition being mastered. we introduce a biased exploration model, which demonstrates that new addition strategies can be discovered without invoking metacognitive filtering. this model provides a fit to data comparable to previous models, with the considerable advantage of avoiding an appeal to knowledge whose source is not itself explained. specifically, we fit the pattern of changes in strategy use over time as children learn addition, as well as the overall error rate and error types reported empirically. the model suggests that the critical element allowing strategy discovery may be prior learning, rather than metacognitive strategy evaluation. we close by offering several empirical predictions and propose that what others have called strategies might often be decomposable into elements that can be assembled on the fly as problem solving unfolds in real time.
duration discrimination is severely impaired when the duration markers are delivered from different sensory modalities (inter-modal) instead of from the same modality (intra-modal). the present study examined the brain activity related to this impairment using event-related potentials. durations were marked either by two auditory signals (aa) or by an auditory and a visual signal (av), and there were two levels of discrimination difficulty (easy and difficult). a negative component (contingent negative variation) which appeared between the two markers at fronto-central sites and is said to be related to time perception, was larger for aa than for av, and was not influenced by discrimination difficulty. a principal component analysis showed that the first and the third principal component captured differences in brain activity patterns between sensory modalities and difficulties, whereas the second principal component could reflect brain activity related to time perception in general, regardless of the modalities.
in most everyday decisions we learn about the outcomes of alternative courses of action through experience: a sampling process. current models of these decisions from experience do not explain how the sample outcomes are used to form a representation of the distribution of outcomes. we overcome this limitation by developing a new and simple model, the exemplar confusion (excon) model. in a novel experiment, the model predicted participants' choices and their knowledge of outcome probabilities, when choosing among multiple-outcome gambles in sampling and feedback versions of the task. the model also performed at least as well as other leading choice models when evaluated against benchmark data from the technion prediction tournament. our approach advances current understanding by proposing a psychological mechanism for how probability estimates arise rather than using estimates solely as inputs to choice models. 
we developed a novel and game like dual 2-back computerized task, gatekeeper, which we deployed online with 245 male and female participants ranging in age from 13 to 83 years. gatekeeper requires participants to remember only 4 items, so does not target memory capacity, but rather measures multitasking ability and interference control in working memory. participants were faster and more accurate with two-targets than one-target, and bayesian analysis supported a null effect of gender on accuracy, but accuracy did decrease with age. these results are consistent with the ability to divide attention and control proactive interference being equal for males and females but showing an age-related decline.
we consider how the information sources people use to test hypotheses change as the sparsity of the hypotheses – the proportion of items in the hypothesis space they include – changes. specifically, we focus on understanding how requests for positive and negative evidence, which have been shown to be sensitive to hypothesis sparsity (hendrickson, navarro, & perfors, in prep), are influenced by requests for specific in- stances, which show a positive bias and less sensitivity to sparsity (markant & gureckis, 2013). we find that people modify their information requests as a function of the sparsity of the hypotheses and they do so in this task primarily by by manipulating the rate of requesting positive and negative evidence. people were also most likely to select the information source that maximized the expected reduction in uncertainty across hypotheses.
are some landmark positions at intersections better for finding a return path than others? this study investigated whether there is a variation in the influence of a landmark on performance and decision times when finding a return path depending on its position at an intersection. a variation of this influence is expected depending on the type of verbalisation of spatial directions used. first, participants learned a path either with direction specific (turn left at or turn right at) or direction unspecific material (turn into direction of or turn in the opposite direction of). in this path the positions of the landmarks were varied systematically. secondly, participants had to find the return path of the learned route and their third task was to write down verbal route descriptions. an effect of the landmark position on finding the return path can be suggested, although it was barely insignificant, for direction specific and direction unspecific material. a significant influence on the accuracy of the information in the route descriptions depending on the position of a landmark and on the specificity of the spatial directions could be shown. the results are discussed in the context of current wayfinding and landmark research.
interlocutors are typically thought to keep track of information that is shared between speaker and listener (i.e., common ground) and information that is available only to the speaker (i.e., privileged ground). in this study, we investigated whether speakers take their interlocutor’s knowledge into account when choosing between definite articles (e.g., the) and indefinite articles (e.g., a) in the context of object reference. in experiment 1, we found that a surprisingly high number of subjects inappropriately use the definite article to refer to objects in privileged ground, suggesting that considering interlocutors’ mental states during language production is effortful and does not always come naturally. in experiments 2-6, we explored various factors that influence whether or not speakers accommodate the knowledge states of interlocutors.
when speakers use modified noun phrases (e.g. “the long book”), they provide information not only about a salient feature of a single item (that this book is long), but also about implicit contrasts with possible alternatives (books can vary by length: some may be short). we investigate the development of preschoolers’ ability to detect implicit contrasts from speakers’ use of adjectives and make inferences about category structure. in experiment 1, we found that adults and preschoolers can make contrast inferences from adjective use in a supportive frame, and this ability improves over the preschool years. in experiment 2, we reduced the cues to contrast and found that adults still inferred implied contrast from adjective use alone, but preschoolers did not. perhaps the issue for preschoolers was an inability to consider alternatives from explicit descriptions (e.g. bringing to mind “short” from hearing “long”). experiment 3 tested this hypothesis by reading preschoolers a book containing relevant opposite pairs immediately prior to the task. after reading the book, older 4-year-olds were able to make contrast inferences reliably, suggesting that increasing children’s access to lexical alternatives may boost their ability to make contrast inferences.
one distinctive feature of human intelligence is a high level of flexibility, that "there is no end to the kinds of problems human reason can deal with" (horgan & tienson, 1996). however, no theory has adequately explained such unique capacity. recently, evolutionary psychologists have confronted this challenge by building models that have the potential to generate human flexibility via interaction of modules and learning. the key idea is that our cognitive system can learn to self-assemble, out of our sophisticated adaptive toolbox, new mechanisms that solve novel problems. in this paper, i identify a serious information routing problem, “the nativist input problem”. it is, briefly, a crippling limitation to the range of contexts in which evolutionary psychology can handle information routing reliably. i argue that it undermines successful self-assembly required for these models to explain human flexibility, highlighting nativism as one of the most problematic commitments of evolutionary psychology.    
the bayesian program in cognitive science has been subject to criticism, due in part to puzzles about the role of rationality and approximation. while somewhat sympathetic with these concerns, i propose that a thoroughgoing boundedly rational analysis strategy can answer to some of them. through simulation results i illustrate the method by showing how one can retrodict recently reported results about particle filter models of categorization (sanborn et al., 2010). i also introduce new obstacles that surface once we take bounded rationality seriously. specifically, again through simulation, i show that the analysis of optimal sampling from vul et al. (2014) is interestingly complicated by the introduction of agents capable of metareasoning. under broad conditions, such agents outperform all uniform k-sampling agents. this motivates the computational study of boundedly rational metareasoning in its own right.
in the acquisition of skills requiring periodic body movements such as in cascade juggling, the establishment of stable body movements seems crucial. we investigated the processes of developing stable body movements in each of the three learning stages defined by the framework established by beek and van santvoord (1992). we focused on two types of stability: stability of the body’s physical center, representing global structure of body movements, and that of arm swing, representing local structure. the experimental results revealed that the skills for establishing local and global structures were acquired sequentially; in this case, first local and then global. in addition, the analysis of verbal reports suggested that stable body movements and conscious attention are mutually related.
kemler nelson (1984) reported that incidental training, relative to intentional training, increased the prevalence of overall similarity classification, supporting a non-deliberative account of overall similarity sorting. however, the analysis conducted by kemler nelson (1984) does not adequately distinguish between usage of an overall similarity classification strategy and single-attribute strategies. the current study replicates kemler nelson's (1984) experiment, seeking to test the original conclusions using a more rigorous analysis. the current study approximates the original experimental procedure, using almost identical stimuli and a longer, modified test phase. results replicate those found by kemler nelson (1984) when the original analysis is applied; however the model-based analysis suggest an overall similarity classification strategy is used rarely and that incidental training increases the prevalence of sub-optimal single-attribute strategies. these results imply that overall similarity classification may be more deliberative than previously thought.
past studies have employed a subjective rating/categorization methodology to investigate whether radicals, an example of sub-lexical visual information in chinese/kanji, contribute to computation of character/word meaning, with conflicting results. this study took an objective, corpus-based approach for the first time. specifically, we conducted a latent semantic analysis based on japanese newspaper text (experiment 1), and found that radical friends (kanji characters with the same radicals) appeared in more similar linguistic contexts than radical enemies (kanji characters that do not include the same radicals). in addition, we consulted a noun-verb predicate corpus extracted from japanese web texts (experiment 2), and showed that nouns including radical friends tended to take more similar predicates than nouns with radical enemies. these findings suggest that characters/words with similar meanings tend to share radicals in kanji, which may explain how children are able to efficiently learn to use the vast number of characters in chinese/japanese.
this study aimed to clarify the mechanism underlying episodic future thinking, which refers to the ability to generate prospective events in a specific time/location/context. given that episodic future thinking involves generating predictions in a plausible order from previous internal predictions, we hypothesized that knowledge of sequential prediction should underlie episodic future thinking. a parallel-distributed processing model was trained to predict the next event in the training sequence. after training, the model was allowed to use the acquired knowledge to repeatedly self-generate event sequences. the resultant event sequences captured the episodic future thinking of normal participants and that of neurological patients when the model was lesioned. moreover, the nature of knowledge acquired after training for sequential prediction of external events reflected that of episodic memory, schema-like knowledge and semantic memory, all of which have been found to contribute to episodic future thinking by past studies. 
bayesian models of cognition and behavior are particularly promising when they are used in reverse-engineering explanations: explanations that descend from the computational level of analysis to the algorithmic and implementation levels. unfortunately, it remains unclear exactly how bayesian models constrain and influence these lower levels of analysis. in this paper, we review and reject two widespread views of bayesian reverse-engineering, and propose an alternative view according to which bayesian models at the computational level impose pragmatic constraints that facilitate the generation of testable hypotheses at the algorithmic and implementation levels.
virtual models are increasingly employed in stem education to foster learning about spatial phenomena. however, the role of design and spatial ability in moderating performance are not yet well understood. we examined the effects of display fidelity (stereo vs. mono), interface location (colocated vs. displaced), and spatial ability on performance during a virtual molecule manipulation task. the results indicated a significant beneficial effect of providing stereo viewing on response time, while interface location had no effect. the effect of providing stereo on performance was moderated by spatial ability. notably, providing stereo did not benefit higher spatial ability participants, while those with lower spatial ability uniquely benefited from using the higher fidelity stereo display. 
humans explain and predict other agents’ behavior using mental state concepts, such as beliefs and desires. computational and developmental evidence suggest that such inferences are enabled by a principle of rational action: the expectation that agents act efficiently, within situational constraints, to achieve their goals. here we propose that the expectation of rational action is instantiated by a naïve utility calculus sensitive to both agent-constant and agent-specific aspects of costs and rewards associated with actions. we show that children can infer unobservable aspects of costs (differences in agents’ competence) from information about subjective differences in rewards (i.e., agents’ preferences) and vice versa.  moreover, children can design informative interventions on both objects and agents to infer unobservable constraints on agents’ actions. 
humans evaluate transgressors focusing on their intentions and the outcome. here we propose that, in addition to these factors, we also take into account the cost and reward of actions, supported by a fundamental inferential process we call a “naïve utility calculus.” because inferences about costs and rewards trade off, observers can infer that agents who incur higher costs place a higher value on acting.  this inference has implications for moral judgments.  our account predicts, somewhat paradoxically, that the higher the costs a perpetrator incurs in transgressing, the more harshly observers will judge him.  less paradoxically, the same principle holds for helpful actions: controlling for intention and outcome, more costly helpful actions will be given more credit. consistent with our framework, we find that adults and preschoolers make graded social evaluations guided by the costs of the actions.
we study inferences about social choices---choices that affect people besides the chooser. social choices depend on the relationships between the people involved: for example, whether they are friends, strangers, or enemies. we propose that these different social relationships correspond to different ways in which the chooser weights another person's utility relative to her own. we describe a probabilistic model of social reasoning that incorporates this notion of weighted utility, and evaluate it in an experiment in which participants made inferences about others'  social choices. the results support our probabilistic model and expose some of the assumptions that people tend to make when reasoning about social choices.
life in our social world depends on predicting and interpreting other people’s behavior. do such inferences always require us to explicitly represent people’s mental states, or do we sometimes bypass such mentalistic inferences and rely instead on cues from the environment? we provide evidence for such behaviorist thinking by testing judgments about agents’ decision-making under uncertainty, comparing agents who were knowledgeable about the quality of each decision option to agents who were ignorant. participants believed that even ignorant agents were most likely to choose optimally, both in explaining (experiment 1) and in predicting behavior (experiment 2), and assigned them greater responsibility when acting in an objectively optimal way (experiment 3).
other things being equal, people prefer simpler explanations to more complex ones. however, complex explanations often provide better fits to the observed data, and goodness-of-fit must therefore be traded off against simplicity to arrive at the most likely explanation. in three experiments, we examine how people negotiate this trade-off. as a case study, we investigate laypeople’s intuitions about curve-fitting in visually presented graphs, a domain with established quantitative criteria for trading off simplicity and goodness-of-fit. we examine whether people are well-calibrated to normative criteria, or whether they instead have an underfitting or overfitting bias (experiment 1), we test people’s intuitions in cases where simplicity and goodness-of-fit are no longer inversely correlated (experiment 2), and we directly measure judgments concerning the complexity and goodness-of-fit in a set of curves (experiment 3). to explain these findings, we posit a new heuristic: that the complexity of an explanation is used to estimate its goodness-of-fit to the data.
explanations frequently lead to predictions that we do not have the time or resources to fully assess or test, yet we must often decide between potential explanations with incomplete evidence. previous research has documented a latent scope bias, wherein explanations consistent with fewer predictions of unknown truth are preferred to those consistent with more such predictions. in the present studies, we evaluate an account of this bias in terms of inferred evidence: that people attempt to infer what would be observed if those predictions were tested, and then reason on the basis of this inferred evidence. we test several predictions of this account, including whether and how explanatory preferences depend on the reason why the truth of the effect is unknown (experiment 1) and on the base rates of the known and unknown effects (experiment 2), and what evidence people see as relevant to deciding between explanations (experiment 3). these results help to reveal the cognitive processes underlying latent scope biases and highlight boundary conditions on these effects.
the serial reaction time (srt) task, which measures how participants' keypress responses speed up as a repeating stimulus sequence is learned, is popular in implicit and motor learning research, and may help us understand the basic learning mechanisms underlying the acquisition of complex skills (e.g., riding a bike). however, complex action sequences are not simple stimulus-response chains, but rather require representing sequential context in order to learn. moreover, human actions are continuous, temporally-extended movements that are not fully measured in the discrete button presses of the srt task. using a novel movement adaptation of the srt task in which spatial locations are both stimuli and response options, participants were trained to move the mouse cursor to a continuous sequence of stimuli. we replicate the nissen & bullemer (1987) rt results with the trajectory srt paradigm and show sequential context effects--predictive bends in response trajectories--that promise to reveal cognitive processes underlying sequential action learning.
while the ubiquity and importance of nonliteral language are clear, people's ability to use and understand it remains a mystery. metaphor in particular has been studied extensively across many disciplines in cognitive science. one approach focuses on the pragmatic principles that listeners utilize to infer meaning from metaphorical utterances. while this approach has generated a number of insights about how people understand metaphor, to our knowledge there is no formal model showing that effects in metaphor understanding can arise from basic principles of communication. building upon recent advances in formal models of pragmatics, we describe a computational model that uses pragmatic reasoning to interpret metaphorical utterances. we conduct behavioral experiments to evaluate the model's performance and show that our model produces metaphorical interpretations that closely fit behavioral data. we discuss implications of the model for metaphor understanding, principles of communication, and formal models of language understanding.
as lifelong statistical learners, humans are remarkably sensitive to the unfolding of elements and events in their surroundings. in the present work, we examined the time-course of non-local dependency learning using a self-paced moving window display. we exposed participants to an artificial grammar of shape sequences and extracted processing times, or how long they viewed each shape, over the course of the experiment. on-line learning was quantified as the growing difference in viewing duration between predictable and predictive items. in other words, as participants learned, they processed predictable items increasingly faster. our results indicate that participants who make implicit predictions as they learn, and have their expectations met, achieve higher learning outcomes on an off-line post-test. potential links between these findings, obtained with novel stimuli in an experimental context, and the role of prediction in natural language comprehension are considered. 
we introduce a framework within evolutionary game theory for studying the distinction between objective and subjective rationality and apply it to the evolution of cooperation on 3-regular random graphs. in our simulations, agents evolve misrepresentations of objective reality that help them to cooperate and maintain higher social welfare in the prisoner's dilemma. these agents act rationally on their subjective representations of the world, but irrationally from the perspective of an external observer. we model misrepresentations as subjective perception of payoffs and a quasi-magical thinking bias to inference -- the former is more conducive to cooperation. this highlights the importance of internal representations, not just observed behavior, in evolutionary thought. our results provide support for the interface theory of perception and suggest that the individual's interface can serve not only that individual's aims, but also society as a whole, offering insight into social phenomena such as religion.
in cognitive modeling, it is routine to report a goodness-of-fit index (e.g., r² or rmse) between a putative model's predictions and an observed dataset. however, there exist no standard index values for what counts as “good” or “bad”, and most indices do not take into account the number of data points in an observed dataset. these limitations impair the interpretability of goodness-of-fit indices. we propose a generalized methodology, percentile analysis, which contextualizes goodness-of-fit measures in terms of performance that can be achieved by chance alone. a series of monte carlo simulations showed that the indices of randomized models systematically decrease as the number of data points to be fit increases, and that the relationship is nonlinear. we discuss the results of the simulation and how computational cognitive modelers can use them to place commonly used fit indices in context.
in this paper we explore the application of a novel data collection scheme for multi-sensory information to the question of whether different sensory domains tend to show similar relations between objects (along with some unique variance). our analyses—hierarchical clustering, mds mapping, and other comparisons between sensory domains—support the existence of common representational schemes for food items in the olfactory, taste, visual, and tactile domains. we further show that the similarity within different sensory domains is a predictor for rosch (1975) typicality measures. we also use the relative importance of sensory domains to predict the overall similarity between pairs of words, and compare subjective similarities to objective similarities based on physical sensory properties of the foods, showing a reasonable match. 
experimentation is at the core of research in cognitive science, yet observations can be expensive and time-consuming to acquire. a major interest of researchers is designing experiments that lead to maximal accumulation of information about the phenomenon under study with the fewest possible number of observations. in addressing this challenge, statisticians have developed adaptive design optimization methods. this paper introduces a hierarchical bayes extension of adaptive design optimization that provides a judicious way to exploit two complementary schemes of inference (with past and future data) to achieve even greater accuracy and efficiency in information gain. we demonstrate the method in a simulation experiment in the field of visual perception.
children who have difficulty with literacy development often experience pervasive and enduring trouble with spelling, even after receiving remedial instruction. our study tests a new approach to improving the spelling of these children. we designed an instructional program emphasizing the morphological structure of words, and directly contrast its benefits to instruction that focuses on word meanings, avoiding any discussion of morphology. the intervention was conducted with french-speaking children in grades 3 and 5 with varying literacy abilities. the results reveal that our intervention improved the spelling of all children in the study, but it was especially effective for children who displayed low spelling performance. moreover, low-performing spellers who received the morphology instruction showed a greater improvement in their spelling of suffixes than children who participated in the vocabulary instruction. our findings suggest that spelling instruction concentrated on morphological structure may be a powerful tool for improving children’s spelling ability. 
when agents violate norms, they are typically judged to be more of a cause of resulting outcomes. in this study, we suggest that norm violations also reduce the causality of other agents, a novel phenomenon we refer to as “causal supersession.” we propose and test a counterfactual reasoning model of this phenomenon in three experiments. experiment 1 shows that causal judgments of one actor are reduced when another actor violates moral norms, even when the outcome in question is neutral. experiment 2 shows that this causal supersession effect is dependent on a particular event structure, following a prediction of our counterfactual model. experiment 3 demonstrates that causal supersession can occur with violation of non-moral norms.
we studied the categorical perception on transitions between seven basic emotional facial expressions and explored the influencing factors. in experiment 1, participants performed a multiple-choice emotion labeling task while observing basic or morphed (blended between a pair of basic emotions) facial expressions. in experiment 2, other participants completed ab-x discrimination task. they observed pairs of images adjacent in a morphing continuum, and matched the test image to one of the pair. the results of experiment 1 revealed influence of emotional context, formed by the presented expressions, on perception of surprise, anger, disgust, and neutral face. the “categorical field” of morphed expressions includes not only the two relevant emotions (morphing basis) but a number of additional ones. based on the data of experiment 1, we selected the pairs of stimuli crossing the categorical boundary, and pairs falling within the category, to predict the discriminability obtained it the experiment 2. a generalized linear mixed model was fitted to the data. we show the main effect of within/between category pair, type of continuum and continuum/category interaction on the probability of correct discrimination. overall, our results showed the categorical perception, but its strength depends on particular pair of emotional categories.
the ability to reason about people's internal states, "theory of mind", has been shown to rely on a distinct and reliable group of brain regions. what triggers the specialization of these brain regions: hard-wired maturation or experience during development? here, we ask this question by examining the neural selectivity of theory of mind brain regions in adults with different developmental experience: late access to language. delayed access to language results in delayed development of theory of mind.  despite matched language competency and intelligence in adulthood, adults with delayed language experience (deaf adults born into non-signing households; don) show less selectivity in their theory of mind brain regions than adults with early language access (deaf adults born to signing households; dos),   in both verbal and nonverbal theory of mind tasks.  moreover,  individual differences in neural selectivity are predicted by  extent of early language experience, suggesting that the emergence of strong selectivity in these brain regions is influenced by experience in childhood. in social brain regions that become highly specialized by adulthood, the degree of specialization is determined by aspects of developmental history.
the idea that we think about relatively abstract domains (like time) in terms of more concrete domains (like space) but not vice versa can be traced to conceptual metaphor theory. experiments using verbal and/or visual stimuli suggest a deep ontological basis for space-time asymmetries. yet vision makes a privileged contribution to spatial processing raising questions about modality. recently, we found that in sound, time and space are mutually contagious, with a larger effect of time on space. here we examine the mutual effects of space, time, and pitch, a uniquely auditory attribute. if space is more abstract than time in sound, space should be more easily contaminated by pitch, while being less effective in contaminating it. while time and pitch were shown to be mutually contagious, pitch affected estimates of space but not vice versa. results overall suggest that in sound, time is not fundamentally more abstract than space.
the quantitative study of the role of communicative efficiency in language production and comprehension has gained increasing attention recently. however, in online production most investigation has focused on the phonetic/phonological level, leaving open the question of whether the communicative pressures involved extend to the syntactic level. i present a corpus study which investigates the omission of optional clause subjects in russian. if speakers communicate efficiently, then they are expected to preferentially omit elements that are more predictable, given preceding context. however, at the syntactic level this has only been directly demonstrated for omission of functional elements. the present study shows that even when other predictors of subject omission are taken into account, contextual predictability remains a significant predictor of whether an optional subject, a relatively complex syntactic constituent, is pronounced. this supports the hypothesis that the drive towards efficient communication is a general principle of language production.
the realization of prosody varies across speakers, accents, and speech conditions. listeners must navigate this variability to converge on consistent prosodic interpretations. we investigate whether listeners adapt to speaker-specific realization of prosody based on recent exposure and, if so, whether such adaptation is rapidly integrated with online pragmatic processing. we used the visual-world paradigm to investigate effects of prosodic cue reliability on the real-time interpretation of the construction “it looks like an x” pronounced either with (a) a h* pitch accent on the final noun, or (b) a contrastive l+h* pitch accent on looks and a rising boundary tone, a con- tour that can support a complex contrastive inference (e.g., it looks like a zebra...(but it is not)). eye-movements suggest that listeners process the l+h* on looks as an early cue to a contrastive interpretation. this effect, however, diminished when listeners had been exposed to the same speaker using the l+h* accent infelicitously. we argue that the process of prosodic interpretations is modulated by the reliability of prosodic cue values, enabling listeners to navigate variability in prosody across speakers and contexts.
long-distance dependencies in center-embedded recursion are among the most typical but also most difficult structures in human language (corballis, 2007; hauser, chomsky, & fitch, 2002). concerning the impact of the learning sample on grasping object-action relations, there are two opposing arguments: more is better vs. fewer is better (maguire, hirsh-pasek, golinkoff, & brandone, 2008). the former theory assumes that a large number of different exemplars facilitates learning (gentner, 2003), while the latter theory suggests that a more restricted set of unique exemplars with repetitions advances the learning of these patterns (casasola, 2005; kersten & smith, 2002). in the current study, we designed a grammaticality-judgment task and test both theories using an artificial grammar learning paradigm. we found that when participants were trained on fewer unique exemplars, but with repetitions, they could still perform significantly better than at chance level. moreover, when the few unique exemplars were repeated for an unequal number of times, their performance was boosted to a higher level. in line with the fewer is better theory, our findings point to a repetition effect and frequency distribution effect in processing hierarchical center-embedded recursion.
one-shot learning -- the human ability to learn a new concept from just one or a few examples -- poses a challenge to traditional learning algorithms, although  approaches based on hierarchical bayesian models and compositional representations have been making headway. this paper investigates how children and adults readily learn the spoken form of new words from one example -- recognizing arbitrary instances of a novel phonological sequence, and excluding non-instances, regardless of speaker identity and acoustic variability. this is an essential step on the way to learning a word's meaning and learning to use it, and we develop a hierarchical bayesian acoustic model that can learn spoken words from one example, utilizing compositions of phoneme-like units that are the product of unsupervised learning. we compare people and computational models on one-shot classification and generation tasks with novel japanese words, finding that the learned units play an important role in achieving good performance.
in philosophy of science, neo-mechanists argue that explanations are only successful when formulated in terms of the behaviors of discrete decomposable components that constitute the system of interest. this approach to explanation implicitly denies the significance of non-linear interactions in structuring the behavior of complex cognitive systems. recently, neo-mechanists have claimed that jas kelso and colleagues have begun to favor neo-mechanistic explanations of neuroscientific phenomena; particularly in the application of the neural field model to rhythmic coordination behaviors. we will argue that this view is the result of a failure to understand dynamic systems explanations and the general structure of dynamic systems research. further, we argue that the explanations cited are in fact not neo-mechanistic explanations. in this paper, we will show that these neo-mechanists have misunderstood the work by kelso and colleagues, which blunts the force of one of their arguments.
perceptual tools such as telescopes allow the application of robust internal perceptual systems to apply beyond the range of their unadorned capacity. this paper explores how reasoning over culturally provided representations enables the perception of conceptually distant structures. in particular, this paper examines the behavior of typical adults estimating the position of large numbers (1 thousand to 1 billion) on a number line. participants—even those who closely match linear placement—show discontinuities in placement in the immediate vicinity of 1 million. this pattern was predicted by a theoretical account in which linear behavior across many orders of magnitude is achieved through highly linear patterns of placement on smaller lines that are recycled and scaled to larger numerosities.  just as the telescope allows perception of the imperceptibly distant, reasoning processes over the natural numbers appear to allow intrinsically limited magnitude-perception systems to apply (with distortion) to much larger scales.
the question of whether grammaticality is a binary categorical or a gradient property has been the subject of ongoing debate in linguistics and psychology for many years. linguists have tended to use constructed examples to test speakers’ judgements on specific sorts of constraint violation. we applied machine translation to randomly selected subsets of the british national corpus (bnc) to generate a large test set which contains well-formed english source sentences, and sentences that exhibit a wide variety of grammatical infelicities. we tested a large number of speakers through (filtered) crowd sourcing, with three distinct modes of classification, one binary and two ordered scales. we found a high degree of correlation in mean judgements for sentences across the three classification tasks. we also did two visual image classification tasks to obtain benchmarks for binary and gradient judgement patterns, respectively. finally, we did a second crowd source experiment on 100 randomly selected linguistic textbook example sentences. the sentence judgement distributions for individual speakers strongly resemble the gradience benchmark pattern. this evidence suggests that speakers represent grammatical well-formedness as a gradient property.
can a person be identified uniquely by some feature of their neural activity, as they can be by fingerprints?  if so, 1) what would those features be like and 2) are existing computational methods sufficient to extract them?  here, we explore these questions by coordinating psychophysiological and machine learning approaches.  we begin with the proposition that one unique feature of individual cognition is the detailed network of concepts, and relationships between concepts, that are present in each individual’s semantic memory.  we then demonstrate that we are able to accurately classify individual unlabeled brain activity—in the form of event-related potentials (erps) elicited during a task that probes semantic memory—to the individual it belongs to with several pattern classifiers.  these results demonstrate that it is possible to identify individuals on the basis of unique features of their brain activity.  biometric applications are discussed.
episodic memory formation is associated with large-scale neuronal activity distributed across the cortex. decades of neuroimaging and patient lesion studies demonstrated the correlation between the roles of specific brain structures in episodic memory retrieval. distributed, coordinated and synchronized activities across brain regions have also been investigated, however, neuronal mechanisms based on effective connectivity underlying the coordination of this anatomically distributed information processing into introspectively coherent cognition have remain largely unknown. here we investigate the information flow network of the human brain during episodic memory retrieval. we have estimated local oscillation amplitudes and asymmetric inter-areal synchronization from eeg recordings in individual cortical anatomy by using source reconstruction techniques and effective connectivity method during episodic memory retrieval. the strength and spectro-anatomical patterns of these inter-areal interactions in sub-second time-scales reveals that the episodic memory retrieval involves increase of information flow and densely interconnected networks between the prefrontal cortex, the medial temporal lobe, and some subregions of the parietal cortex. in this network, interestingly, the sfg acted as a hub, globally interconnected across broad brain regions.
culture, there are similarities in color-odor associations. these associations are forms of crossmodal correspondences. recently, there has been discussion about the extent to which these correspondences arise for structural reasons (e.g., an inherent mapping between color and odor), statistical reasons (e.g., covariance in experience), and/or semantically-mediated reasons (e.g., stemming from language). the present study probed this question by testing color-odor correspondences in 6 different cultural groups (dutch, dutch residing-chinese, german, malay, malaysian-chinese, and us residents), using the same set of 14 odors and asking participants to make congruent and incongruent color choices for each odor. we found consistent patterns in color choices for each odor within each culture, and variation in the patterns of color-odor associations across cultures. thus culture plays a role in color-odor crossmodal associations, which likely arise, at least in part, through experience.
we explore a previously undescribed regularity in language: a bias for longer words to map to relatively more complex meanings. while theories of communication make the more general prediction that longer utterances should be associated with more complex meanings, this prediction has not yet been explored at the level of words. through norming and experimental studies, we find evidence in support of a complexity bias in word meanings. we conclude by discussing hypotheses about the nature of this bias.
research in the field of spatial cognition has advocated a frame of reference (for) -based cognitive representation system to account for human’s spatial reasoning and navigation capacities. it has been argued that such mental models may also contribute to the underlying mechanisms of theory of mind (tom). in the present study, we investigated how people made rapid judgments about the number of visible objects from their own perspectives (egocentric frame of reference, efor) and from others’ perspectives (intrinsic frame of reference, ifor). we examined both behavioral and eye tracking responses, and the results suggest that a for-based representation system promotes the efficiency and flexibility of tom functions. our findings support the notion of a possible conceptual link between spatial and social cognitive processes.
we model the performance of children on the goswami and brown (1990) analogy task, paying close attention to the distribution of errors children made on the task. this distribution follows a very particular pattern which, as we show, may be simulated by assuming a lack of development in the richness of children’s concepts of physical causation. this modeling is done using the hybrid cognitive architecture clarion, and a method of representing structured knowledge within clarion’s dual-process system.
manipulatives are commonly used to provide concrete bases for abstract mathematical concepts. however, it is unclear when concrete experiences benefit abstract thinking. we investigated whether understanding a manipulative’s mechanism would affect mathematical use and understanding. participants completed a robotics task that could be solved with either mathematical or non-mathematical strategies. participants with higher mechanistic understanding were more likely to utilize complex mathematical strategies during the task, and understood the mathematical relationships within the robot better than participants with lower mechanistic understanding. the study provides evidence for a relationship between mechanistic and mathematical understanding, suggesting that mechanistic manipulatives, upon which mathematics can be applied, may foster mathematical understanding. 
holistic processing is an expertise marker in visual perception. here we tested participants’ perception of cantonese syllables through composite paradigm commonly used for measuring holistic processing in vision research. we found that participants were more holistic in processing syllable initials than finals, possibly because initials are shorter and more easily combined with neighboring segments. more importantly, experts’ perception of syllable initials was strongly affected by finals (i.e., holistic processing), even when the initials were separated or disconnected from finals; whereas in novices, holistic processing gradually decreased with segment separation and disconnection. as for syllable final perception, experts were strongly influenced by initials, yet not when the segments were separated/disconnected. in contrast, novices showed little holistic processing in all conditions. these results showed that experts’ perception of syllable parts were more influenced by neighboring segments, suggesting that holistic processing may also be an expertise marker in auditory perception.
while relational reasoning has been described as a process at the heart of human cognition, the degree to which relational representations can be primed remains an open debate. this paper will present a category-learning experiment that shows that the learning of spatial relations (above and below) can be primed using a subtle visuospatial stimulus that may capture exogenous attention to produce saccades. 
psychopathic individuals possess a deficit in emotion-processing that interferes with their ability to perceive emotional expression in others. participants varying in “subclinical psychopathy” (i.e., psychopathic characteristics below the cutoff for psychopathy) categorized the emotional prosody in semantically neutral words and sentences representing five emotion categories (happy, sad, angry, fear, and disgust). word-length stimuli were predicted to be perceived with greater ambiguity than the sentence-length stimuli due to the duration difference between the two kinds of stimuli, with the difference between the stimuli  predicted to be larger for participants with more psychopathic characteristics. participants with more psychopathic characteristics and participants with fewer psychopathic characteristics were equally good at identifying the emotion in sentence-length stimuli. however, the participants with more psychopathic characteristics were less accurate at identifying emotion in word-length stimuli than participants with fewer psychopathic characteristics.
we present a computational model of mental rotation and shape comparison. the model posits that spatial abstraction, in which spatial details are removed to simplify a representation, is a key skill underlying spatial ability. shapes are represented as collections of two-dimensional parts, and abstraction is applied by merging parts or ignoring certain part features. using the model, we simulate a classic mental rotation experiment, demonstrating how abstraction explains the study’s key finding. finally, we compare the part-based approach to a previous edge-based approach, demonstrating that the current approach better explains human shape comparisons.
people frequently reason about causal relationships and variables that cannot be directly observed. this paper presents results from an experiment in which participants used statistical information to make judgments about the number and base rates of hidden causes, as well as the forms of causal relationships in which those causes participated. our data allow us to evaluate several models of hidden cause discovery, and reveal that people have different expectations about the forms of causal relationships than recent theories predict.
does gesturing help speakers find the right words? according to several theories of speech-gesture relationships, iconic gestures should facilitate speech production, but beat gestures should not. here we tested the effects of gesturing on word production in two experiments. participants produced low-frequency words from their definitions while instructed to perform beat gestures, iconic gestures, or while not given any instructions about gesturing (baseline condition). compared to baseline, participants were faster to produce the target words while performing beat gestures, bimanually or with their left hand alone, but they were slower to produce the target words when instructed to perform iconic gestures. results provide the first evidence that beat gestures can help speakers produce words. this benefit may arise from the fact that gestures are motor actions, rather than from any special properties of gestures, per se.
delay discounting refers to decision makers’ tendency to treat immediately consumable goods as more valuable than those only available after some delay.  previous work has focused on a seemingly irrational feature of these preferences: the systematic tendency to exhibit more patience when consequences are far in the future but less patience about those same, identical rewards as time passes.  one explanation for delay discounting itself appeals to the risk implicitly associated with delayed rewards.  the current study investigates whether the implicit risk hypothesis is capable of explaining the seemingly irrational shifts in patience by having participants make subjective risk judgments regarding a variety of real-world scenarios.  to reduce the possibility of task demands, participants judged hazard rates rather than survival rates.  results suggest that the seemingly irrational shifts in patience are quite reasonable once participants’ beliefs about the relationship between delay and risk are taken into account.
gaze cues quickly orient attention, but language can affect the extent to which we follow these cues (macdonald & tatler, 2013). we investigated how reliability of language and gaze cues affect attention. participants, provided with gaze and verbal cues, selected one of two potential targets and received immediate feedback. different combinations of gaze and language reliabilities (50%, 80%, 100%) were used across nine sessions. the most reliable cue available informed participants’ decisions. language was favoured when reliability was equal and cues incongruent. when language cues were 100% reliable, incongruent gaze cues had a larger detrimental effect on performance when they were 80% reliable compared to 50%. when gaze cues were 100% reliable, there was an overall detrimental effect of unreliable language, with performance slower when language was 50% reliable compared to 80%. we conclude that language cues are favoured and cause disruption when unreliable, even when superfluous to the task.
even infants expect agents to act rationally in pursuit of their goals.  however, little research has looked at whether young children expect other agents to learn rationally. in the current study, we investigated 4.5- to 6-year-olds’ reasoning about another agent’s beliefs after the agent observed a sample drawn randomly or selectively from a population. we found that those children who could correctly track both the true state of the world and the other agent’s initial beliefs expected the other agent to learn rationally from the data. critically, this inference depended upon but could not be reduced to either the child’s own understanding of the world, or the child’s own inferences from the sampling process, suggesting that the ability to integrate these component processes underlies a developing understanding of the way in which evidence informs others’ beliefs.
this paper advocates a re-introduction of the notion of cyborgin order to acquire a new perspective on studies concerning thedevelopment of human cognition in highly technological environments.in particular, we will show how the notion of cyborgproperly engages cognitive issues that have a powerful resonanceespecially as far as social cognition is concerned, andmay consequently provide a new tool for tackling the emergentsafety issues concerning sociality mediated by the internet, andthe moral panic occasionally surrounding it.
the aim of this paper is to connect studies in cognitive nicheswith the diffusion of high-technologies, cyborgs and robots, soto obtain a new framework for analyzing some dilemmas offuture technological developments. digital technologies dramaticallyboosted the niche constructing dynamics by allowingthe construction of new informational environments andby the introduction of synthetic-minds that are able to carryon niche construction and maintenance activities side-to-sidewith human beings. cognitive niches, structured to ease theenvironmental selective pressure, may progressively degeneratecausing an increase in selective pressure and hence a reductionin welfare for the individuals: yet, when the failure iscaused exactly by what was meant to benefit the population,and when the reversal of niche is (or seems to be) unfeasible,it is possible to individuate a “degenerative niche.
existing discussions of polysemy describe the relations that extended senses may have to the most central sense of a word, but they do not explain in more detail how particular senses are generated for a given word.  we propose that extended senses are initially built on the salient features of referents of core senses (and further senses may be generated from those). we provide evidence for the role of salient features of core senses in generating extended senses through three studies. these studies use speakers of english and chinese, historically unrelated languages. 
what is the relation been spatial language and cognition? across speech communities, linguistic preferences for particular spatial frames of reference (for) predict non-linguistic spatial reasoning strategies. this has been taken to imply a powerful influence of language on reasoning, but extra-linguistic factors may also matter. we present evidence from a bilingual community in juchitán, mexico, where the two languages contrast in how they encode space. in our spatial reasoning task, the population overall showed a mixed profile of for use. this naturally occurring variability provided a laboratory for asking, at a fine-grained level, what factors predict individuals’ spatial reasoning. contrary to suggestions in the literature, we found no effects of language dominance or of the language used for the task. instead, reliance on an egocentric strategy for the non-linguistic task was predicted by mastery of egocentric spatial vocabulary. these results delimit the influence of language on spatial reasoning. 
mathematical cognition, paragon of abstraction, is marked by systematic associations between number and space, often described as “mental number lines.” in three experiments, we demonstrate a novel effect: a sagittal (back-to-front) number line for negative and positive integers. in a paradigm requiring full-body movements, participants judged numerical magnitude (exp. 1-2) and parity (exp. 3). across all three experiments, participants associated numerical magnitude with locations in front of and behind the body. responses to negative integers were faster when moving backward than forward; responses to positive integers, faster forward than backward. this sagittal number line appears to require the involvement of negative numbers (exp. 1-2) and is most pronounced when judging magnitude (exp. 3). in sum, reasoning about integers induces systematic dispositions to act along the sagittal axis. such dispositions may reflect our mathematical habitus, habits of action and thought that reflect and enact our conceptual systems.
in science, technology, engineering, and mathematics (stem) education, problem solving tends to be highly procedural, and these procedures are typically taught with general instructional text and specific worked examples. subgoal labels have been used in worked examples to help learners understand the procedure being demonstrated and improve problem solving performance. the effect of subgoal labels in instructional text, however, has not been explored. the present study examined the efficacy of subgoal labeled instructional text and worked examples for programming education. the results show that learners who received subgoal labels in both the text and example are able to solve novel problems better than those who do not. subgoal labels in the text appear to have a different effect, rather than an additive effect, on learners than subgoal labels in the example. specifically, subgoal labels in text appear to help the learner articulate the procedure, and subgoal labels in the example appear to help the learner apply the procedure. furthermore, having subgoal labels in both types of instruction might help learners integrate the information from those sources better. 
the potential information gained from asking a question and one’s uncertainty about the answer to that question are not always the same. for example, given a coin that one believes to be fair, the uncertainty a person has about the outcome of flipping that coin is high, but either outcome is unlikely to make them believe that the coin is biased (i.e., the “information gain” of that observation is low). in the present paper we show that people use a simple form of predictive uncertainty to guide their information sampling decisions, a strategy which is often equivalent to maximizing information gain, but is less efficient in environments where potential queries vary in their reliability. we conclude that a potentially powerful driver of human information gathering may be the inability to predict what will happen as a result of an action or query.
colloquially, episodic memory is described as "the memory of personally experienced events". here we ask how episodic memory should be characterized in order to be validated as a natural kind. we propose to conceive of episodic memory as a knowledge-like state that is identified with an experientially based mnemonic representation of an episode. we discuss selected experimental results that provide exemplary evidence for uniform causal mechanisms underlying the properties of episodic memory and argue that episodic memory is a natural kind. the argumentation proceeds along two cornerstones: first, empirical results support the claim that the principal anatomical substrate of episodic memory is the hippocampus. second, we can pin down causal mechanisms onto neural activities in the hippocampus to explain the psychological states and processes constituting episodic memory.
based in current debates in aesthetics, we examined whether people’s beliefs match philosophers’ arguments that an original painting or carved sculpture possesses a privileged nature when compared with originals in other types of art. we tested whether participants believe the destruction of an original art piece has different consequences on the ability to experience that piece if the art is visual, literary, or musical (experiment 1). in experiment 2 we explored how different forms of destruction varied whether people believe an art piece still exists and the perceived quality of an experience with the piece. in summary, we demonstrated that people have a more lax view of how art can be experienced than is assumed by most philosophers, but share an intuition that the original form of a work of visual art has a unique nature.
in conversation, speakers are likely to refer to the same objects more than once. these repeated references are reduced with respect to their initial counterparts, both in speech and gestures. in this paper we investigate the effect of cognitive load on the reduction of multimodal referring expressions. we report an experiment in which native speakers of dutch engaged in a director-matcher task where repeated references were elicited, and a time constraint was imposed in order to increase the load. our results show that articulatory, lexical, semantic, and gestural reduction took place irrespective of the cognitive demands. nevertheless, we found that cognitive load moderated the extent to which these utterances were reduced, with reduction being less pronounced for speakers experiencing higher load. a subsequent perception experiment revealed that speakers with an increased load produced referring expressions that proved more informative to naïve listeners.
this study presents evidence in favor of a cognitive primitives hypothesis for processing fraction magnitudes. this account holds that humans have perceptual access to fractional magnitudes and that this may be used to support symbolic fraction knowledge. in speeded cross-format comparisons, participants picked the larger of two stimuli, which were either symbolic fractions or nonsymbolic ratios composed of pairs of dot arrays or pairs of circles. participants demonstrated distance effects across formats, demonstrating that they could compare analog fractional magnitudes independently of the particular formats in which they were presented. these results pose a challenge to innate constraints accounts that argue that human cortical structures are ill-suited for processing fractions. these results may have important implications both for theorizing about the nature of human number sense and for optimizing instruction of fractional concepts.
the study of second language acquisition (sla) is often hindered by substantial variability in the background of learners, their learning process and the input they receive. this diversity often makes it difficult to isolate specific learning factors and study their impact on l2 development. we present a computational study of sla as an alternative methodological approach. by applying a usage-based computational model of construction learning on bilingual (german and english) input data, we analyze various learning variables in isolation. in particular, we investigate three factors: ratio between the amount of l1 and l2 input, age of l2 onset, and l2 frequency distribution. our results are in line with experimental findings on the facilitatory effect of lower l1/l2 ratio and balanced l2 frequency distribution. we found no negative effect of later age of l2 onset on proficiency, which might be due to positive cross-linguistic transfer between german and english constructions.
contemporary theories of language production disagree about the cognitive mechanisms involved in the production of past tense forms of regular and irregular verbs. two models compete to explain this process: dual-route and single-route. the present study tests these models using previously reported methods of production and naturalness rating of the past tense forms of novel verbs. overall, participants show a preference for regular verb forms, both in production and rating tasks. however, presentation of a novel verb in an irregular semantic context cancels out that preference. previous findings were not replicated, and inconclusive results show some support for both models.
the flexibility and unbounded expressivity of our linguistic abilities is unparalleled in the biological world. explaining how children acquire this fundamental aspect of human language is a key challenge for cognitive science. a recent corpus study by yang (2013) has cast doubt on the lexical specificity of children’s productivity, as hypothesized by usage-based approaches. focusing on determiner-noun combinations, he suggests that children possess an adult-like determiner category. in this paper, we show that yang’s results may depend too heavily on an idealized notion of frequency distributions. we propose that these issues may be resolved by sidestepping sampling considerations and directly modeling children’s actual language processing. we therefore evaluate the abilities of two computational models to capture children's productions of determiner-noun combinations. the first model implements a probabilistic context-free grammar, which acquires statistical information incrementally. a second model, the chunk-based learner (cbl), provides a simple instantiation of item-based learning. cbl outperforms the rule-based model, successfully producing the vast majority of the determiner-noun combinations in a dense corpus of child speech. the results thus suggest that the case against lexical specificity in children’s early determiner-noun sequences may be overstated.
changes in language processing and production accompanying aging have most commonly been interpreted as evidence for age-related cognitive decline. a recent proposal (ramscar et al., 2014) challenges that interpretation, asserting instead that such changes emerge as a consequence of—and in order to support—processes of lifelong learning like continued vocabulary growth. under this account, the mechanisms of language processing and production do not deteriorate with age, but rather the computational complexity of the underlying information processing task increases as more data is observed over the lifespan. the current study examines whether spoken language displays properties consistent with the notion of lifelong learning by examining the relationship between age, within-speaker lexical diversity, and between-speaker lexical overlap in a conversational speech corpus, switchboard i. we find older speakers exhibit more diverse lexicons, and that they share fewer words with interlocutors than younger speakers. 
the typical structure of equations influences how we learn the meaning of the equal sign.  previous studies have shown that as students gain experience with addition problems, they actually perform worse on certain problems, before eventually improving.  we seek to explain this trajectory with gradual implicit learning, without explicit representation of strategies or principles.  our parallel distributed processing model is nevertheless able to simulate several phenomena observed in how children learn mathematical equivalence: not only how successful performance develops, but also what strategies are used and how equations are encoded.
this study investigated the effect that pre-exposure to a set of stimuli has on the prevalence of family resemblance categorization. 64 participants were tested to examine the effect that pre-exposure type (same-stimuli vs unrelated-stimuli) and the perceptual difficulty of the stimuli (perceptually similar vs perceptually different) has on categorization strategy.  there was a significant effect of perceptual difficulty, indicating that perceptually different stimuli evoked a higher level of family resemblance sorting than perceptually similar stimuli. there was no significant main effect of pre-exposure type; however, there was a significant interaction between pre-exposure type and level of perceptual difficulty. post-hoc tests revealed that this interaction was the result of an increase in family resemblance sorting for the perceptually different stimuli under relevant pre-exposure but no such effect for perceptually similar stimuli. the theoretical implications of these findings are discussed.
there are numerous studies demonstrating that people’s judgments about meanings of words can sometimes derive from their sound – a phenomenon often referred to as sound symbolism. a recent comprehensive assessment of english demonstrates that some small amount of systematicity exists between form and meaning. is this small level of systematicity in language sufficient to drive the observed behavioral effects of sound symbolism? in this study we first tested the extent to which similarities amongst the sounds of words was sufficient to drive sound symbolic effects. we then tested whether a computational model that learned to map between form and meaning of english words better accounted for the observed behavior. we found that phonological similarity alone was sufficient to account for several effects of sound symbolism (without reference to meaning at all), but that the form-meaning mapping model was able to reproduce additional key behavioral effects of sound symbolism.
adults are sophisticated language users, and there is much debate as to the maturational and experiential changes that occur throughout childhood to bring about these abilities. we propose that the onset of literacy may be an important event in the course of language development, as it marks a qualitative shift in the linguistic patterns to which an individual is exposed.  in experiment 1, we investigate the frequencies of two complex sentence types in child-directed speech and literature.  in experiment 2, these sentence types are elicited from eight and twelve year old children and adults in a picture-description production task.  differences between written and spoken language predict both group differences and individual differences in text exposure on the production task.  linguistic experience gained from reading may affect spoken production choices, and the onset of literacy may be an important predictor for what in the laboratory is deemed adult-like language use.
do people rely on their causal intuitions to determine the predictive value of cues?our real-world dataset comprises one criterion (child mortality) and nine cues (e.g., gdp per capita).we elicited people’s causal models about the domain. in a second task, they had to rank the cues according to their beliefs about the cues’ predictive value. alternative cue rankings were derived from people's causal models using measures of causal centrality.people’s judgments of cue importance corresponded more closely to the causal-based cue orders than to the statistical associations between the cues and the criterion.computer simulations suggest that people’s causal-based cue orders form a sound basis for heuristic inference. causal-based cue orders allowed take-the-best, a simple decision heuristic, to perform as well as a linear model using about 35% of the available data.these findings indicate that people can rely on their causal intuitions to determine a useful cue order.
when asked to solve mathematical problems, some people experience anxiety and threat, which can lead to impaired maths performance. the present studies investigated the link between maths anxiety and performance on the cognitive reflection test (crt). the crt is a measure of a person’s ability to resist intuitive response tendencies, and it correlates strongly with important real-life outcomes, such as time preferences, risk-taking, and rational thinking. experiment 1 demonstrated that mathematical anxiety was a significant predictor of cognitive reflection, even after controlling for the effects of mathematical knowledge and test anxiety. in experiment 2 both working memory load and mathematical anxiety were associated with lower levels of cognitive reflection. a potential explanation is that maths anxiety is linked to lower levels of cognitive reflection, because anxious thoughts burden working memory resources.  given earlier findings that showed a close link between cognitive reflection, unbiased decisions and rationality, our results suggest that mathematical anxiety might be negatively related to individuals’ ability to make advantageous choices and good decisions.
whenever people depend on others, information about their likely behavior is important for the pursuit of goals. we investigated how the way social information is learned, by description or experience, affects offers in a bargaining situation. participants learned how often each offer had previously been accepted or rejected, either as probability information or by experiencing others’ responses. when participants had to draw a representative sample of responses, the proportion of risky offers decreased under social experience, resulting in a gap to the description condition. when participants could terminate sampling whenever they wanted, however, no description–experience gap was observed. the sampling pattern suggests that participants disregarded probability information and relied on the allocation as proxy for risk. accordingly, a certain amount of social experience seems necessary to overwrite  initial expectations and change behavior. under what conditions people search for social information is crucial for understanding how and when it impacts behavior.
how do people solve the explore-exploit trade-off in a changing environment? in this paper we present experimental evidence in an "observe or bet" task, comparing human behavior in a changing environment to their behavior in an unchanging one. we present a bayesian analysis of the observe or bet task and show that human judgments are consistent with that analysis. however, we find that people's behavior is most consistent with a bayesian model that assumes a rate of change that is higher than the true rate in the task. we argue that this tendency is the result of asymmetric consequences: assuming that the world changes more often than it really does is not very costly, whereas assuming a too-low rate of change can carry much more severe consequences.
people naturally and easily establish social groupings based on appearance, behavior, and other nonverbal signals. however, psychologists have yet to understand how these varied signals interact. for example, which factor has the strongest effect on establishing social groups? what happens when two of the factors conflict? part of the difficulty of answering these questions is that people are unique and stochastic stimuli. to address this problem, we use robots as a visually simple and precisely controllable platform for examining the relative influence of social grouping features. we examine how behavioral mimicry, similarity of appearance, and direction of gaze influence peoples' perception of which group a robot belongs to. experimental data shows that behavioral mimicry has the most dominant influence on social grouping, though this influence is modulated by appearance. non-mutual gaze was found to be a weak modulator of the perception of grouping. these results provide insight into the phenomenon of social grouping, and suggest areas for future exploration.
individuals often revise their beliefs when confronted with contradicting evidence. belief revision in the spatial domain can be regarded as variation of initially constructed spatial mental models. construction and revision usually follow distinct cognitive principles. the present study examines whether principles of revisions which follow constructions under high task demands differ from principles applied after less demanding constructions. we manipulated the task demands for model constructions by means of the continuity with which a spatial model was constructed. we administered tasks with continuous, semi-continuous, and discontinuous conditions as between-subject factor (experiment 1) and as within-subject factor (experiment 2). construction and revision followed distinct cognitive principles in the changeless conditions of experiment 1. with increased task demands due to switches between different continuity conditions (experiment 2), reasoners adapted the principles they used for model revisions to the principles which they had used during antecedent constructions.
 a learner’s semantic network represents the learner’s knowledge of words/concepts and the relations among them. the structure of this network is significant as it might reveal aspects of the developmental process that leads to the network. in this work, we use computational modeling to examine the structure of semantic networks of different simulated word learners. we find that the learned semantic knowledge of a learner that simulates a normally-developing child reflects the structural properties found in adult semantic networks of words. in contrast, the network of a late-talking learner — one that simulates a child with a marked delay in vocabulary acquisition — does not exhibit these properties. we discuss the implications of this result for understanding the process of vocabulary acquisition and delay.
do we invest irrational amounts of effort into keeping options viable, or do we manage available and threatened options in an adaptive fashion? to ask and answer this question, we advocate an approach that considers the dynamic properties of decision environments. by linking the exploration-vs.-exploitation dilemma to animal foraging, we show that preserving and abandoning options can both be adaptive.  specifically, people should stay and abandon options in progressive environments, and leave and seek alternatives in exhaustive environments.  we extend a multi-arm bandit problem with threatened options by a manipulation of environmental expectations.  our findings show that people are highly sensitive to environmental assumptions and small payoff differentials.  this replicates the original effect, but may explain the apparently irrational tendency to keep options open as an ecologically rational adaptation.
research on risky choice has been dominantly based on studies of choice between two alternatives, with the findings often generalized to environments with more than two alternatives. one prominent claim of this research is that choices differ with respect to risk when alternatives are described (the description paradigm) as opposed to experienced (the experience paradigm): individuals appear to make decisions as if they over-weight small probabilities in the description paradigm, but under-weight the same probabilities in the experience paradigm. here, we show that the under-weighting in the experience paradigm is sensitive to the choice set size in the gain domain. two experiments show that as set sizes increase, choices systematically favour risky alternatives in the experience paradigm.  using simulations of three choice models, we further demonstrate that this risk-amplification is independent of choice and search strategies and is predicted by the statistical structure of pay-offs. the results suggest caution in generalising findings from two-choice environments to many-choice environments and further indicate a robust and systematic problem with increasing choice set sizes.
we propose a novel way to use discriminative analysis to project high-dimensional eeg data onto a low-dimensional discriminative space for visualization, analysis, and statistical testing. this multivariate analysis directly controls for the multiple comparison problem (mcp) by effectively reducing the number of test variables. a major advantage of this approachis that it is possible to compare the brain activity across conditions even when the trial count is low, provided that a sufficient number of trials are used to establish the initial hyperplane(s), meaning that error conditions and conditions that divide subtle behavioral differences can be readily compared. currently these data are either ignored or lumped with other data therebylosing the ability to reveal the neural mechanisms underlying subtle behavioral differences. the proposed method provides a powerful tool to analyze conditions with relatively small numbers of trials from high-dimensional neural recordings.
studies of human intelligence provide strong evidence for the neural efficiency hypothesis: more efficient brain functioning in more intelligent individuals, that is, less cortical activation in brighter individuals.the main goal was to explore the relationship between intelligence and cortical activation in combination with a cognitive training. in 83 participants, cortical activation was assessed by means of event-related desynchronization (erd) before and after working memory training. in a pre-test training post-test design, erd during performance of trained and untrained transfer tasks was correlated with scores in a psychometric intelligence test.we found a negative correlation between erd and intelligence for moderately difficult tasks. a decrease in cortical investment from pre- to post-test was found for simple tasks but likewise for individuals with lower and higher intelligence. these findings suggest partial confirmation of the neural efficiency hypothesis for moderately difficult tasks and they indicate that training can help become neurally efficient.
the ability to choose problem solving strategies flexibly and adaptively is an important part of proficiency. however, it is unclear how simple forms of problem solving practice as well as feedback affect this ability. on the one hand, as demonstrated by the einstellung and stroop effect, practice can decrease adaptivity. on the other hand, practice helps to associate problem types with effective solution strategies what can increase adaptivity. in a microgenetic design with 48 trials of a mathematical problem solving task, we found that the adaptivity of strategy choices increased linearly during practice without feedback in a group of ninth-graders. instructional support to stimulate insight sped up this process in a second experimental group. the results are interpreted in terms of cognitive models of strategy choices. they demonstrate the adaptive nature of human problem solving with minimal informational input.
incremental learning explanations state that semantic interference is driven by activation levels of competitors. to explore nonsemantic contributions to interference, we examined the combined and separate effects of facilitatory phonological form preparation and semantic relatedness in a blocked cyclic picture naming procedure. phonological similarity was facilitatory when tested separately, but had little effect when tested with the other conditions. we found about twice as much interference in word sets that shared both meaning and form (e.g., cyclically name puffin, pigeon, and peacock) as in semantic-only sets. thus, phonological similarity impacted interference when it was combined with a semantic attribute. a computational model that isolated the learning mechanism and eliminated carryover effects simulated this result and additionally showed cumulative interference over naming cycles. together with other findings from our research group and in the literature, these results suggest that co-activation from a variety of sources can drive interference. 
early studies investigating sign language acquisition claimed that signs whose structures are motivated by the form of their referent (iconic) are not favoured in language development. however, recent work has shown that the first signs in deaf children’s lexicon are iconic. in this paper we go a step further and ask whether different types of iconicity modulate learning sign-referent links. results from a picture description task indicate that children and adults used signs with two possible variants differentially. while children signing to adults favoured variants that map onto actions associated with a referent (action signs), adults signing to another adult produced variants that map onto objects’ perceptual features (perceptual signs). parents interacting with children used more action variants than signers in adult-adult interactions. these results are in line with claims that language development is tightly linked to motor experience and that iconicity can be a communicative strategy in parental input.
this study investigates how prosody encodes the extent to which a linguistic element is informative. while most prior work has approached this question from one of the two angles, namely (i) information theory/statistical probability and (ii) discourse-pragmatics/information structure, we focus on the interaction between these two dimensions. our results show that the prosodic marking of information-structural categories depends on statistical probabilistic factors. specifically, the post-focus pitch reduction resulting from new-information focus and corrective focus is modulated by the focused word’s frequency and contextual probability, respectively. in terms of pitch, new-information narrow focus patterns like wide focus when the focused word is lexically infrequent, although the two focus types differ when the word has high frequency. furthermore, corrective narrow focus patterns like wide focus when the focused word is contextually improbable, although the two focus types differ when the word has low contextual probability. we discuss how these results suggest that prosody reflects speakers’ expectation and surprise about the interlocutor’s knowledge state. our findings highlight the importance of integrating research from the information-theoretical perspective with research from the information-structural perspective, to improve our understanding of prosody.
gaming the system, a behavior where students disengage from a learning environment and attempt to succeed by exploiting properties of the system, has been shown to be associated with lower learning. machine learned and knowledge engineered models have been created to identify gaming behaviors, but few efforts have been made to precisely identify how experts code gaming behaviors. in this paper, we used cognitive task analysis to elicit knowledge about how experts code students as gaming or not in cognitive tutor algebra. we show how building a cognitive model of this process gave us insights about the behaviors gaming is composed of.
a current aim in research on moral cognition is the development of computational models of moral choices and judgements. we fit diffusion models with and without dependence on visual fixations to data on binary moral choices. we find that a fixation dependent model provides a better fit and can capture many features of the empirical data. we discuss the implications for understanding moral cognition and future development of moral choice models.
the current study evaluates how lexical choice impacts task performance in dyads tasked with building an object together without a shared visual environment. our analyses suggest that, while interpersonal lexical convergence in target linguistic categories promotes successful communication, success does not require convergence in all categories. in the absence of shared visual workspaces and face-to-face communication, success increases when interlocutors converge in establishing common ground but decreases with increased co-occurrence of knowledge-state words, perhaps due to mutual hedging and uncertainty. finally, miscommunication increases with use of ambiguous spatial terms and with markers of confusion, pointing to unique lexical signatures for successful and unsuccessful communication.
a fundamental property of language is that it allows us to establish joint attention to a referent, for instance by the use of spatial demonstratives. traditional accounts of demonstrative choice focused on the physical proximity of the referent to the interlocutors. however, recent work taking into account the multimodal context in which spatial demonstrative use is generally embedded shows that such accounts are too simplistic. using a controlled elicitation task, we tested the differential roles of visual joint attention, proximity of a referent, and use of a pointing gesture in demonstrative choice in dutch. it was found that ‘proximal’ demonstratives were used to refer to objects nearby the speaker. ‘distal’ demonstratives were used for referents not nearby the speaker, but also in an addressee-anchored way, i.e. when the referent was in the addressee’s visual attentional focus. findings are discussed in terms of demonstrative systems and multimodal reference production in general. 
both subitizing, the ability to enumerate small sets without counting, and finger gnosis, the ability to mentally represent one’s fingers, have been found to predict calculation skill in children (penner-wilger et al., 2007, 2009). in the current paper, we examined whether these same relations hold for young adults. consistent with the developmental data, both subitizing and finger gnosis were significantly related to university students’ (n = 51) calculation fluency, jointly accounting for 33% of variability in fluency. the findings demonstrate that early precursor skills to mathematics remain similarly related into adulthood.
analysis of the symbol grounding problem has typically focused on the nature of symbols and how they tie to perception without focusing on the actual qualities of what the symbols are to be grounded in. we formalize the requirements of the ground and propose a basic model of grounding perceptual primitives to regions in perceptual space that demonstrates the significance of continuous mapping and how it influences categorization and conceptualization of perception. we also outline methods to incorporate continuous grounding into computational systems and the benefits of applying such constraints.
expectations learned from our environment are known to exert strong influences on episodic memory. furthermore, people have prior expectations for universal color labels and their associated hue space—a salient property of the environment. in three experiments, we assessed peoples' color naming preferences, and expectation for color. using a novel experimental paradigm, we then assessed free recall for color. we found that people’s color naming preferences were consistent with the universal color terms (berlin & kay, 1969), as well as a strong subjective agreement on the hue values associated with these color labels. we further found that free recall for color was biased towards the mean hue value for each preferred color. we modeled this relationship between prior expectation and episodic memory with a rational model under the simple assumption that people combine expectations for color with noisy memory representations. this model provided a strong qualitative fit to the data.
in a setup based on the masicampo and baumeister (2008) lemonade study, the effects of caffeine on dual-process reasoning were explored. participants in this double-blind study were divided into a caffeine and a caffeine-free control group. participants had to solve several classical dual-process paradigms. participants in the caffeine group were expected to perform better on analytic reasoning trials. in a follow-up experiment participants were also given an unexpected implicit recollection task to see whether caffeine has an affect on conflict monitoring, an executive function underlying dual-process reasoning. even though the paradigms being used proved to be appropriate for dual-process testing, no effects of caffeine on dual-process reasoning or on conflict monitoring were found.
people map numbers onto horizontal space, forming an implicit mental number line (mnl). the direction of the mnl, which varies across cultures, has often been attributed to the direction of reading and writing words. yet, this proposal is neither clearly motivated nor well supported by experimental data. here we tested the hypothesis that finger-counting habits can determine the direction of the mnl. americans were trained to count on their fingers from left to right or from right to left. after rightward counting, participants showed implicit associations of small numbers with left space and large numbers with right space, typical for americans. after leftward counting, this space-number association was extinguished, overall, and was qualitatively reversed in a significant proportion of the individual participants. a few minutes of finger counting experience can redirect the mnl, supporting a causal role for finger counting in the acquisition and maintenance of culture-specific mental number lines.
three experiments investigate whether neuroscientific explanations for belief in some proposition (e.g., that god exists) are judged to reinforce, undermine, or have no effect on confidence that the corresponding proposition is true. participants learned that an individual’s religious, moral, or scientific belief activated a (fictional) brain region and indicated how this information would and should influence the individual’s confidence. when the region was associated with true or false beliefs (experiment 1), the predicted and endorsed responses were an increase or decrease in confidence, respectively. however, we found that epistemically-neutral but “normal” neural function was taken to reinforce belief, and “abnormal” function to have no effect or to undermine it, whether the (ab)normality was explicitly stated (experiment 2) or implied (experiment 3), suggesting that proper functioning is treated as a proxy for epistemic reliability. these findings have implications for science communication, philosophy, and our understanding of belief revision and folk epistemology.
in a recent paper, acheson, macdonald, and postle (2011) made an important but controversial suggestion: they hypothesised that a) semantic information has an effect on order information in short-term memory (stm) and b) that order recall in stm is based on the level of activation of items within the relevant long-term memory (ltm) network. however, verbal stm research typically has led to the conclusion that factors such as semantic category have a large effect on the number of correctly recalled items and little or no significant impact on order recall (poirier & saint-aubin, 1995; tse, 2009). both of the studies reported here tested the hypotheses advanced by acheson et al. results show that as predicted, manipulating the putative activation of list items significantly impacts the recall of item order.
the structure of previous sentences influences both production and comprehension of subsequent sentences, although there is less support for the latter. this effect, called structural priming, supposedly results from the repetition of syntactic structure, while evidence for the influence of thematic roles is controversial. we suggest that structural priming is achieved by automatic analogical mapping and transfer, which predicts that the thematic structure should be primed too. an experiment showed that the shared thematic structure is responsible for structural priming in comprehension of ambiguous sentences, rather than the syntactic structure. when participants read an unambiguous base sentence with an instrumental thematic role, they tended to interpret the corresponding role in the ambiguous prepositional phrase in the target as an instrument as well. this effect was present only when base and target sentences shared their whole thematic structure, not only the key role and in the absence of syntactic repetition. 
people face a problem similar to that faced by algorithms thatmanage the memory of computers: trying to organize informa-tion to maximize the chance it will be available when neededin the future. in computer science, this problem is known as“caching”. inspired by this analogy, we compared the prop-erties of a model of human memory proposed by andersonand schooler (1991) and caching algorithms used in computerscience. we tested each algorithm on a dataset relevant to hu-man cognition: headlines from the new york times. in addi-tion to overall performance, we investigated whether the algo-rithms from computer science replicated the well-documentedeffects of recency, practice, and spacing on human memory.anderson and schooler’s model performed comparably to theworst caching algorithms, but was the only model that capturedthe spacing effects seen in human memory data. all modelsshowed similar effects of recency and practice.
the meaning of gradable adjectives is highly context-dependent, and is notoriously difficult to capture precisely. recent work in theoretical linguistics suggests that the way we use gradable adjectives can be explained in terms of optimal language use. to test this hypothesis we formulate a probabilistic speaker model that combines ideas from bayesian approaches to pragmatic reasoning as social cognition with broader optimality considerations, as suggested by evolutionary linguistics. we demonstrate that, despite its simplicity, the model explains empirical data on the applicability of adjectives in context astonishingly well. 
people tend towards wishful thinking, in which they overestimate the probability of favorable outcomes and underestimate the probability of unfavorable outcomes. many explanations for this phenomenon focus on its irrationality. we explore whether wishful thinking could actually help people make better decisions given that they have limited cognitive resources. we consider a situation in which multiple decisions must be made over a period of time, where the consequences of these decisions are not fully determined. we model this situation as a markov decision process, and incorporate limited cognitive resources by varying the amount of time in the future that the agent considers the consequences of its decisions. through simulations, we show that with limited cognitive resources, this model can exhibit better performance by incorporating a bias towards wishful thinking. this advantage occurs across a range of decision-making environments, suggesting that the same effect could be applicable to many real life scenarios.
i argue that emotive states affect perceptual processing either directly or indirectly with latencies that fall within late vision and not early vision. these effects differ from the effects of, and are subserved by different neuronal mechanisms than those that subserve, attentional effects on perception, although the two sorts of effects may interact. it follows that the emotive effects found in perception do not entail either the cognitive penetrability of early vision or its emotional penetrability.
monotonic (logical) reasoning makes the strong claim that an inference cannot be contradicted by future information; an assumption contrary to everyday life experience. this assumption is relaxed in non-monotonic reasoning. however, there are only few formal non-monotonic theories of reasoning that have inspired psychological theory-building. can formal systems such as cumulative logic (system c) or preferential logic (system p), developed in philosophy and artificial intelligence, predict human non-monotonic inferences? previous investigations have mainly used probabilistic representations of these systems and it remains unclear whether participants make the same inferences based on a qualitative description. we describe a different methodological approach and report related experimental findings that run counter to current approaches to human non- monotonic reasoning. implications of our proposed method are discussed.
premises and conclusions in classical syllogistic reasoning are formed using one of four quantifiers (all, some, some not, none). in everyday communication and reasoning, however, statements such as “most” and “few” are formed as well. so far only chater and oaksford’s (1999) probability heuristics model (phm) makes predictions for these so-called generalized quantifiers. in this article we (i) extend existing and develop new theories, (ii) develop multinomial processing tree (mpt) models for these theories, and (iii) conduct an experiment to test the models. the models are evaluated with g2, akaike’s (aic) and bayesian information criteria (bic), and fisher’s information approximation (fia). mental model-based accounts and phm provide an equal account to the data
planning problems have been extensively studied with regard to graph theoretical properties such as the number of steps necessary to reach a specific goal state or the size of the problem space. these structural properties, however, do not completely characterize a problem. in the presented eye-tracking study we also investigated the influence of perceptual factors on the solution to a planning problem. while not affecting the correctness of a solution, the results suggest that certain gestalt properties are responsible for the deviation from optimal plans.
i critically examine the existing data in emotion research to show that empathy is not necessary for moral judgment. i argue that other emotions, such as disgust, are responsible for moral judgment, and that humans are  able to make moral judgments  without  empathy.  autistic  individuals  are  of interest because they are said to lack empathy, yet display some form of morality. thus, empathy cannot be the core motivator in moral judgment.
this paper introduces a hypothesis that the perceived sentence stress in speech is related to the unpredictability of prosodic features, thereby capturing attention of the listener. in order to study this idea, a computational model was designed that learns the statistical structure of temporal f0 trajectories from continuous speech data without supervision using n-gram statistics. when the model output is compared to human perception of stress on a set of novel utterances, the low-probability points of the f0 trajectories show high correlation with the moments of subjective perception of stress. the result gives support to the idea that perceptual attention and unpredictability of sensory stimulus are mutually connected, and suggests that stress perception can be learned with similar statistical learning mechanisms that are considered to play a central role in early word segmentation.
we present the first model capable of performing hierarchical reinforcement learning in a general, neurally detailed implementation.  we show that this model is able to learn a spatial pickup and delivery task more quickly than one without hierarchical abilities.  in addition, we show that this model is able to leverage its hierarchical structure to transfer learned knowledge between related tasks.  these results point towards the advantages to be gained by using a hierarchical rl framework to understand the brain's powerful learning ability.
a growing bulk of work indicates that we think about time in terms of space. solving temporal ambiguities may involve adopting alternative spatial frames – namely time-moving vs. ego-moving perspectives. previous work showed that people draw on either spatial perspective to disambiguate statements such as next wednesday´s meeting has been moved forward 2 days (boroditsky, 2000). the ambiguity lies in the expression move forward, which can be translated into spanish either as adelantar or as mover hacia adelante. a spanish corpus analysis shows that, when these expressions are used to talk about time, the former is more frequently used to describe events moving towards the ego (time-moving perspective). we studied whether the use of these expressions influences the interpretation of ambiguous temporal statements in spanish. results from three experiments show that:  1.both spatial schema primes and the choice of “move forward” translation constrain people´s interpretations of ambiguous temporal statements (experiment 1); 2.the use of different metaphors to talk about time influences the solving of spatial ambiguities (experiment 2); 3.temporal primes containing no metaphorical forms fail to do so (experiment 3). we conclude that the conventionalized use of expressions affects how people draw on spatial schemas when thinking about time and space.
various studies have provided evidence that people activate introspective simulations when making valence judgments. such evidence is in line with an embodied cognition account that argues that cognition is fundamentally embodied, with perceptual simulation rather than language statistics being the source of lexical semantics. recently, demonstrations that conceptual knowledge is encoded in language  have been used to argue that semantic processing involves both language statistics and perceptual simulation, with linguistic cues allowing meaning to be bootstrapped with minimal symbol grounding. whether language also encodes attitudes towards concepts is unclear. in three studies, negative-valence words were found to be more closely associated in language with individuals commonly considered villains, and positive-valence words with heroes (both fictional and historical). these results suggest that attitudes toward persons can be inferred from lexical associations.
spatial locations can be extracted from language statistics, based on the idea that nearby locations are mentioned in similar linguistic contexts, akin to tobler’s first law of geography. however, the performance of language-based estimates is inferior to human estimates, raising questions about whether human spatial representations can actually be informed by such (inferior) statistics. we show that alternative methods of computing co-occurrence statistics improve language-based estimates, illustrating that simple linguistic associations may in fact inform spatial representations. most importantly, we show that by bootstrapping from grounded city locations, linguistic associations can be exploited to accurately estimate the locations of unknown cities, as well as human estimates of city locations. these results support the hypothesis that (un-grounded) linguistic associations can be productively combined with pre-existing spatial representations to yield new grounded representations, shedding light on the issue of symbol grounding in cognition.
grounded cognition theories state that conceptual knowledge is closely linked to the current situation and embodied in sensory dimensions. alongside the interaction with the environment, knowledge related to our environment is continually recovered from memory. thus, the perceptual situation is closely linked to the reactivated traces in memory. visual illusions correspond to a situation in which the perceived image differs from the objective image. in order to explore the link between conceptual processes and perceptual processes, we used the ebbinghaus illusion and replaced the perceptual size difference of the inducers by a typical size difference simulated in memory (animals with a typically large or small size were used as inducers). results showed a bias in judgments of the size of the test elements even when the inducers did not have different physical sizes but only reactivated different sizes in memory.
adaptive decision making often entails learning to approach things that lead to positive outcomes while avoiding things that are negative. the decision to avoid something removes the risk of a negative experience but also forgoes the opportunity to obtain information, specifically that a seemingly negative option is actually positive. this paper explores how people learn to approach or avoid objects with uncertain payoffs. we provide a computational-level analysis of optimal decision making in this problem which quantifies how the probability of encountering an object in the future should impact the decision to approach or avoid it. a large experiment conducted online shows that most people intuitively take into account both their uncertainty and the value of information when deciding to approach seemingly bad things.
achievement goals are a powerful construct for understanding students’ classroom experiences and performance, yet most work examining achievement goals relies on self-report measures gathered through questionnaires. the current work aims to assess achievement goals using a task choice embedded within a typical classroom activity. results show the behavioral measure of achievement goals predicts performance on the task, while self-reported achievement goals do not. self-reported achievement goals predict quarterly grades, while the behavioral measure of achievement goals does not. this work supports the viability of a behavioral measure and suggests the achievement goals that students adopt at a task level may be different from their general class achievement goals. using complementary achievement goal measures may improve understanding of how achievement goals relate to student behaviors and academic achievement.
achievement goals have been examined extensively in relationship to self-reported learning behaviors and achievement, yet very little work has observed the behaviors through which achievement goals might influence learning and performance. we collected fine-grained behavioral data to assess students’ activities throughout the semester in a college psychology course, and then used one learning behavior, access to course outlines, to explain the relationship between self-reported achievement goals and grades. results suggest that downloading course outlines partially mediates the relationship between goals and grades. identifying how goals influence achievement through observable behaviors contributes to the theoretical understanding of achievement goals while also suggesting practical implications for instructors.
beliefs are a fundamental component of our daily decisions, and as such, beliefs about our health have a huge impact on our health behaviors. poor medication adherence is a well-documented problem and while it has been extensively researched, it has yet to be addressed using a bayesian framework. this study aims to use a mixture model to understand belief updating as it affects decision making. using an established experimental paradigm in categorical perception, we test memory and prediction in order to establish a model that can explain human belief updating. results indicate that a mixture model provides a good explanation of participant behavior in this paradigm. 
neural networks exhibit ongoing, spatio-temporal patterns of spiking activity. evidence shows that these patterns are metastable, i.e. temporary, transient, and non-stationary. metastability is theorized to be adaptive for neural and cognitive function, but learning must somehow remain stable in the context of highly variable spike dynamics. in the present study, a neural network learning algorithm is developed to co-exist with intrinsic variability that arises from regulating spike propagation to stay near its critical branching point. the learning algorithm is based on reinforcement traces stored at synapses that change much more slowly than synaptic switches triggered to maintain critical branching. as a result, learning establishes a stable synaptic space within which variability and metastability can arise from critical branching. model efficacy is demonstrated using time-delayed  xor learning, and spike dynamics are compared with evidence of metastability in hippocampal recordings.
adults, children and infants are all able to infer likely word meanings based on the relative frequency with which labels and referents appear together (e.g., smith & yu, 2007; yu & smith, 2008). however, the extent to which learners rely on aggregation of co-occurrence statistics vs. test specific hypotheses to infer mappings is currently a matter of significant uncertainty (smith & yu, 2012), exacerbated by the different experimental methods used to test learning mechanisms. real world word learning is likely to involve a combination of statistical aggregation and active hypothesis testing. the current experiment investigates how these two learning mechanisms interact during word learning by having participants respond to a subset of items during a cross-situational word learning task. we find that hypothesis-testing is most effective when informed by statistical information and that the process of hypothesis-testing draws attention away from the remaining set of items.
in an experiment in functional elegance, episodic memory and learning have been deconstructed in the sigma cognitive architecture in terms of pre-existing memory and learning mechanisms plus a template-based structure generator.  as a side effect, base-level activation also becomes deconstructed in terms of a learned temporal prior.
when trying to determine which of two causes produces a more desirable outcome, if the outcome is autocorrelated (goes through higher and lower periods) it is critical to switch back and forth between the causes. if one first tries cause 1, and then tries cause 2, it is likely that an autocorrelated outcome would appear to change with the second cause even though it is merely undergoing normal change over time. experiment 1 found that people tend to perseverate rather than alternate when testing the effectiveness of causes, and perseveration is associated with substantial errors in judgment. experiment 2 found that forcing people to alternate improves judgment. this research suggests that a debiasing approach to teach people when to alternate may be warranted to improve causal learning.
semantic models play an important role in cognitive science. these models use statistical learning to model word meanings from co-occurrences in text corpora. a wide variety of semantic models have been proposed, and the literature has typically emphasized situations in which one model outperforms another. however, because these models often vary with respect to multiple sub-processes (e.g., their normalization or dimensionality-reduction methods), it can be difficult to delineate which of these processes are responsible for observed performance differences. furthermore, the fact that any two models may vary along multiple dimensions makes it difficult to understand where these models fall within the space of possible psychological theories. in this paper, we propose a general framework for organizing the space of semantic models. we then illustrate how this framework can be used to understand model comparisons in terms of individual manipulations along sub-processes. using several artificial datasets we show how both representational structure and dimensionality-reduction influence a model’s ability to pick up on different types of word relationships.
one way to learn about the world is by asking questions. we investigate how children (n= 287, 7- to 11-year olds) and young adults (n=160 17- to 18-year olds) ask questions to identify the cause of an event. we find a developmental shift in children’s reliance on hypothesis-scanning questions (which test hypotheses directly) versus constraint-seeking questions (which reduce the space of hypotheses), but also that all age groups ask more constraint-seeking questions when hypothesis-scanning questions are unlikely to pay off: when the problem is difficult (studies 1 and 2) or the solution is one among equally likely alternatives (study 2). these findings are the first to demonstrate that even young children adapt their strategies for inquiry to increase the efficiency of information search.
in this paper, we present a computational investigation into the compositionality of iconic gestures by trying to learn a motor grammar. we propose a grammar formalism that learns (1) the salient, invariant features of single movement segments (motor primitives) and (2) the hierarchical organization of these segments in complex gesturing. the formalism is applied to a dataset of natural iconic gestures. the extracted structure reveals compositional patterns of iconic gesturing.
in this paper we apply a computational text analysis technique used for measuring moral rhetoric in text to analyze the moral loadings of tweets. we focus our analysis on tweets regarding the 2013 federal government shutdown; a topic that was at the forefront of u.s. politics in late 2013. our results demonstrate that the positions of the members of the two major political parties are mirrored by the positions taken by the twitter communities that are aligned with them. we also analyze retweeting behavior by examining the differences in the moral loadings of intra-community and inter-community retweets. we find that retweets in our corpus favor rhetoric that enhances the cohesion of the community, and emphasize content over moral rhetoric. we argue that the method proposed in this paper contributes to the general study of moral cognition and social behavior.
although computational models developed in cognitive architectures are often rich in their knowledge of procedural skills, they are often poor in their knowledge of declarative facts about the world. this work endows the act-r cognitive architecture with world knowledge derived from wikipedia, compiling a knowledge base of over 37 million declarative facts that can be accessed by a cognitive model via standard memory retrievals. estimates of the accessibility of these facts are also derived from wikipedia text, allowing act-r to utilize the likelihood of knowing a fact and associations between related facts. integration with a simple procedural model demonstrates how the knowledge base may serve not only to answer simple factual questions, but also to disambiguate among multiple possible meanings based on context. the resulting knowledge base can be queried quickly (typically well under one second) and is easily generalizable to other cognitive architectures.
while it is well known that agents only tend to be held accountable for events they have caused, recent findings suggest that the inverse relation between causation and accountability also holds. according to this view, normative evaluations also affect responses to causal test questions. a key problem of this research is that causal queries are typically ambiguous. the question whether somebody has caused a specific outcome may on the one hand refer to causal relations, but it may also be understood as a request to assess the moral accountability of the agent. to test whether normative evaluations really affect causal inference, it is necessary to disambiguate the test question. in experiment 1, we showed that the assumed influence of social or prescriptive norms on causality disappears when causal inference is measured using unambiguous test questions. furthermore, experiment 2 demonstrates that no influence of moral values is seen when the pragmatic context of the task highlights the causal meaning of the test question. both findings cast doubt on the claim that normative evaluations influence causal inference. 
a recent body of work has demonstrated that the incremental presentations of linguistic search cues can speed up visual processing in conjunctive visual search.  in this paper, we investigate different processing configurations using a real-time embodied computational model and demonstrate that, different from previous hypotheses, the same incremental processing configuration can explain all experimental conditions.
focused reasoning is a method for continuing a specific inference task as soon as rules or facts which may assist in the reasoning are added to the knowledge base without repeating completed inference, re-posing queries, or performing unnecessary inference. determining if focused reasoning should commence uses very few computational resources above those used normally to add a term to a knowledge base. we have developed three focused reasoning procedures -- backward-in-forward, forward, and forward-in-backward -- built upon inference graphs, a graph-based concurrent reasoning mechanism. 
preference is the primary dimension underlying odor perception. therefore, to understand odor perception it is necessary to understand odor preferences. we propose that preference for an odor is determined by preferences for all objects and/or entities associated with that odor (extending palmer and schloss’s (2010) ecological valence theory of color preferences to odor preferences). odor preferences were strongly predicted by preference for all associates with the odors (e.g., people liked the apple odor which was associated with mostly positive things like apples, soap, and candy and disliked the fish odor associated with mostly negative things like dead fish, trash, and vomit. our model performed significantly better than one based on preference for the object the odors were designed to smell like (e.g., predicting preference for the apple odor based on preference for apples).  these results suggest that odor preferences are a summary statistic, coding the valence of previous odor-based experiences. 
how do we manage to step into another person's shoes and eventually derive the intention behind observed behavior? we propose a connectionist neural network (nn) model that learns self-supervised a prerequisite of this social capability: it adapts its internal perspective in accordance to observed biological motion. the model first learns predictive correlations between proprioceptive motion and a corresponding visual motion perspective. when a novel view of a biological motion is presented, the model is able to transform this view to the closest perspective that was seen during training. in effect, the model realizes a translation-, scale-, and rotation-invariant recognition of biological motion. the nn is an extended adaptive resonance model that incorporates self-supervised error backpropagation and parameter bootstrapping by neural noise. it segments and correlates relative, visual and proprioceptive velocity kinematics, gradually refining the emerging representations from scratch. as a result, it is able to adjust its internal perspective to novel views of trained biological motion patterns. thus, we show that it is possible to take the perspective of another person by correlating proprioceptive motion with relative, visual motion, and then allowing the adjustment of the visual frame of reference to other views of similar motion patterns.
when comparing the ability of computational cognitive models to fit empirical data, the complexity of the compared models needs to be taken into account. a promising method for achieving this is the parametric bootstrap cross-fitting method (pbcm) proposed by wagenmakers et al. (2004). we contribute to a wider applicability of the pbcm in two ways: first, we compare the performance of the data-informed and the data-uninformed variant of the pbcm. our simulations suggest that only the data-uninformed variant successfully controls for model complexity in model selection. second, we propose an extension of the pbcm, called mmpbcm, that is applicable to, in principle, arbitrarily many competing models. we evaluate the mmpbcm by applying it to the comparison of several sets of competing models. the obtained results suggest that the mmpbcm constitutes a more powerful approach to model comparison than the pbcm.
abstraction often requires appropriate integration of more concrete representations.  during development, the more specific or localized representations may arise first.  here we study the special case of integration of visual representations from the left and right hemispheres during infancy.  we present failures of interhemispheric integration in two domains, form perception and approximate number, in infants ranging from 8 to 18 months of age.  in experiment 1, infants succeeded in representing equality of two shapes only when both shapes were presented in the same visual hemifield.  in experiment 2, infants represented 16 when shown 16 dots in one hemifield but not when shown 8 dots in each hemifield.  we argue that interhemispheric integration poses a particular and unusually late-resolved challenge in infant vision.
according to previous accounts, teaching is the helpful sampling of examples according to a learner's known biases. using the domain of boolean concepts, we show that biases are necessary, there is no single rational bias, and teaching is not possible when the teacher does not know the learner's bias.taken together, these results suggest that teaching via sampling would be either ineffective or impossible for boolean concepts.we offer an alternative account of teaching based on cooperation and the teacher's omission of irrelevant features.the result is a model of teaching that is computationally efficient, effective in concept spaces with infinitely many features, and suggestive of a natural concept representation based on cooperation.
the important role of referring expressions in human communication has inspired much research in the fields of computational linguistics and psycholinguistics. building on the research done by viethen, goudbeek and krahmer (cogsci, 2012) the present study takes a cross-linguistic perspective on examining the use of the colour attribute in distinguishing a target referent. it aims at answering the following research question: does the availability of adequate basic colour terms in a language affect the use of colour in reference production? we conducted a language production experiment with native speakers of dutch and greek. our results confirm that the use of the colour attribute in reference production depends on the colour term resources of a particular language. in addition, we have recorded a large cross-linguistic difference in the proportion of the colour attribute use, which we relate to the particular colour nuances used.
strict compositionality in morphological theory is problematic for explaining how language-users comprehend phenomena like the partial yet non-decomposable forms in phonaesthemes and in blends like edutainment. an alternative account, based on discriminative learning, proposes that language-users associate linguistic cues (e.g., short segment or letter strings) with multiple simultaneous possible lexical and grammatical meanings. we evaluate this account on off-line human identifications of partial word-forms, using english blend words as our test case. we hypothesize that readers' ability to parse out source meanings from written blend forms should be correlated with how strongly a naive discriminative reading  model associates the cues in each form with the correct source meanings. we provide evidence for this claim in two experiments, in which the discriminative learning model reliably predicted participants' success rate in guessing the sources of both attested and novel blends. this finding supports discriminative learning as a realistic model of how readers parse wordforms and map them to meanings. further, the result points towards a novel, precise account of blend processing.
causal reasoning involves evaluation and integration of the observed evidence, the quality of which is influenced by the external factors such as uncertainty and the internal factors such as one's cognitive ability. the current experimental study investigated the relationship between working memory (wm), causal reasoning and impacts of ambiguous observations. results revealed that wm assessed by the n-back task was associated with subjects' causal reasoning under unambiguous condition. the higher n-back scores were associated with lower variability in causal ratings. on the other hand, wm assessed by the operational span task was associated with subjects' reaction to the ambiguous evidence. subjects with higher span had greater individual difference in their reactions to the ambiguous evidence than those with lower wm capacity.
studies of children’s causal learning typically provide learners with clear evidence for direct causal relations, e.g., a machine that activates when a toy is placed upon it. but causal systems in the real world often present indirect perceptual evidence generated by interactions between hidden variables: consider a child trying to figure out what’s inside a box by shaking it. we propose that effective learning and exploration depend on being able to interpret evidence through the lens of intuitive theories – theories of both the physical world and one’s own perceptual apparatus – to imagine how one’s actions might change the state of the world and what kinds of changes would be most perceptually discriminable. we present three studies exploring these capacities in young children, and suggest how they could support powerful and sophisticated inferences about hidden causes.
several recent theoretical proposals suggest that young children are rational, constructivist learners (e.g. gopnik & wellman, 2012; xu & kushnir, 2012; 2013).  one of the claims made under constructive learning is that children are active learners – they selectively attend and explore their environment in order to maximize information gain (e.g., kidd, piantadosi, & aslin, 2012; schulz & bonawitz, 2007).  most studies to date, however, have focused on how efficiently children learn when they are given evidence by an experimenter (‘teacher’), under conditions of training: children receive a restricted set of evidence, and they are subsequently tested on their learning. yet children are not mere observers; they actively engage their environment to supplement their learning. in our experiment, 3-year-old children successfully acquired higher-order generalizations using self-generated evidence during free play, suggesting an early capacity to engage in self-directed learning.
this paper investigates how team structure impacts team information processing and how this affects team resilience to change. teams in three different subgrouping structures: homogeneous, heterogeneous, or no-clustering, were instructed to make decisions in which they had to evaluate different companies and pick the best one. each member was told to evaluate the companies in a different way, creating teams with diverse perspectives. partway through the experiment the problem evaluation criteria changed, but teams were not informed of the change, only whether their choice was correct. teams with homogeneous-clustering were less capable than the other two types of teams in making use of multiple preferences and in dealing with changes. a similar effect was also found in computational simulations built from a pdp model. we suggest that heterogeneous-clustering can weaken members’ ownership and confirmation biases while no-clustering ensures a free flow of information, with both able to enhance team performance. 
eye movement recording is not only a research tool but can also be used as a learning tool. previous research on eye movement modeling and analogical thinking has demonstrated that stimulating eye movements can foster learning and problem solving. such training interventions can support learners and problem solvers without revealing the solution, but just by guiding their gaze. the present two studies investigated whether a preceding stimulation of eye movements would affect the comprehension of following learning materials. study i revealed a positive effect of a non-verbal eye movement pre-training on learning outcomes. study ii corroborated this finding and, additionally, revealed no effect of presentation format (static versus dynamic) on comprehension. with respect to eye movements performed during the learning phase, pre-training led to more homogenous fixation strings. moreover, the homogeneity could also be attributed to a dynamic representation (study ii). in sum, a non-verbal pre-training of eye movements before exposure to the learning content fosters comprehension in static and in dynamic representations.
when processing language, the cognitive system has access to information from a range of modalities (e.g. auditory, visual) to support language processing. language mediated visual attention studies have shown sensitivity of the listener to phonological, visual, and semantic similarity when processing a word. in a computational model of language mediated visual attention, that models spoken word processing as the parallel integration of information from phonological, semantic and visual processing streams, we simulate such effects of competition within modalities. our simulations raised untested predictions about stronger and earlier effects of visual and semantic similarity compared to phonological similarity around the rhyme of the word. two visual world studies confirmed these predictions. the model and behavioral studies suggest that, during spoken word comprehension, multimodal information can be recruited rapidly to constrain lexical selection to the extent that phonological rhyme information may exert little influence on this process.
the effect of literacy on phonological processing has been described in terms of a virus that “infects all speech processing” (frith, 1998). empirical data has established that literacy leads to changes to the way in which phonological information is processed. harm & seidenberg (1999) demonstrated that a connectionist network trained to map between english orthographic and phonological representations display’s more componential phonological processing than a network trained only to stably represent the phonological forms of words. within this study we use a similar model yet manipulate the transparency of orthographic-to-phonological mappings. we observe that networks trained on a transparent orthography are better at restoring phonetic features and phonemes. however, networks trained on non-transparent orthographies are more likely to restore corrupted phonological segments with legal, coarser linguistic units (e.g. onset, coda). our study therefore provides an explicit description of how differences in orthographic transparency can lead to varying strains and symptoms of the ‘literacy virus’. 
languages tend not to exhibit unpredictable variation. we explore alignment/accommodation during interaction as a mechanism to explain this cross-linguistic tendency. specifically, we test the hypothesis (derived from historical linguistics) that interactions between categorical and variable users are inherently asymmetric: while variable users (of e.g. a grammatical marker) can accommodate to their partner by increasing their usage, categorical users should be reluctant to accommodate to variable partners, since this requires them to violate the rules of their grammar. we ran an experiment in which pairs of participants learnt a miniature language (featuring a potentially variable grammatical marker) and then used it to communicate. our results support the hypothesis: variably-trained participants accommodate to their categorically-trained partners, who do not change their behaviour during interaction. more generally, interaction results in the elimination of variation: accommodation/alignment is a viable mechanism for explaining the absence of unpredictable variation in language.
people must often infer what might have transpired in the past to bring about the present state of the world, a task called retrodiction. we hypothesize that retrodiction relies on similar cognitive mechanisms to prediction – inferring possible futures based on the present state of the world. here we investigate how people perform on physical reasoning tasks that differ only in that people are asked to do either prediction or retrodiction. we find that average behavior is similar between tasks across a range of difficulty, though there was greater variability in retrodiction responses. we propose two ways in which prediction and retrodiction might be related; however, neither sufficiently explains the similarities and differences across tasks.  we suggest that both tasks rely on similar cognitive processes, but that further research is needed to determine the exact relation.
prior research has found that comparison fosters abstraction and transfer of concepts (e.g., categories, solution methods). these learning benefits are often explained by virtue of comparison’s ability to highlight common relational structure between cases. here we explore the role of comparison in identifying critical differences. participants compared contrastive cases, listed differences between them, and completed a classification task. we found that carrying out a structural alignment prior to listing differences influenced the kinds of differences people noticed. further, the kinds of differences people noticed predicted their subsequent classification performance.
the evidence that available options influence risk preference raises concerns about using risk attitude measures to guide investment choice. a between-participants test found those who first made choices between high (low) risk pension funds subsequently preferred higher (lower) risk funds when offered a choice from a larger range of funds. a within-participants test, with a fourteen-day break between conditions, found the same participants selected a lower risk fund after they experienced making choices between low risk funds, than they did after they experienced making choices between high risk funds. effects were not influenced by order, or attenuated by a bias warning. results are consistent with theories that suggest risky decision making involves similar processes to those involved in psychophysical perception (e.g. decision by sampling), although there was also evidence of sensitivity to absolute values. from an applied perspective, customers’ risk preferences are susceptible to manipulation.
previous work has found that one way people infer the direction of causal relationships involves identifying an asymmetry in how causes and effects change over time. in the current research we test the generalizability of this reasoning strategy in more complex environments involving ordinal and continuous variables and with noise.  participants were still able to use the strategy with ordinal and continuous variables. however, when noise made it difficult to identify the asymmetry participants were no longer able to infer the causal direction.
decision-making in noisy and changing environments requires a fine balance between exploiting knowledge about good courses of action and exploring the environment in order to improve upon this knowledge. we present an experiment in which participants made repeated choices between options for which the average rewards changed over time. comparing a number of computational models of participants' behaviour in this task, we find evidence that a substantial number of them balanced exploration and exploitation by considering the probability that an option offers the maximum reward out of all the available options.
most theoretical as well as empirical work regarding the scalar implicature "not all" of the quantifier "some" has focused on the controversy of whether this implicature is generated by default or based on context. independently of this question, it can be also asked whether this scalar implicature contributes to the truth-conditional content of sentences. we present results of an erp study which tackles both these questions. we adopt a sentence-picture verification paradigm to investigate whether the violation of this implicature, when it is based on short-term memory rather than semantic memory, elicits n400 or late positivity (e.g. p600) effects. additionally, we test if the truth-value judgments of the pragmatically infelicitous sentences correlate with the elicited erp components.
in this paper, we demonstrate that predicting stimulus co-occurrence patterns in a bayes-optimal manner endogenously explains classical conditioning. simulated experiments with a standard bayesian implementation of this model show that it is capable of explaining a broader range of effects than any previous theory of classical conditioning. by simplifying the mathematical structure of statistical modelling of conditioning and demonstrating its ability to explain a large set of experimentally observed effects, our work advances bayes-optimal inference about stimulus co-occurrence as a rational principle explaining classical conditioning.
most theories explaining how animals form preferences for their actions agree upon a basic outline: animals discover what is preferable through interactions with the world, store this information in memory, and recall it to help them decide what to do in a new situation. however, no single theory currently explains both how preferences are learned, and how they are recalled in a way that is compatible with empirical data. we advance precisely such a proposal in the form of a stochastic choice model where the decision agent learns what to do based on scale-free comparisons between options it observes in the world and at each decision instance recalls a subset of these comparison experiences in a manner that minimizes the metabolic costs of memory recall. in simulation, this model makes qualitatively accurate predictions connecting agent choices with various dynamic choice correlates documented in the literature on choice process models.
what types of scaffolds support sense making in mathematics? prior work has shown that grounded representations such as diagrams can support sense making and enhance student performance relative to analogous tasks presented with more abstract, symbolic representations. for grounded representations to support students’ learning of symbolic representations, students’ sense making must be maintained when both grounded and symbolic representations are presented together. this study investigates why students sometimes fail to coordinate these representations, in particular, why performance is high with fraction diagrams alone, but decreases when fraction symbols are included. results indicate that symbols trigger incorrect transfer from whole-number procedures, and that students lack the qualitative reasoning that the diagrams are intended to tap. specifically, students do not find it obvious that the sum of two positive symbolic fractions is larger than its two addends. qualitative inference rules such as this one appear important in mediating the sense making process in the context of tempting misconceptions even when otherwise-supportive grounded representations are available.
regardless of age there are mixed findings concerning the extent to which individuals utilize statistical features of input to make inductive inferences. direct instruction seems to be one important factor in linking one’s understanding of statistical properties with their reasoning. in the present study we examined the extent to which explicit training on some statistical principles would influence preschoolers’ inductive reasoning. the results indicate that a short training about random selection and the match between samples and populations increased children’s use of these principles to make inductive generalizations. critically, the training effects were observed in a different domain than was presented in the training and for statistical principles not presented in the training. thus, the present results suggest that the training had a broad impact on children’s reasoning. these results have important implications for understanding the nature of the statistical principles employed during induction. 
research suggests that checklists reduce errors in fields ranging from aviation to medicine. checklists are effective in part because their content is not randomly selected from available information but strongly sampled from information experts believe is critical.  this sampling process supports the inference that unlisted information is unlikely to be important.  however, this predicts that checklists might leave learners selectively vulnerable to unlisted sources of error. in experiment 1, we show that adults in an aviation class detect fewer unlisted sources of error given a checklist than at baseline.  in experiment 2, we show that this inductive bias does not require previous experience with checklists: given a checklist for organizing a room, children (mean: 62 months) selectively overlooked unlisted items relative to baseline, and did so even when told the list might be incomplete.
a long-standing challenge in cognitive science is how neurons could be capable of the flexible structured processing that is the hallmark of cognition.  we present a spiking neural model that can be given an input sequence of words (a sentence) and produces a structured tree-like representation indicating the parts of speech it has identified and their relations to each other.  while this system is based on a standard left-corner parser for constituency grammars, the neural nature of the model leads to new capabilities not seen in classical implementations.  for example, the model gracefully decays in performance as the sentence structure gets larger.  unlike previous attempts at building neural parsing systems, this model is highly robust to neural damage, can be applied to any binary-constituency grammar, and requires relatively few neurons (~150,000).
we present a multi-domain computational model for symbolic reasoning that was designed with the aim of matching human performance. the computational model is able to reason by deduction, induction, and abduction. it begins with an arbitrary theory in a given domain and gradually extends this theory as new regularities are learned from positive and negative examples. at the core of the computational model is a cognitive model with bounded cognitive resources. the combinatorial explosion problem, which frequently arises in inductive learning, is tackled by searching for solutions inside this cognitive model only. by way of example, we show that the computational model can learn elements of two different domains, namely arithmetic and english grammar.
we are skilled at reading other’s intentions – until they try to hide them. we are biased towards taking at face value what others say, but it is not clear why. one possibility is that we are uncertain, and make the decision by relying on heuristics. half of our participants judged whether speakers were lying or telling the truth. the other half did not have to commit to a judgment: they were allowed to say they were unsure. we expected these participants would no longer need to rely on simplified heuristics and so show a reduced bias compared to the forced choice condition. surprisingly, those who could say they were unsure were more biased towards believing people. we consider two possible accounts, both highlighting the importance of examining raters’ uncertainty, which have so far been undocumented. allowing raters to abstain from judgment gives new insights into the judgment-forming process.
developmental studies show that it takes longer for children learning spoken languages to acquire viewpoint-dependent spatial relations (e.g., left-right, front-behind), compared to ones that are not viewpoint-dependent (e.g., in, on, under). the current study investigates how children learn to express viewpoint-dependent relations in a sign language where depicted spatial relations can be communicated in an analogue manner in the space in front of the body or by using body-anchored signs (e.g., tapping the right and left hand/arm to mean left and right). our results indicate that the visual-spatial modality might have a facilitating effect on learning to express these spatial relations (especially in encoding of left-right) in a sign language (i.e., turkish sign language) compared to a spoken language (i.e., turkish).
a number of open questions are still unanswered about whether and how dyads perform better compared to individuals on memory tasks. the literature on collaborative recall demonstrates a robust collaborative inhibition effect, where participants do worse when remembering in collaborative contexts. however, a growing body of research suggests that this inhibition can be ameliorated, or even reversed, under certain task and social conditions. here we construct nominal groups (hypothetically optimal aggregates of individual performers) to compare to collaborative groups. we observe collaborative inhibition on two performance metrics (number of trivia clues answered, speed of answering), but we find a facilitatory effect of collaboration on two other performance metrics (accuracy, number of clues subsequently recalled). we also show that familiarity can reduce this collaborative inhibition in many ways.
a recent line of research suggests that in a tempting situation, a dishonest decision can be executed more quickly and easily than an honest one. some theories have purported that dishonesty is a default and automatic tendency, while honesty requires a more deliberative process. we argue that the facilitation observed in past studies is closely dependent on the nature of the task. in the current study we added a memory constraint to a cognitive task that prompts dishonest responses. participants were rewarded for their accuracy in privately predicting the outcome of computerized coin flips. they reported their prediction by clicking their mouse on one of the two options on the screen (heads, tails). we collected the mouse movements for each participant and analyzed the mouse trajectories to study decision-making dynamics. results revealed that patterns of facilitation are subtle and likely shaped by task constraints, rather than dishonesty simply being “automatic.”
this study proposed a design database consisting of creative and noncreative designs for creative research and discussed the correlation between creative assessment and brain activities using fmri. we answered the following two research questions: which brain areas are activated when assessing creative designs in contrast to noncreative designs and does social evaluation influence creativity assessment based on subjective criteria. the left inferior and middle temporal gyri (ba 37) were activated when assessing creative designs in contrast to noncreative designs. these activations suggest that an inference process to understand meanings underlying creative designs is important in creativity assessment. the left superior temporal gyrus (ba 38) was more activated when assessing creative designs with inconsistent social evaluations than without social evaluations; whereas, the decision behavior for creativity assessment was robust. this result suggests that the participants might consider the intentions of evaluation of others when inconsistent social evaluations are presented.
syllogistic reasoning lies at the intriguing intersection of natural and formal reasoning, of language and logic. syllogisms comprise a formal system of reasoning yet use natural language quantifiers, and invite natural language conclusions. how can we make sense of the interplay between logic and language? we develop a computational-level theory that considers reasoning over concrete situations, constructed probabilistically by sampling. the base model can be enriched to consider the pragmatics of natural language arguments. the model predictions are compared with behavioral data from a recent meta-analysis. the flexibility of the model is then explored in a data set of syllogisms using the generalized quantifiers most and few. we conclude by relating our model to two extant theories of syllogistic reasoning – mental models and probability heuristics.
why do people self-report an aversion to words like “moist”? the present study represents an initial scientific exploration into the phenomenon of word aversion by investigating its prevalence and cause. we find that as many as 20% of the population equates hearing the word “moist” to the sound of fingernails scratching a chalkboard. this population often speculates that phonological properties of the word are the cause of their displeasure. one tantalizing possibility is that words like “moist” are aversive because speaking them engages facial muscles that correspond to expressions of disgust. however, three experiments suggest that semantic features of the word – namely, associations with disgusting bodily functions – underlie peoples’ unpleasant experience. this finding broadens our understanding of language and contributes to a growing literature on the cognitive processes relating to highly valenced and arousing words.
children's number-line estimation has produced a lively debate about representational change, supported by apparently incompatible data regarding the descriptive adequacy of logarithmic (opfer et al., 2011) and power models (slusser et al., 2013). to test whether methodological differences might explain discrepant findings, we created a fully crossed 2x2 design and assigned 96 children to one of four cells. in the design, we crossed sampling (over-, even-) and supervision (with feedback, without feedback), which were candidate factors to explain discrepant findings. in three conditions (over-sampling/unsupervised-83%, even-sampling/unsupervised-67%, and over-sampling/supervised-58%), the majority of children provided estimates better fit by the logarithmic than by the power function. in the last condition (even-sampling/supervised-30%), the reverse was found. overall, a reliable association (p &lt; .0001) was found between proportion best fit by the power function and supervision. results suggest that the fit of the power function to children's estimates is likely an artifact of supervision.
in this paper, we describe an extension of the theory of short-term memory decay for the act-r cognitive architecture. by including a short-term decay for elements recently cleared from active memory, we have extended the functionality of spreading activation as a source of implicit contextual information for the model. in act-r models of serial memory and decision-making, contextual information has generally been modeled using either explicit markers (e.g., positional indices) or fixed-length windows of prior elements (e.g., a lag-based representation). while markers and fixed-length windows do capture some patterns of human errors, they are inflexible, are set by the modeler and not the model, and are not psychologically-plausible representations of contextual information. in conjunction with our associative learning mechanism (thomson & lebiere, 2013), we show how buffer decay can provide more flexible and implicit contextual information which explains refraction, positional confusion errors, and repetition facilitation and inhibition.
we investigated the interpolation of missing values in data that were fit by bidimensional regression models. this addresses a problem in spatial cognition research in which sketch maps are used to assess the veracity of spatial representations. in several simulations, we compared samples of different sizes with different numbers of interpolated coordinate pairs. a genetic algorithm was used in order to estimate parameter values. we found that artificial inflation in the fit of bidimensional regression models increased with the percent of interpolated coordinate pairs. furthermore, samples with fewer coordinate pairs resulted in more inflation than samples with more coordinate pairs. these results have important implications for statistical models, especially those applied to the analysis of spatial data.
many studies have shown that our visual system may construct a “statistical summary representation” over groups of visual objects. although there is a general understanding that human observers can accurately represent sets of a variety of features, many questions on how the statistical summary is computed still remain unanswered. this study investigated sampling properties of visual information used by human observers in deriving an average representation of a set of items. we presented three models of ideal observers to perform a size averaging task: a global averaging model without item noise (gam1), a global averaging model with item noise (gam2), and a limited sampling model (lsm). we compared the performance of the ideal observer of each model to the performance of human observers using statistical efficiency analysis. our results suggest that average size of items in a set may be computed without representing individual items, discarding the limited sampling model.
we tested whether overhearers made use of the relationship between specific (e.g. really, oh) and generic (e.g. uh huh, mhm) backchannels and speakers’ talk in online dialogue comprehension. in experiment 1 we found that words that followed specific backchannels were recognized more slowly than words that followed either generic backchannels or pauses. in experiment 2 we found that the type of backchannel and the discourse relationship between the speaker’s subsequent and previous turn predicted overhearer’s recall of words that preceded backchannels and pauses. when the turn was a continuation of the narrative preceding the test point, specific backchannels resulted in faster responses. when the turn was an elaboration of the narrative preceding the test point, specific backchannels resulted in slower responses. we conclude that overhearers make use of the predictive relationship between listener backchannels and speakers’ discourse in comprehending dialogue. 
when people make inferences about causal situations with vague and imperfect information, their judgments often deviate from the normative prescription of classical probability. as a result, it is difficult to apply popular models of causal reasoning such as delta p and causal power, which provide good accounts of behavior in casual learning tasks and tasks where statistical information is provided directly. we propose a unified explanation of human causal reasoning using quantum probability theory that can account for causal reasoning across many different domains. in our approach, we postulate a hierarchy of mental representations, from fully quantum to fully classical, that could be adopted for different situations. we illustrate our approach with new experiments and model comparisons.
a critical aspect of human cognition is the ability to effectively query the environment for information. the `real' world is large and noisy, and therefore designing effective queries involves prioritizing both scope -  the range of hypotheses addressed by the query - and reliability - the likelihood of obtaining a correct answer. here we designed a simple information-search game in which participants had to select an informative query from a large set of queries, trading off scope and reliability. we find that adults are effective information-searchers even in large, noisy environments, and that their information search is best explained by a model that balances scope and reliability by selecting queries proportionately to their expected information gain.
we develop a model for the stability and maintenance of phonological categories.  examples of phonological categories are vowel sounds such as "i" and "e".  we model such categories as consisting of collections of labeled exemplars that language users store in their memory.  each exemplar is a detailed memory of an instance of the linguistic entity in question.  starting from an exemplar-level model we derive integro-differential equations for the long-term evolution of the density of exemplars in different portions of phonetic space. using these latter equations we investigate under what conditions two phonological categories merge or not. our main conclusion is that for the preservation of distinct phonological categories, it is necessary that anomalous speech tokens of a given category are  discarded, and not merely stored in memory as an exemplar of another category.
lower nonword reading performance in the old version of parallel-distributed processing models in english was taken as evidence for the necessity of sequential components in reading aloud, but the later updates have resolved this issue without discarding the parallel processing principle. a model’s validity can be tested by cross-script extensions. on this point, an extension to japanese kanji reading has posed a question. specifically, the latest japanese connectionist model has incorporated a sequential component in order to improve kanji nonword reading performance. the present study, however, proposed an alternative, fully parallel-distributed processing model to map distributed kanji and kana visual representations to phonemic/moraic representations, with satisfactory nonword reading performance. first cross-linguistic evidence from japanese is provided to support a single-mechanism theory that postulates parallel-processing for both words and nonwords reading.
humans acquire their most basic physical concepts early in development, but continue to enrich and expand their intuitive physics throughout life as they are exposed to more and varied dynamical environments.  we introduce a hierarchical bayesian framework to explain how people can learn physical theories across multiple timescales and levels of abstraction.  in contrast to previous bayesian models of theory acquisition, we work with more expressive probabilistic program representations suitable for learning the forces and properties that govern how objects interact in dynamic scenes unfolding over time.  we compare our model and human learners on a challenging task of inferring novel physical laws in microworlds given short movies.  people are generally able to perform this task and behave in line with model predictions.  yet they also make systematic errors suggestive of how a top-down bayesian approach to learning might be complemented by a more bottom-up feature-based approximate inference scheme, to best explain theory learning at an algorithmic level.
semantic knowledge contains information about both individual concepts and relationships between concepts. relationships come in many forms, including taxonomic and thematic, and are critical for converting collections of attributes known about each entity into an interconnected web of semantic knowledge. according to computational modeling studies, increasing knowledge about entities and their relationships should support increasing elaboration in the organizational structure of semantic knowledge. in contrast, extant empirical research has presented a static picture of the developmental trajectory of semantic organization, in which concepts remain organized according to thematic relations into adulthood. the current developmental study introduces methodological innovations designed to overcome limitations that may have skewed the developmental trajectory described in prior studies. the picture that has emerged from this study reflects dramatic changes in semantic organization from preschool age to adulthood, in which an initially limited grasp of multiple types of relations expands and becomes increasingly robust with age.
this paper examines people’s subjective beliefs about probability distributions arising from repeated events, such as the number of heads in ten coin flips.  across elicitation methods and decision scenarios, people express beliefs that are systematically biased relative to the actual distribution, over-estimating the tails and under-estimating the shoulders of the distribution. while experts are relatively more accurate than novices, both show significant bias.  
the results of several self-paced reading and eye-tracking studies (e.g., pickering and traxler, 2003) have been interpreted to suggest that readers do not use verb subcategorization preference as an early means for completing unbounded dependencies. subsequent papers (e.g., arai and keller, 2013) have hypothesized that this finding may actually be due to the frequency of larger syntactic configurations. this paper utilizes a robust statistical model and finds evidence in support of the latter interpretation: apparent lack of sensitivity to subcategorization preference is shown to be explainable by a confounding frequency effect of syntactic configuration.
how can we make sense of observed instrumental actions that are on a first glance bizarre, i.e., different from what “i myself would have done”? in an attempt to answer this question, the paper sets forth a two-staged reasoning procedure for teleological action explanation: goal assignment, and backward planning. closed-world assumptions about abnormalities frame reasoning to a manageable format under limited processing capacities. non-default instrumental actions may be explained with respect to a goal hypothesis by encountering an abnormality in the action context. the proposed procedure can be modelled in logic programming, and thereby subserve empirical research on the more generic topic of of defeasible reasoning.
the threshold theory of categorization posits that prior to making a categorization decision a respondent assesses the similarity between item and category and compares it against a personal threshold. only if the item-category similarity exceeds this threshold should the respondent endorse the item as a category member. the threshold theory thus assumes that a single latent variable, item-category similarity, suffices to explain all categorization patterns. we put this assumption, known as local independence, to test by providing respondents with sets of four items to categorize. these items are equated in terms of their similarity to the target category, but are by design comprised of two pairs of similar items, such as rollerskates-skateboard and horse-mule for the category of vehicles. contrary to the local independence assumption, the items within the pairs are more likely to receive the same categorization decision than the items across pairs. we explain how these categorization patterns can be accommodated within the threshold theory framework, either by giving up the assumption that everyone assesses item-category similarity in the same way for differently weighted category information, or by explicitly incorporating item-item similarity in addition to item-category similarity. 
a cognitive model of the visual imagination will produce “incoherent” results when it adds elements to an imagined scene that come from different contexts (e.g., “computer” and “cheese” with “mouse”). we approach this problem with a model that infers coherence relations from co-occurrence probabilities of labels in images.  we show that this algorithm’s serial traversal of networks of co-occurrence relations for a particular query produces greater coherence than one leading model in the field of computational coherence: thagard’s connectionist model. 
some recent analyses of language as a transmission medium have fruitfully applied information theory in various ways to sequences of words. in most cases, the information contained in a word is defined as a function of that word’s local context (e.g., its probability conditioned on the preceding word).  a central assumption in much of this work is the important role of context. for example, the hypothesis of uniform information density (jaeger, 2010) requires some notion of context in order to be tested. we sought a structured corpus in order to extend and explore the potential role of a context in the observed information density of messages. specifically, how might a language user’s affective state influence their language use? we used a database of over one hundred thousand consumer reviews that includes an assortment of user-related variables. these user-related variables, such as the overall rating of a review used here as a proxy for a user’s affect, appear to have an interesting relationship to basic information-theoretic measures such as the average amount and variability of observed information of a review's words. we discuss these results in terms of the broader context that may shape the information structure of messages, and relate these findings to existing theories.
dual or multiple systems approaches are ubiquitous in cognitive	science, with examples in memory, perception, categorization,	cognitive development, and many other fields.  dynamical systems	models with multiple stable states or modes of behavior are also	increasingly used in explaining cognitive phenomena.  catastrophe	theory provides a formal framework for studying the dynamics of	switching between two qualitatively distinct modes of behavior.	here we present a parametric approach to testing specific	predictions about the dynamics of such switches that follow from	catastrophe theory.  these so-called catastrophe flags are	bimodality, divergence, and hysteresis.  we show how these three	flags can be tested using (constrained) mixture and hidden markov	models and provide an example of each using three different data	sets.
this study aimed to examine nonverbal expressions of older adults performing a feeling-of-knowing (fok) meta-memory task, since nonverbal cues are considered to serve as indicators of memory deficit awareness. in a production experiment, we collected a variety of recalled and unrecalled answers from older adults (mean age = 79.5) and tested their accuracy. nonverbal behavior was annotated manually and automatically using facial expression detection software. we found an overall effect of fok ratings on the use of fok related nonverbal features. for recalled items, the participants used more nonverbal cues with lower foks than with higher foks. for unrecalled items, the opposite effect was found. a subsequent perceptual study showed that third-party judges were able to estimate older adults’ fok correctly. overall, this study shows that the elderly can be aware of their memory deficits and display the associated nonverbal cues in a manner comparable to younger age groups.
moral criticism is both a social act and the result of complex cognitive and conceptual processes. we demonstrate consensual features of various acts of moral criticism and locate them within a higher-order feature space. people showed consensus in judging 28 verbs of moral criticism on 10 features, and the judgment patterns formed a two-dimensional space, defined by an intensity axis and an interpersonal engagement axis. subsets of verbs formed well-defined clusters roughly corresponding to the four quadrants of this space. the marker verbs of these clusters were lashing out (intense, public), pointing the finger (mild, public), vilifying (intense, private), and disapproving (mild, private).
landmarks are an essential part of human navigation. in most situations, landmarks used for navigation are available in the environment. however, landmarks can also be set up deliberately to facilitate future orientation. the question how such navigator-driven and individual landmark placement affects spatial learning and what strategies are used has rarely been examined. we addressed this question with two experiments. participants explored virtual environments and placed landmarks with the aim of developing a mental map of the environment (measured by sketch mapping, study 1) or to facilitate wayfinding (study 2). their performance was compared to participants who did not place landmarks. landmarks were detrimental to sketch mapping (study 1), and provided no significant advantage for wayfinding (study 2). however, we found strong supra-individual consistencies of landmark placement strategies in both studies, implying a "wisdom of the crowd" for critical landmark locations.
formal logic and probability theory are often considered the most fundamental norms of rational thought, but their application to psychological tasks has raised serious doubts about human rationality. a central finding is that people sometimes judge the probability of a conjunction to be higher than that of its conjuncts (conjunction fallacies, cfs). bayesian logic (bl, von sydow, 2011) formalizes subjective probabilities of noisy-logical explanatory patterns (pattern probabilities) instead of extensional probabilities (relative frequencies), and predicts a system of rational inclusion fallacies. this paper distinguishes a monadic from a dyadic pattern explanation of cfs; it tests two corresponding formalizations of bl (the former concerned with cells, the latter with marginals); and it models pattern probabilities in a novel way (based on acceptance thresholds). in an experiment we varied observed frequencies and formulations. the results deviate radically from narrow norms but they corroborate the idea of monadic and dyadic pattern probabilities.
the study of semi-supervised category learning has shown mixed results on how people jointly use labeled and unlabeled information when learning categories. here we investigate the possibility that people are sensitive to the value of both labeled and unlabeled items, and that this depends on the structure of the underlying categories. we use an unconstrained free-sorting categorization experiment with a mixture of both labeled and unlabeled stimuli. the results showed that when the distribution of stimuli involved distinct clusters, participants preferred to use the same strategies to sort the stimuli regardless of whether they were given any additional category label information. however, when the stimuli distribution was ambiguous, the sorting strategies people usedwere strongly influenced by the labeled information given. we capture performance in both cases with an extension to anderson’s rational model that does not know the exact number of category labels in advance.
previous studies report that children use color words in a haphazard manner before acquiring adult-like meanings. the most common explanation for this is that children struggle to abstract color as a domain of linguistic meaning, and that this results in a stage in which children produce but do not comprehend color words. however, recent evidence suggests that children’s early usage of color words is not random, and that they acquire partial but systematic meanings prior to acquiring adult-like meanings. here we employ parent report, a color word production task and an eye-tracking comprehension task to provide further support for this conclusion and show for the first time that toddlers often acquire color word meanings even before beginning to produce them. 
u.s. students consistently score poorly on international mathematics assessments. one reason is their tendency to approach mathematics learning by memorizing steps in a solution procedure, without understanding the purpose of each step. as a result, students are often unable to flexibly transfer their knowledge to novel problems. whereas mathematics is traditionally taught using explicit instruction to convey analytic knowledge, here we propose the causal contrast approach, an instructional method that recruits an implicit empirical-learning process to help students discover the reasons underlying mathematical procedures. for a topic in high-school algebra, we tested the causal contrast approach against an enhanced traditional approach, controlling for conceptual information conveyed, feedback, and practice. the causal contrast approach yielded remarkably greater success, especially on novel problems, across students with varying levels of mathematical competence. 
explicitly presented task-irrelevant targets are facilitated in a later recognition test, provided they frequently appear synchronously with targets from a previously presented relevant task (dewald & sinnett, 2013). this dual task paradigm was used to test the relationship between the modality of which a primary task was presented, and the modality of a subsequently presented secondary task. earlier findings suggest that cross-modal presentations lead to higher facilitation rates for items that were previously aligned with auditory targets when compared with only unimodal (auditory or visual) presentations. the current study extends these findings to conditions where the primary task is presented visually, while testing later word recognition in either the same (visual), different (auditory), or across (audiovisual) modalities. overall, target-aligned information was recognized at significantly higher rates than non-aligned information for all three recognition tests. critically, when comparing the magnitude of facilitation, cross-modal presentation resulted in the highest degree of facilitation.
the effects of fatigue on cognitive processing are not fully understood. computational modeling research has led to two distinct accounts of fatigue, and specifically its effects on psychomotor vigilance performance, which are both supported by empirical findings. the first account is based on act-r and posits that fatigue increases the probability of microlapses. a biomathmatical model of fatigue modulates this probability. the second account is based on a diffusion model and posits that fatigue decreases the drift rate of the diffusion process. the same biomathematical model of fatigue is used to control the drift rate parameter. we compare the models’ predicted reaction time distributions to one another and to human data in a psychomotor vigilance performance task. though they embody entirely different modeling approaches and different levels of abstraction, the accounts generate equivalent predictions and capture the detrimental effects of fatigue through mechanisms that have similar theoretical interpretations. in both accounts, fatigue effectively increases the contribution of noise to cognitive processing and decreases neural inhibition. this unexpected convergence supports a more general account of how sleep deprivation impairs psychomotor vigilance performance through degradation of the quality of cognitive processing.
behavioral studies suggest that manipulable artifact concepts are largely organized around action-based knowledge with thematic and functional relations being privileged ways to group objects together. moreover, recent eye tracking studies have shown that thematic and functional knowledge are activated with different temporal dynamics during object conceptual processing. in order to assess the neurophysiological correlates of thematic and functional knowledge activation, we used a priming paradigm in which event-related potentials were recorded during object identification. the neural response was analyzed as a function of the type of semantic relation shared by prime and target objects: thematic [saw-wood], specific function [saw-axe] and general function [saw-knife]. results revealed graded priming effects on the n400 component that could be related to processing time course differences. findings support the hypothesis of distinct cognitive and neurophysiological mechanisms underlying thematic and functional knowledge. 
some research has suggested that face and object recognition are independent abilities. recently, however, it has been shown that they are not, and that the relationship is moderated by experience with the object categories (gauthier et al., in press). gauthier et al. suggest that a domain general ability underliesface and object recognition that is expressed when people have sufficient experience in that category. using the cambridge face memory test (cfmt) and vanderbilt expertise test (vet), they showed that as experience with non-face object categories grows (averaged over all eight categories of the vet), the shared variance between the cfmt and vet performance increased monotonically. this theory fits with our neurocomputational model (“the model”, tm, cottrell and hsiao (2011)), since in tm, categories differentiated at the subordinate level are recruited by the face network (tong, joyce, & cottrell, 2008). we model “domain general ability” as the resources available for the mapping from images to labels (the number of hidden units), and “experience” as the number oftraining epochs with non-face objects. we show that, as in the data, the shared variance between the performance on faces and the performance on subordinate-level object categorization increases as experience grows. our results thus suggest that a potential source for the variance in the “domain general ability” between individuals is the amount of representational resources available for fine-level discrimination. one might have expected that faces and objects compete for this shared resource, leading to a negative correlation between them. our analysis of the hidden unit representations shows that they share a “spreading” transform, that moves similar objects apart in representational space, consistent with our previous analyses suggesting that this is why the the fusiform face area is recruited by new categories of expertise (tong et al., 2008).
theories in concept learning predict that interleaving instances of different concepts is especially beneficial if the concepts are highly similar to each other, whereas blocking instances belonging to the same concept provides an advantage for learning low-similarity concept structures. this suggests that the performance in concept learning tasks can be improved by grouping the instances of given concepts based on their similarity. to explore this hypothesis, we use physical bongard problems, a rich categorization task with an open feature space, to analyze the combined effects of comparing dissimilar and similar instances within and across categories. we manipulate the within- and between-category similarity of instances presented close to each other in blocked, interleaved and simultaneous presentation schedules. the results show that grouping instances to promote dissimilar within- and similar between-category comparisons improves the learning results, to a degree depending on the strategy used by the learner.
most learning models assume, either implicitly or explicitly, that the goal of learning is to acquire a complete and veridical representation of the world, but this view assumes away the possibility that pragmatic goals can play a central role in learning. we propose instead that people are relatively frugal learners, acquiring goal-relevant information while ignoring goal-irrelevant features of the environment. experiment 1 provides evidence that learning is goal-dependent, and that people are relatively (but not absolutely) frugal when given a specific, practical goal. experiment 2 investigates possible mechanisms underlying this effect, and finds evidence that people exhibit goal-driven attention allocation, but not goal-driven reasoning. we conclude by examining how frugality can be integrated into bayesian models of learning. 
in two language production experiments, we investigated whether stored knowledge of the typical color of objects affects spoken reference. in experiment 1, human speakers referred to objects with colors ranging from very typical (e.g., red tomato) to very atypical (e.g., blue pepper). the probability that speakers redundantly include color in their descriptions was almost linearly predicted by the degree of atypicality. in experiment 2, we extended this finding to references to objects for which color is inherently a less salient property in stored knowledge (i.e., objects with a highly characteristic shape, making color less important for recognition). following these findings that typicality affects reference production, we conclude that speakers utilize stored knowledge about everyday objects they refer to. we discuss the implications of our findings for artificial agents that generate natural language, arguing that computational models fall short in capturing general knowledge about typical properties of objects.
we study two different models of a turn-based game called the marble drop game, which is an experimental paradigm designed to investigate higher-order social reasoning. our first model is a computational-level description of the game, associating cognitive difficulty of a game trial with its structural properties. our second model is an algorithmic-level model postulating a forward reasoning plus back-tracking strategy for solving the game, rather than backward induction as prescribed by game theory. our experiment shows that the algorithmic-level model is more predictive for the participants’ reaction times.  this research illustrates how various methods of logic and computer science may be used for building computational cognitive models. 
it is widely acknowledged that causation entails more than spatial-temporal contiguity or correlation, but efforts to specify that extra component of experience have been elusive. in this paper, we argue that the representation of causal relations is based on the feeling of force as understood through the sense of touch. grounding causation in people’s sense of touch allows us to address long-standing challenges that have been raised against force-based approaches to causation. in support of our proposal, we report a series of experiments showing that the perception of causation is associated with the notion of force, as indicated by changes in people’s sensitivity to a physical force acting against their hand. we also show that when people associate correlations with force, they view those correlations as causal. implications for understanding the origins of causal knowledge are discussed.
most vision research on motion analysis focuses on learning human actions from video clips. in this paper, we investigate the use of still images, rather than videos, for motion recognition. we present evidence from both human cognition and computer vision that still images do indeed contain a wealth of information about motion patterns. our contributions are three-fold. first, we automatically determine classes of motions that can effectively be characterized by still images.  to make this determination we introduce the notions of motion verbs (m-verbs) and motion phrases (m-phrases); these refer to linguistic concepts motivated by visual cognition and are not restricted only to motions performed by humans. second, we build ucsd-1024, a large dataset distilled from more than two million still images. these images come from 1,024 categories of motion; we use crowdsourcing to provide human validation of the motion categories. third, we exploit motion patterns from ucsd-1024 using a weakly-supervised learning strategy and demonstrate performance competitive with state-of-the-art computer vision action classification methods.
theory of mind research has looked at how learners infer an agent’s unobservable mental states from observable actions. however, such research has tended to neglect another observable source of data: the agent’s reactions to events. in particular, the agent’s facial reactions might provide important information about her mental states that are otherwise ambiguous given her actions. here we present a bayesian framework and a behavioral study testing how adults use an agent’s facial reactions to reason backward about her beliefs and desires. we found that participants’ joint inferences of belief and desire from facial expressions were predicted by a bayesian model analysis, based on integrating the likelihoods of the observed facial reactions and the observed action with their prior over mental states. we argue that people’s naïve theory of emotional reactions is structurally and causally intertwined with theory of mind in a way that allows forward prediction and backward inference.
languages differ qualitatively in their numeral systems. at one extreme, some languages have a small set of number terms, which denote approximate or inexact numerosities; at the other extreme, many languages have forms for exact numerosities over a very large range, through a recursively defined counting system. what explains this variation? here, we use computational analyses to explore the numeral systems of 25 languages that span this spectrum. we find that these numeral systems all reflect a functional need for efficient communication, mirroring existing arguments in the domains of color, kinship, and space. our findings suggest that cross-language variation in numeral systems is shaped by the functional need to communicate precisely, using minimal cognitive resources.
since saussure, the idea that the forms of words are arbitrarily related to their meanings has been widely accepted. yet, implicit metaphorical mappings may provide opportunities for iconicity throughout the lexicon. we hypothesized that vertical spatial metaphors for emotional valence are manifested in language through space in signed languages and through the spatialized dimension of pitch in spoken languages. in experiment 1, we analyzed the directions of the hand motions constituting words in three signed languages, and related them to the valence of their english translation equivalents. the vertical direction of signs predicted their valences. on average, signs with upward movements were the most positive in valence, and signs with downward movements the most negative. signs with non-vertical movements were intermediate in valence. experiment 2 extended this type of analysis to a tonal language, mandarin chinese. the pitch contours of chinese words predicted the valence of their english translation equivalents. 
the current study investigated the interactions among category structure, supervision, and the ability to selectively attend during category learning. speciﬁcally, we compared pigeons’ with human adults’ category learning using artiﬁcial categories to examine the role of selective attention in category learning. results showed that pigeons beneﬁt more from supervision, and unlike human adults, the beneﬁt is stronger for sparse categories. moreover, whereas supervision did not affect human adults’ generalization performance, low-supervision resulted in lower generalization for pigeons. the results were discussed in terms of the difference in utilizing the supervisory signal, and the ability to selectively attend to category relevant information.
spatial reasoning ability is enhanced by spatial activities and spatial language. spatial games (e.g., block building, assembling jigsaw puzzles) are often accompanied by spatial language, which, in turn, is often accompanied by co-speech gesture.  here we investigate the effects of spatial language and gesture in the context of puzzle play in improving preschool children’s puzzle assembly ability. we do this by conducting a training study in which we independently manipulate the presence of spatial language and the presence of gesture in the context of four jigsaw puzzle training sessions.  our findings show that providing co-speech gesture along with spatial language is particularly effective in improving children’s ability to put together puzzles on their own.
children learn their earliest words through social interaction, but it is unknown how much they use social information. some theories argue that word learning is fundamentally social from its outset, with even the youngest infants understanding intentions and using them to infer a social partner’s target of reference. in contrast, other theories argue that early word learn- ing is largely a perceptual process in which young children map words onto salient objects. one way of unifying these ac- counts is to model word learning as weighted cue-combination in which children attend to many potential cues to reference, but only gradually learn the correct weight to assign each cue (hollich, hirsh-pasek, & golinkoff, 2000). we test 3 predictions of a naive cue-combination account and show each to be incorrect. thus, while aspects of this unifying account are correct, it must be amended to capture the dynamics of children’s behavior across differing referential situations.
the unaccusativity hypothesis (uh) holds that intransitive verbs are divided into two broad classes, namely unaccusatives and unergatives. while there is evidence that the uh holds cross-linguistically, it is known that languages do not divide the intransitives into two uniform groups. we investigate the unaccusative-unergative distinction in turkish by an offline grammaticality judgment task using a visual analog scale and by running an eye tracking experiment to tap on cognitive processing of split intransitivity. cluster analyses indicate that the results of two experiments are broadly compatible, i.e., native speakers represent intransitive verbs in two classes, as the uh predicts. however, the offline experiment results specify uncontrolled process verbs as unaccusative, whereas the eye-gaze data characterize them as unergative. this result lends partial support for auxiliary selection hierarchy. we also suggest that the uncontrolled process verb class might be where the unaccusative-unergative split occurs in turkish. 
older adults are often susceptible to confusing or forgetting medical instructions. the purpose of the present study was to examine the effects of causal knowledge on the learning and retention of medical information among younger and older adults. participants were asked to read about a fictitious disease with or without explanations on the cause-and -effects of illness management. a multiple-choice knowledge test was administered immediately and 1-week following the presentation of health booklets. results demonstrated that causal knowledge facilitated the application and retention of novel medical knowledge across time for younger adults. in contrast, causal explanations did not seem to influence the test performances of older participants.  after controlling for age, verbal ability, working memory, and health literacy, provision of causal explanation explained a significant amount of unique variance in test performance. incorporating causal explanations in health education materials may have the potential to help patients acquire medical knowledge. 
human subjects exhibit ``sequential effects" in many psychological experiments, in which they respond more rapidly and accurately to a stimulus when it reinforces a local pattern in stimulus history, compared to when it violates such a pattern. this is often the case even if the local pattern arises by chance, such that stimulus history has no real predictive power, and therefore any behavioral adjustment based on these erroneous predictions essentially amounts to superstition.  earlier, we proposed a normative bayesian learning model, the dynamic belief model (dbm), to demonstrate that such behavior reflects the engagement of mechanisms that identify and adapt to changing patterns in the environment \cite{yu2009}.  in that earlier work, we assumed a monotonic relationship between prior bias and response time (bias {\it toward} a stimulus was assumed to result in faster reaction time when that was the actual stimulus; conversely, when the other stimulus was present, it was assumed to result in a slower response).  here, we present a more detailed and quantitative analysis of the relationship between prior bias and behavioral outcome, in terms of response time and choice accuracy.  we also present novel behavioral data, along with a framework for jointly identifying subject-specific parameters of the trial-by-trial learning (dynamic belief model, dbm) and within-trial sensory processing and decision-making (drift-diffusion model, ddm) based on the behavioral data.  our results provide strong evidence for dbm, and reveal potential individual differences, in their differential beliefs about the timescale at which local patterns persist in sequential data.
animals routinely adapt to changes in the environment in order to survive. though reinforcement learning may play a role in such adaption, it is not clear that it is the only mechanism involved, as it is not well suited to producing rapid, relatively immediate changes in strategy in response to environmental changes. we explored the possible adaptive mechanisms underlying in a cognitive model of human behavior in a change detection experiment. besides reinforcement learning, the model incorporates counterfactual reasoning to help learn the utility of different task strategies under different environmental conditions. the results show that the model can accurately explain human data and that counterfactual reasoning is key to reproducing the various effects observed in this change detection paradigm.
we present the conditional probability calculator ccpc for predicting word-by-word processing difficulties in human sen- tence comprehension. this system, in conjunction with weighted grammars and the linking hypothesis entropy reduction (hale, 2006), derives the subject-object asymmetry in italian relative clauses, including the animacy effect of head nouns.
the brahms generalized Überlingen model (brahms-gÜm) is a cognitive-behavioral simulation of aviation work practices that reveals how normally complicated situations become cognitively complex for people in a dynamic environment of malfunctioning tools and non-routine workload. brahms-gÜm was developed by analyzing and generalizing the roles, systems, and events leading to an aircraft collision, a scenario that can be simulated as a particular configuration of the model. brahms-gÜm demonstrates the strength of the brahms framework for simulating behaviors of asynchronous (or loosely coupled), distributed processes in which the sequence of spatial-temporal interactions can become mutually constrained and unpredictable.
relatively little is known about the interaction between a bilingual's two languages beyond the word level. this paper investigates the issue by comparing word reading times (rts) in both l1 and l2 to quantitative predictions by statistical language models. recurrent neural networks are trained on either a dutch corpus, an english corpus, or the two corpora combined (i.e., the bilingual network treats the two languages as one). next, estimates of word surprisal by the three models are compared to rts by native dutch speakers on l1 dutch and l2 english sentences. the monolingual dutch model accounts for rts on dutch better than the bilingual model. in contrast, the bilingual model outperforms the monolingual english model on english rts. these findings suggest that sentence comprehension in l1 is not much affected by l2 knowledge, whereas l2 reading does show interference from l1. 
this paper provides an overview of an approach to developing computational models of fatigue, which has been used to develop detailed accounts of laboratory phenomena, and to make a priori predictions in more naturalistic tasks. the research has led to novel theories and mechanisms that help to build bridges between integrated theories of human cognition from cognitive science and theoretical and mathematical research on sleep and fatigue. moreover, this research lays the foundation for new technologies to help mitigate fatigue risk in applied settings.
many species change their signals in response to crowding, consistent with information theoretic accounts of signalling in the presence of noise. in this article we explore the hypothesis that the statistical structure of language has evolved to enhance reception and processing in response to competition in the language market. in particular, we investigate how concreteness has changed over the last 200 years. we take a big data approach, combining large text corpora (including the google ngram corpus, the corpus of historical american english, and presidential speeches) with the recent collection of concreteness norms for over 40,000 english words (brysbaert et al., 2013). across corpora we find that concreteness has steadily increased since the 1800s. this takes place both within and across word classes, indicating that the rise in concreteness is systemic and not limited to changes in grammar. by comparing recent concreteness norms with older norms, we show that the observed changes in concreteness are not due to a bleaching effect caused by the loss of concreteness as words age. we further investigate how the statistical distribution of other properties of words change in a way that may indicate that language is becoming more distinctive. we discuss a number of potential explanations and implications of these changes, including changes in literacy, gender, the flynn effect, and the influence of competition in the marketplace of ideas.
phonologists and psycholinguists draw a three-way distinction amongst real words, possible words, and impossible words.the distinction between real words and possible words provides the foundation for  lexical decision experiments. the distinction between possible words and impossible words reveals implicit cognitive generalizations about words in a language, and thereby contributes to the understanding of language acquisition and processing.  left to the side in this vast body of theory and experimental results is a real understanding of new words. is a new word just a new random selection from the possible words? no. first of all, some possible words are more possible than others. second, there's an important distinction between the creation of a new word, and its adoption by the linguistic community. the creation of a new word is a manifestation of an individual person's cognitive system. but to be widely adopted, it must successfully compete with other words to be used in discourse. in this paper, i review a series of results on how and why some possible words are more possible than others. then, i will introduce work in progress that looks at the interaction of social and cognitive factors in processing new words.
visual search is one of the most common behaviors in daily life. studies of visual search, however, have mainly focused on how visual properties of stimuli affect search efficiency. the current study examined the effects of immediate auditory feedback for each selection during a multiple-target visual search task. in a feedback condition, one of two different sounds was played, indicating whether the subject had reported a correct detection, i.e., was fixating a target. in the neutral sound condition, subjects always received the same sound, regardless of whether they had visually selected a target or a distractor. we analyzed overall performance measures such as trial duration and the proportion of correct target detections and correctly completed trials. furthermore, we analyzed pupil size as a measure of cognitive effort. the results show that pupil dilation was greater and search accuracy was better when subjects were given feedback than when they only received a neutral sound. in summary, the present study demonstrates that immediate feedback may increase cognitive effort, leading to more accurate task performance, with enhancement of specific components of search behavior.
we investigated how the benefits of comparisons (within- and/or between- category comparisons) for generalizing novel names for novel objects along a non-salient dimension (texture) might depend on dimensional distinctiveness. we tested 4- and 6-year-olds. we found that in the case of a lower distinctiveness, older children gave more texture-based answers following within-category comparison whereas younger children gave more texture-based answers in between-category comparisons. when distinctiveness was high, both groups benefited from within-comparison. they also benefited from between-category comparison only when within-category comparison were available (i.e. when both kinds of comparison were available). we interpret these findings in terms of differential costs of comparison for varying levels of distinctiveness along either nonsalient or salient dimensions.
emotions have an influence on attention, decision making, and memory (all factors required for wayfinding). it is assumed that both an emotional state and emotionally laden landmarks have an impact on wayfinding and on later recollection of the path. we performed two experiments to investigate our hypotheses. first, in both experiments participants had to study a route in a virtual environment including landmarks. then they passed a recognition and wayfinding task, which was repeated after one week. the mood was measured using the panas scale. in the first experiment the emotionally laden landmarks were used as a between-subject factor in order to investigate the effect of mood in wayfinding. the aim of the second experiment was to examine the effect of emotionallly laden landmarks (within-subject factor) without affecting the emotional state. results show that emotions have no significant effect on correct recognition, wayfinding and response times (experiment 1). for experiment 2 the results show that the best wayfinding performance occurs when negatively laden landmarks were used. recognition performance was similar, however, hardly decreased over time for the negative stimuli. these findings are discussed within the current research literature.
the acquisition of mental state verbs (msvs) has been extensively studied in respect to their common occurrence with sentential complement syntax. however, msvs also occur in a variety of other syntactic structures. moreover, other verb classes frequently occur with sentential complements, e.g., communicationand perception verbs. the similarity in distribution of the various verb classes over syntactic patterns may affect the acquisition of the meaning of msvs by association. in this study we present a novel computational model to learn verbclasses, which allows us to analyze the association of mental verbs to their meaning over a variety of syntactic patterns. our results point to an important role of the full syntactic preferences of msvs on top of their occurrences with sentential complements.
here we introduce a simple actor-critic model of eye movements during category learning that we call rlattn (reinforcement learning of attention). rlattn stores the rewards it receives for making decisions or performing actions, while attempting to associate stimuli with particular categories. over multiple trials, rlattn learns that a large reward is most likely when the values of the relevant stimulus features have been revealed by fixations to them. the model is able to approximate human learning curves in a common category structure while generating fixation patterns similar to those found in human eye tracking data.  we additionally observed that the model reduces its fixation counts to irrelevant features over the course of learning.  we conclude with a discussion on the effective role eye movements might play in bridging structural credit assignment and temporal credit assignment problems.
in current approaches to pragmatic reasoning the comprehension and production of referring expressions is modeled as a result of the interlocutors' mutual perspective-taking under the additional assumption that speakers try to minimize their articulatory effort or production cost. the latter assumption is usually not tested and instead built into the experimental tasks of referential language games by artificially restricting the set of possible referring expressions available to identify a referent. we present two language game experiments: a production experiment, in which the speakers were allowed to freely choose a referring expression, and a comprehension experiment to replicate earlier findings with our stimuli. our results show that while listeners easily perform pragmatic reasoning, speakers resort to overspecification when the effort of pragmatic reasoning becomes too high.
i revisit fodor’s (1983) notion of “module” and defend it against views weakening the criteria to consider a process modular. many approaches to modularity (e.g., barrett & kurzban’s, carruthers’, cosmides & tooby’s, and others) are unsatisfying because the notion put forward is uninformative. i will explain why we should understand fodor’s notion of module as identifying a homeostatic property cluster (cf. boyd, 1991). this account should be integrated within a broader view of cognition.
simultanagnosia is a visual cognitive disorder following a bilateral lesion in parieto-occipital brain areas. it affects the patients integrative perception so that scenes or hierarchically organized objects cannot be perceived as a whole but just in a piecemeal fashion. qualitative explanations consider impairments of attentional selection mechanisms, feature binding, or global shape processing. until now, however, no computational model has been used to quantitatively reproduce the performance patients suffering from simultanagnosia. we focus on modeling the impairment of recognizing hierarchical stimuli (navon letters), which have been used in several studies with patients and healthy subjects. in particular, we apply the established hmax model of object recognition, specifically trained on letter recognition, to investigate the role of low-level, bottom-up processing, salience, and the selection of a window of attention. we also assess to which extent a top-down modulatory mechanism is necessary to quantitatively reproduce the global letter recognition performance in patients. our results indicate that as long as a bottom-up segmentation of the global shape from local elements is possible, global shape recognition succeeds. however, when top-down form completion appears necessary to identify the global shape, the current, bottom-up processing model fails. moreover, we replicate training effects in the global task, which are comparable with patients performance in similar tasks. the present results suggest several promising future research directions to extend the model for modeling the mechanisms underlying global shape recognition in healthy subjects as well as the impairments in patients suffering from simultanagnosia.
previous research has shown that bidirectional associative memories (bam), a special type of artificial neural network, can perform various types of associations that human beings are able to perform with little effort. however, considering a simple association problem, such as associating faces with names, iterative type bam networks usually take hundreds and sometimes thousands of learning trials to encode such associations correctly, whereas humans in some conditions learn much faster. the present study therefore proposes an adjustment to a particular type of bam network that increases its performance in a rapid learning condition while processing memory capacity is limited. results show that the modification to the original learning rule of the bhm leads to improved performance when rapid learning is required. moreover, the model preserves its high memory load capacity in standard learning. this study could lead to improved cognitive models that can adapt their behavior in function of the contextual conditions.
we describe the properties of a connectionist network that is able to make decisions in strategic games. we use the structure of bidirectional associative memory (bam), a minimal two-layer recurrent neural network with binary activation functions and binary connection weights. we apply bam to finite-strategy two-player games, and show that network activation in the long run is restricted to the set of rationalizable strategies.  the network is not guaranteed to reach a stable activation state, but any pure strategy profile that constitutes a stable state in the network must be a pure strategy nash equilibrium.   
prior research has provided substantial insight into individuals’ intertemporal preferences (i.e., preferences about delayed rewards). the present study instead investigated the preferences of small groups of individuals asked to express collective intertemporal decisions. the paradigm consisted of three phases. during the pre-collaboration and post-collaboration phases participants completed an intertemporal matching task individually. during the collaboration phase participants completed a similar task in small groups, reaching mutually agreed-upon decisions. results suggest that group preferences were systematically related to group members’ pre-collaboration preferences. in addition, collaborative decision making altered group members’ intertemporal preferences. furthermore, it was found that individuals’ post-collaboration preferences were independently related to both their pre-collaboration preferences and the preferences of other group members, suggesting that individuals’ post-collaboration preferences represented a revision of their pre-collaboration preferences based on the preferences observed in other group members.
expertise affords individuals a variety of advantages for learning and for problem solving, including competing advantages such as using automatic strategies vs. using sophisticated strategies. in the present study, high school students with varying levels of calculus expertise completed measures of conceptual understanding and skill with external representations before a task in which they were asked to coordinate between multiple representations (cmr) and determine whether they represented the same mathematical function. strategy use during the cmr task was coded based on think-aloud data. results indicate that students with more expertise tended to use automatic strategies when completing the task, and, surprisingly, used fewer sophisticated strategies than more novice peers. 
external representations are more effective when spatial dimensions are used to represent numeric variables. however, this principle may result in suboptimal representations when the number of numeric variables to be represented is large. to test this possibility, participants studied a set of graphs representing a parametrized function under different parameter values. the graphs were displayed either using a grid organization, with parameter values represented by spatial dimensions (horizontal and vertical position of the graphs), or juxtaposed in a single area, with parameter values represented by non-spatial dimensions (color and texture). juxtaposed organization led to better learning. however, this advantage was eliminated when the graphs were presented successively rather than simultaneously. the results suggest that juxtaposed organization can improve comprehension of complex data by facilitating comparison between parts of the data. such organization may be preferable even if it precludes use of spatial dimensions for some numeric variables.
three experiments are reported in which the attentional capture effect of sound disappearance was assessed. in all experiments participants were required to judge the pitch of target sounds that were preceded by one or more context sounds.  in experiments 1 and 2, targets presented in the same location as a context sound that had abruptly terminated 100 ms before its presentation, were identified better than target sounds presented in a different location.  this result was obtained both when targets followed a single context sound (experiment 1) and when targets followed pairs of dichotically-presented context sounds that terminated at different points (experiment 2).  the results of experiment 3 replicated those obtained in the previous experiments and showed that under some conditions the facilitative effect could persist at intervals longer than 100 ms. the results of these experiments suggest that under some conditions, the disappearance of a sound can capture attention.
agents typically revise their beliefs when confronted with evidence that contradicts those beliefs, selecting from a number of possible revisions sufficient to reestablish consistency. in cases where an individual’s beliefs concern spatial relations, belief revision has been fruitfully treated as a decision about which features of an initially constructed spatial mental model to modify. a normative claim about belief revision maintains that agents should prefer minimal belief revisions. yet recent studies have rebutted the preceding claim, where minimality is understood to consist in modifying the position of the fewest objects, showing instead that reasoners prefer revisions that modify the position of an object x while retaining the position of an object y, when the agent’s new evidence is a relational statement of the form ‘xry’. we here present cases where the preceding effect is reduced, and show an effect of minimality as measured by the number of initial premises preserved.
nearly all success is due to some mix of ability and luck. but some successes we attribute to the agent’s ability, whereas others we attribute to luck. to better understand the criteria distinguishing credit from luck, we conducted a series of studies on knowledge attributions. knowledge is an achievement that involves reaching the truth. but many factors affecting the truth are beyond our control and reaching the truth is often partly due to luck. which sorts of luck are compatible with knowledge? we find that knowledge attributions are highly sensitive to lucky events that change the explanation for why a belief is true. by contrast, knowledge attributions are surprisingly insensitive to lucky events that threaten but ultimately fail to change the explanation for why a belief is true. these results shed light on our concept of knowledge, help explain apparent inconsistencies in prior work on knowledge attributions, and constitute progress toward a general understanding of the relation between success and luck.
greater over-confidence in answers to multiple choice general knowledge questions has been found for people in east asian countries compared to english-speaking countries. a drawback of this research is difficulty in establishing the equivalence of samples across countries, so we compared students at the same university whose first language was either east asian, english, or other. our earlier research using chinese speaking students suggested under-confidence; however we had presented questions with four response options rather than two. therefore here we also manipulated the number of response options. we found that the east asian group consistently performed worse at a given level of confidence than the other groups, but that they displayed under rather than over-confidence for 4-option items. thus our results were consistent with findings of greater confidence for people with east asian roots, but whether this manifests as over-confidence, under-confidence, or better calibration could depend on the question’s structure.
a central question in the field of language production is the extent to which the speech production system is organized for robust communication.one view holds that speakers' decision to produce more or less clear signals or to speak faster or slower is primarily or even exclusively driven by the demands inherent to production planning. the opposing view holds that these demands are balanced against the goal to be understood. we investigate the degree of hyperarticulation in the presence of easily confusable minimal pair neighbors (e.g., saying pill when bill is contextually co-present and thus a plausible alternative). we directly test whether production difficulty alone can explain such hyperarticulation. the results argue against production-centered accounts. we also investigate how specific hyperarticulation is to the segment that contrasts the target against the contextually plausible alternative.our evidence comes from a novel web-based speech recording paradigm.
there has been little research on infants’ development of causal inference in the second year after birth. we report an experiment in which 9- to 18-month-old infants viewed visual sequences consisting of three looming shapes, one after another. half of the sequences (causes) were predictive of an attention-getting reward (effect), and the other half were non-predictive. the statistical complexity of predictive sequences was varied between conditions. we analyzed latencies of infants’ eye movements toward the reward location. older infants yielded more anticipatory eye movements in predictive than non-predictive sequences. effects of both infant age and complexity of causal sequences were observed. to qualitatively account for these findings, we formulated a bayesian model based on generic priors favoring simple causal events coupled with noisy shape identification.
studies suggest that mimicking specific gestures prior to math instruction facilitates learning. however, benefits could be due to the eye movements that accompany gesture, rather than to gesture per se. children (m age = 8 yrs, 9 mos) who solved pretest equations incorrectly were taught a correct strategy for solving equations. they were randomly assigned to mimic gestures instantiating the strategy, the eye movements that accompany those gestures, or speech only prior to and during instruction. children completed an immediate posttest and a 4-week follow-up test. we hypothesized that children in the eye movement and gesture conditions would retain more from instruction when compared to children in the speech only condition. posttest performance was similar across conditions. contrary to hypotheses, children in the gesture condition retained less from instruction when compared to children in the other conditions. results suggest that there may not always be benefits of gesture during instruction. 
senticnet is a publicly available semantic and affective resource for concept-level opinion mining and sentiment analysis. rather than using graph-mining and dimensionality-reduction techniques, senticnet 3 makes use of `energy flows' to connect various parts of extended common and common-sense knowledge representations to one another. senticnet 3 models nuanced semantics and sentics (that is, the conceptual and affective information associated with multi-word natural language expressions), representing information with a symbolic opacity intermediate between that of neural networks and of typical symbolic systems.
between the dawn of the internet through year 2003, there were just a few dozens exabytes of information on the web. today, that much information is created weekly. the opportunity to capture the opinions of the general public about social events, political movements, company strategies, marketing campaigns, and product preferences has raised increasing interest both in the scientific community, for the exciting open challenges, and in the business world, for the remarkable fallouts in marketing and financial prediction. keeping up with the ever-growing amount of unstructured information on the web, however, is a formidable task and requires fast and efficient models for opinion mining. in this paper, we explore how the high generalization performance, low computational complexity, and fast learning speed of extreme learning machines can be exploited to perform analogical reasoning in a vector space model of affective common-sense knowledge. in particular, by enabling a fast reconfiguration of such a vector space, extreme learning machines allow the polarity associated with natural language concepts to be calculated in a more dynamic and accurate way and, hence, perform better concept-level sentiment analysis. 
the way gaze cues are used in social interactions is by no means irrelevant, as they are fundamentally important to understand social interactions. in this paper, we argue that social conflict is a form of relating and that gaze clues are critical to understand the underlying cognitive processes to this phenomenon. for that purpose, we created an experimental setting that reduces real-life to a mixed motive game. we analyse the gaze patterns of twenty-two 10- to 12-year-old children, in specific moments of the game, which may be conductive for conflict. our aim is to understand how subtle forms of conflict unroll, by analysing micro-level behaviours and establish a link to high-level psychological constructs. we have found that children look more intensely to the partner when they try to get a larger profit and they look longer when they try to reach a less profitable agreement, showing a more collaborative attitude. they also shift the attention to the other when they think the other might felt exploited. 
how do people recover precise meanings from ambiguous utterances? frank and goodman (2012) proposed that listeners do this by rationally combining evidence about word meaning and the salience of particular objects in context. they found that a bayesian model based on this idea provided a near-perfect account of their empirical data. however, their test of the model was based on communication about simple geometrical objects that varied along only three dimensions. here, we ask whether their proposal extends to the richer and more complex domain of spatial relations. we find that it does. while the results are not as strong as in their original study, they nonetheless demonstrate that simple formal accounts of communication may capture important aspects of pragmatic inference. 
using a novel apparatus coupling a visual illusion with an eye tracker device, trained participants are able to generate smooth pursuit eye movements, even without a target to follow. this allows them to perform arbitrary continuous shapes, and, for instance, write letters with their eyes. in a previous study, based on data from a single writer (author jl), we developed and tested a bayesian computational model – the bap-eol model – able to simulate character recognition. in the present study, data from different writers provide the opportunity to study the signal characteristics of eye-written letters. more precisely, we extend the model to perform writer recognition. experimental results, and high performance we obtained, show that eye writing is as writer specific as handwriting is, and that motor idiosyncrasies are present in eye-written letters.
chunk decomposition and assembly strategies have been found in the drawing of complex hierarchical diagrams (spe- cifically avow diagrams). analysis of 40 diagrams pro- duced by five participants provided evidence for the strategies based on the duration of pauses between drawn elements. the strategies were initially discovered using a new visualiza- tion technique developed to allow the detailed examination of the sequential order of diagram drawing in conjunction with information about the durations of pauses associated with drawn elements.
previous studies on reference tracking have established the importance of semantic factors in affecting the likelihood of re-mentioning a referent. this paper extends this line of research by investigating the interaction between syntax and semantics in this process. we conducted a chinese sentence-completion experiment and found that the degree of syntax-semantics mismatch affects a referent’s likelihood of re-mention. the results thus support a theory relating a referent’s salience in discourse to its likelihood of re-mention.  
young children are remarkably prosocial towards humans. however, it is less clear what drives children’s prosociality towards non-human others. here we explore the possibility that children’s moral regard stems from their understanding of others as autonomous beings. to investigate this possibility, we asked five and seven-year-old children to interact with a robot dog that appeared to be either moving autonomously (displaying self-generated movement), or appeared remote-controlled by the experimenter. compared with controlled robot, the autonomous robot caused children to ascribe higher emotional and physical sentience to the robot, to reference the robot as having desires and physiological states, and to reference moral concerns as applying to the robot. children who owned a dog at home were also more likely to behave prosocially towards the autonomous robot. results imply a potential role of technology on children’s developing social cognition and prosocial behavior.
the study investigates how the speaker grounds meaning for a referent by gestural repetition along with speech in conversation. each stretch of talk encompasses the whole joint action during which similar gestures to depict the same referents are produced across turns. a particular cross-modal grounding strategy was found: the previous speaker’s gesture is replicated to form a semantic foundation shared by the participants; upon such common ground in gesture, the speaker readily conveys new meaning with a new lexical expression. the use of the cross-modal grounding strategy facilitates the expression of shared knowledge in gesture and new meaning in speech within a clause. it also bears out the bilateral process of speaking: during the construction of utterance, the speaker grounds new meaning by considering the addressee’s current state of knowledge as revealed by gestural repetition. in turn, the addressee informs the speaker about his/her acknowledgement of the newly established meaning.
the key difference between the cognitive abilities of humans and other animals may be the ability to reason relationally; models of relational reasoning are one way to demonstrate this proposed difference. the present work uses the dora model to simulate a task designed to assess the theory of mind capabilities of 4- and 5-year-old children and apes. in the original experiment, the apes and children successfully completed a number of control tasks in which they used cues from an experimenter to reason about the hiding location of a reward. however, only the children succeeded on the critical manipulation in which it was necessary to infer what the experimenter knew. the simulations presented herein demonstrate that the apes’ performances across all tasks can be accounted for by simple rule use. conversely, the 4-year-olds succeeded via relational inference and learning; 5-year-olds alone had the requisite relational structures predicated beforehand.
visual narratives often depict images of individual characters without showing the larger scene, meaning that this whole spatial environment must be inferred from these component parts. however, few theoretical models of narrative or discourse have attempted to explain the generation of such “additive” inference. this paper explores the complex interactions between narrative structure and meaning within these types of discourse phenomena, situated within the model of visual narrative grammar based on jackendoff’s (2002) parallel architecture of linguistic structure. narrative “conjunction” repeats a single narrative category within a broader constituent, allowing for expansion of a sequence beyond the canonical narrative arc. these conjoined units then correspond to semantic structures in a variety of ways, allowing an “additive” inference of actions, scenes, characters, and/or semantic associative networks. this simple yet powerful architecture enables us to account for a large variety of phenomena in visual narratives and other discourse contexts, while providing a structure that can be tested in empirical research.
the resolution of temporary syntactic ambiguity involves not only the reanalysis of syntactic structure but also the resolution of the conflict between the new correct interpretation and the initial incorrect parse.  the current study investigated the contribution of domain-general conflict resolution ability as indexed by performance on an n-back task (with lures) and the online resolution of temporary syntactic ambiguity as indexed by the p600.  p600s for temporarily ambiguous sentences were predicted by accuracy for n + 1 lures. no such relationship was found for unambiguous, syntactically complex sentences.  these results suggest that domain-general conflict resolution ability underpins the online resolution of temporary syntactic ambiguity.
a key goal of category learning research is to describe how categories are represented. essential to this research are measures that provide investigators insight into exactly what learners have gained from their training experience. in this paper, we review and explore three commonly used measures: a) ease of acquisition, b) generalization, and c) single feature classification. we report results of a category learning experiment in which these measures are compared side-by-side. we find that generalization and single feature classification data are the more informative measures; we also find a novel inconsistency between them. specifically, many learners who generalize based on only a single dimension demonstrate robust knowledge of both dimensions during the single feature classification test. we discuss implications for methodology in the field, as well as for selective attention and theories of human category learning.
we hypothesized that gestures, which are often schematic in form, might play a role in making ideas more schematic and thus more transferable to new contexts. adapting gick & holyoak’s (1983) analogical reasoning paradigm, we had participants read and retell two stories, one after the other, and then try to describe their similarities. the stories share a helpful strategy for solving a problem that participants would encounter later. contrary to predictions, participants who spontaneously gestured about the helpful strategy during the retelling phase did not solve the problem as frequently as those who kept their hands still. but participants who spontaneously gestured about the strategy when comparing the stories during the similarities phase were not hindered in the same way. our results suggest that gesture may have contrasting effects at different stages of analogical reasoning, perhaps through a common mechanism of maintaining and entrenching representations.
two experiments document effects of experienced outcome feedback on risk behavior in a repeated description-based decision task. in study 1, participants were initially strongly risk-seeking in the loss domain, but became less so across 100 repeated trials with outcome feedback. no significant trend was observed for gain problems.  participants then experienced an additional 100 trials of the reflected gain or loss problem.  trends in risk preferences across these set 2 trials were similar to those in set 1, however, initial set 2 levels of risky-option choices were shifted towards ev-maximization, suggesting a cross-domain effect of prior experience.  study 2 attempted to distinguish between reinforcement-learning and monetary reference-point explanations of these cross-domain effects by “endowing” participants facing 100 gain (loss) trials with a large starting loss (gain).  endowment with a large prior gain mimicked the effects of 100 prior gain trials for loss-domain decisions, favoring the reference-point account.
traditional semantic theories assume that meaning arises from the syntactic combination of amodal symbols processed by a modular subsystem. this idea has two striking implications: first, sensory-motor experience has no relevance in language processing; secondly, since the domain of syntactic rules is the sentence, linguistic interpretation takes place in a two-step fashion such that discourse-level information is considered only after establishing sentence local meaning. this paper calls into question both these assumptions. contrary to the predictions of two-step models, in the present erps study we found evidence of the power of discourse in overwriting local semantic violations (e.g., using a funnel to hang the coat) and in making locally acceptable combinations (e.g., using a funnel to pour water into a container) globally incongruent. since context systematically affected the action possibilities of an object, the current results also challenge traditional theories showing that affordances are immediately integrated in the creation of new meanings.
complex, dynamic environments present special challenges to autonomous agents. specifically, agents have difficulty when the world does not cooperate with design assumptions. we present an approach to autonomy that seeks to maximize robustness rather than optimality on a specific task. goal-driven autonomy involves recognizing possibly new problems, explaining what causes the problems and generating goals to solve the problems. we present such a model within the midca cognitive architecture and show that under certain conditions this model outperforms a less flexible approach to handling unexpected events.
two experiments examined participants’ use of independent and relational category structures in a spatial memory task. when estimating the locations of dots presented on a rectangular display, many participants appeared to divide the space into left and right relational categories, biasing estimates away from the center of the screen and toward the outer edges, in contrast to prior work showing biases toward centrally located prototypes.  more participants showed this relational pattern at short interstimulus intervals than at long ones. the results suggest that participants flexibly make use of different types of spatial structure under different task demands.  keywords: spatial memory; categorization.
children as young as age 3 understand that different people have different areas of expertise (i.e., the division of cognitive labor) and they choose information sources accordingly (e.g., lutz & keil, 2002). however, it is unclear whether this understanding depends primarily on social cognitive skills, such as an appreciation of others’ mental states, or non-social cognitive skills, such as the ability to categorize different types of entities. to address this question, children ages 3 to 5 (n=63) completed tasks measuring social and non-social cognitive skills, and made inferences about what two unfamiliar experts would know. the results demonstrate that developmental differences in children’s understanding of expertise are mediated through concomitant differences in categorization ability, but not theory of mind
how do ordinary people decide whether an individual object at t1 is the same individual at t2? we show that valence—people’s value judgments about whether a given trait is good or bad—can influence this decision. this effect is explained by people’s tendency to believe that the underlying essence of an entity is good, and may be part of a far wider phenomenon of how people understand essences in general—be they of humans, categories, or even non-human objects.
computers increasingly perform a variety of important tasks and services that influence individuals and organizations, yet few studies tell us about how humans interact with computers and other non-human decision-makers. in four experiments, we asked people to engage in cooperation tasks with computers and with humans. experiment 1 found that people gave more money to a human than a computer. we argue this effect reflects a basic bias in favor of humans, which are perceived to be the in-group, when compared to computers, which are perceived to be the out-group. in experiment 2, we varied computer and human ethnicity to be the same or different as the participant; results indicated that ethnicity had a parallel but additive effect that was independent to the effect of the human social category. the data of experiment 3 indicate that it is also possible to promote group membership with computers by creating structural interdependence based on shared incentives. finally, we demonstrate in experiment 4 that our framework based on social categorization theory can predict situations where people will cooperate more with computers than with humans. we discuss implications for understanding people’s decision making with human and non-human others.
sequential learning (sl) is believed to be an essential component of language development. despite support from behavioral studies, neural evidence of this relationship, especially in children, is scarce. the current study measured 7-12-year-olds’ erps to a visual sl task involving incidental learning of probabilistic relationships between predictors and targets presented within a serial input stream. various aspects of language and cognitive development were assessed with standardized tests. results on the sl task showed that children demonstrated sl as determined by differences in erp amplitudes and response times for predictor conditions that varied with the probability of predicting the target. crucially, the amplitude of erp difference waveforms was positively correlated with language ability and cognitive control. these findings validate the use of a probabilistic visual predictor-target task to investigate sl in children and, most importantly, provide neural evidence of a close relationship between sl, language development and cognitive control.
though human beings are experts in the determination of aspectual relations, current models of aspect lack principled parsimony. we show that even on a limited segment of language, determining aspectual interpretations seems to require much ad hoc information. our suggestion is to give parsimony first priority. the model we present in this paper is limited in scope, but its complexity is bounded in principle.
theories in embodied cognitive science emphasize the importance of self-other mapping during emotion perception. this implies the body form through which an emotion is expressed may impact how the emotion is perceived. research in human computer interaction has demonstrated that people can reliably label emotions of virtual characters; however, it has hardly examined how people perceive the emotions of virtual characters at a visceral level. here, we asked participants to identify under time pressure for action, whether an observed bodily movement is angry or happy. our research provides evidence that emotions conveyed by non- human virtual characters and humans are indeed perceived differentially, at the visceral level. this work carries implications for theories of embodied cognition and the design of virtual environments.
when people use mathematics to model real-life situations, their modeling is often mediated by semantic alignment (bassok, chase, & martin, 1998): the entities in a problem situation evoke semantic relations (e.g., tulips and vases evoke the functionally asymmetric “contain” relation), which people align with analogous mathematical relations (e.g., the non-commutative division operation, tulips/vases). here, we applied the semantic-alignment framework to understand how people use rational numbers as models of discrete and continuous entities. a textbook analysis revealed that mathematics educators tend to align the discreteness vs. continuity of the entities in word problems (e.g., marbles vs. distance) with distinct symbolic representations of rational numbers—fractions vs. decimals, respectively.  we discuss the importance of the ontological distinction between continuous and discrete entities to mathematical cognition, the role of symbolic notations, and possible implications of our findings for the teaching of rational numbers.
developmental research has focused on the challenges that fractions pose to students in comparison to whole numbers. usually the issues are blamed on children’s failure to properly understand the magnitude of the fractional number because of its bipartite notation.  however, recent research has shown that college-educated adults can capitalize on the structure of the fraction notation, performing more successfully with fractions than decimals in relational tasks, notably analogical reasoning. the present study examined whether this fraction advantage also holds in a more standard mathematical task, judging the veracity of multiplication problems.  college students were asked to judge whether or not a multiplication problem involving either a fraction or decimal was correct.  some problems served as reciprocal primes for the problem that immediately followed it. participants solved the fraction problems with higher accuracy than the decimals problems, and also showed significant relational priming with fractions.  these findings indicate that adults can more easily identify relations between factors when rational numbers are expressed as fractions rather than decimals.
this paper presents a cognitive model—the sensory motor system (sms)—for an action execution process, as a new module of the lida systems-level cognitive model. action execution refers to a situation in which a software agent or robot executes a selected goal-directed action in the real world so as to output pertinent movement. action execution requires transforming a selected goal-directed action into lower-level executable actions, and executing them. a sensorimotor system derived from the subsumption architecture has been implemented into the sms; and several cognitive neuroscience hypotheses have been incorporated as well, including the two visual systems and others. a computational sms has been created inside a lida-based software agent in webots to model the execution of a grip action. the grip’s design is inspired by the arm controller of the robot herbert and the current study of human’s action execution. simulated results are compared to human performance.
emergence is pervasive in complex systems, and often produces surprising phenomenon that are challenging to understand and apply, especially regarding inter-level causalities. here, we study engineering undergraduates’ capacity to understand and solve design problems concerning inter-level causalities in nanomechanical biological systems. we developed a gui with an agent-based molecular simulation that calculates performance and renders animations in real-time as users adjust design inputs. we randomly assigned undergraduate engineering students to learning groups with support of animated simulations or charts. both groups improved on pre/post design problems. on assessments of understanding inter-level causality, only the animation group demonstrated an understanding. both groups were then presented contrasting animations of continuous and intermittent systems, resulting in about half of participants in each group demonstrating an understanding of inter-level causal behaviors. study findings demonstrate the difficulty in understanding inter-level causal relationships, the helpfulness of software tools, and that greater learning may improve design performance.
the existence of an advantage in sequential learning for musicians over nonmusicans is highly debated. the current study used an auditory sequential learning task to investigate the neurophysiological correlates of sequential learning in adults with either high or low music aptitudes. while behavioral results alone revealed no difference between the reaction times of the two groups, event-related potential data showed that higher music aptitude was associated with decreased amplitudes of the p300 and contingent negative variation effect between two conditions with different transitional probabilities relative to a target stimulus. these data suggest that increased music training and skill leads to more efficient processing of (i.e., reduced attentional demands for) auditory sequential patterns. 
we investigate the hypothesis that multisensory representations mediate the crossmodal transfer of shape knowledge across visual and haptic modalities. in our experiment, participants rated the similarities of pairs of synthetic 3-d objects in visual, haptic, cross-modal, and multisensory settings. our results offer two contributions. first, we provide evidence for a single multisensory shape representation common to both visual and haptic modalities. second, our analyses suggest that these representations are part-based, representing objects as compositions of subparts.
while goal orientation and related factors like learner self-efficacy are of great interest to learning science researchers, some voice concerns regarding the measurement of such factors using self-report questionnaires.  to address these concerns, recent work has explored the use of behavioral indicators like hint-seeking and glossary use in intelligent tutoring systems like carnegie learning’s cognitive tutor® (ct) as alternative, “online” measures of goal orientation.  we re-examined this approach by measuring 273 ct users’ achievement goals and self-efficacy judgments via embedded questionnaires and their hint-seeking and glossary use via log data. using graphical causal models and linear structural equation models to observe structural relationships among goal orientations, self-efficacy, behaviors, and learning outcomes, we found that tracing orientations via “online measures” is more nuanced than perhaps previously appreciated. we describe complex relations observed in the model among motivations, behaviors, and outcomes and discuss the implications for the online measurement of motivation.
the brain encodes the space in various reference frames. the key role in spatial transformations is played by the posterior parietal cortex where neurons combine retinal location of visual stimulus with gaze direction to encode spatial information. this nonlinear dependence of neuronal responses, gain modulation, is considered a fundamental computational principle used in the brain. the important insight can be obtained through computational models, typically artificial neural networks. in this paper, we test the zipser--andersen model but use more realistic and variable stimuli, employing the simulated icub robot. the multi-layer perceptron was able to successfully perform coordinate transformation from eye- to body-centered reference frame, using gaze information. model achieves high accuracy of 2 to 4 degrees on testing data, depending on the dataset variability. we provide visualisation techniques for analysing the network, and the effects of gain modulation and shifting receptive fields. our results confirm previous findings that hidden neurons use various intermediate codings that mediate transformations.
fine et al. (2013) recently demonstrated that readers continually adapt their syntactic expectations in order to accurately approximate the distributions of syntactic structures in a given communicative context. here, we examine patterns of eye movements as subjects read sentences that contain an atypical distribution of syntactic structures to gain more fine-grained insight into the time-course and nature of this adaptive process. an adaptation effect was only elicited on a late measure—second-pass reading times—consistent with the claim that expectation adaptation to an atypical distribution of syntactic structures occurs at a higher level that is abstracted away from the physical properties of the visual input.
languages tend not to exhibit unpredictable variation, and learners receiving variable linguistic input tend to eliminate it, making the language more regular. we explore how this behavior is influenced by social cues, in particular when variability is distributed within and across teachers. we trained participants on an artificial language that contained lexical variability and manipulated how that variability was distributed across teachers: learners either received input from one or three variable teachers, or from three teachers who were individually consistent but exhibited variability collectively. we found that learners were more likely to produce variable output when their input came from (one or multiple) teachers who exhibited variable labeling, and they regularized more when learning from individually consistent teachers. this indicates that the propensity of language learners to eliminate linguistic variation is modulated by social cues, pointing to potential links with the broader literature on social learning in other domains.  
infants’ ability to detect patterns in speech input is central to their acquisition of language, and recent evidence suggests that their cognitive faculties may be specifically tailored to this task: seven-month-olds reliably abstract rule-like structures (e.g., abb vs. aba) from speech, but not other stimuli. here we ask what drives this speech advantage. specifically, we propose that infants’ learning from speech is driven by their representation of speech as a communicative signal. as evidence for this claim, we report an experiment in which 7-month-old infants (n=28) learned rules from a novel sound (sine-wave tones) introduced as a communicative signal, but failed to learn the same rules from tones presented in non-communicative contexts. these findings highlight the powerful influence of social-communicative contexts on infants’ learning.
previous research has shown that the mental models participants use throughout a task influence the efficiency with which they learn and adapt to changes in their environment (lee & johnson-laird, 2013; stöttinger et al, 2014). we wanted to measure the influence of different types of mental models participants hold before engaging in a task. using a modified version of the game “plinko”, participants predicted the likelihood that a ball falling through pegs would land in one of forty slots. importantly, participants were asked to make likelihood estimations before seeing the first ball drop. this initial probability estimate was used to categorize participants into different groups based on distinct a priori models. results indicated that participants came into this task with a number of distinct initial models, and that the type of model influenced their ability to accurately represent different distributions of ball drops in plinko.
recent research has suggested a division between lexical representations and phonological patterns; lexical items are stored with talker-specific information, while phonological patterns are represented at a separate, abstract level of representation (finley, 2013; smolensky & legendre, 2006). the present paper provides further evidence for this proposal, demonstrating that learners will extend a novel phonological pattern (vowel harmony) to speakers of a novel dialect when the words are familiar, but not when the words are unfamiliar, further supporting a distinction between the representations of lexical items and the representations of phonological patterns.
the existence of sound-to-shape correspondences has been demonstrated in the literature on sound-symbolism using double forced-choice paradigms and ad hoc figures. in two experiments, we tested if the sound-shape correspondence effect would be observed when participants were required to name one by one figures of every-day entities. additionally, as stimuli represented known entities, we hypothesized that the sound-symbolic effect would be influenced by the entities’ category (i.e., natural, artificial). results confirmed the sound-shape correspondence in both experiments. furthermore, in experiment 2 a modulation due to the category was observed while participants, both adults and children, named agents (i.e., animals, anthropomorphous robots). results are discussed in the framework of embodied cognition theories.
tracx (french, addyman, & mareschal, 2011) is a recursive connectionist system that implicitly extracts chunks from sequence data. it can account for experiments on infant statistical learning and adult implicit learning, as well as real-world phoneme data, and an experiment using backward transitional probabilities that simple recurrent networks cannot account for. one criticism of tracx, however, is the implausibility in a connectionist model of if-then-else statements. in particular, one of these statements controls what data is copied from the model’s internal memory into its input, based on a hard error threshold. we, therefore, developed a more biologically-plausible version of tracx devoid of if-then-else statements, relying only on spreading activation and without any learning error threshold.  this new model, tracx 2.0, performs essentially as well as the original tracx model and, in addition, has two fewer parameters than the original and accounts for the graded nature of chunks. 
we use eye-tracking data, analyzed by a neural network and by linear discriminant analysis (lda), to study the temporal dynamics of children's analogy making. we determine how well the number of item-to-item saccades while solving an analogy problem predicts whether or not a child will correctly answer the problem. for the a:b::c:d visual analogy problems, by the first third of the trial we can tell with 64% accuracy whether or not the problem will be answered correctly. two-thirds of way through the trial, we can predict with 82% accuracy the answer that will be given. by looking only at the final third of the trial, we can predict with up to 90% accuracy what the child will do. average gaze times at the target and distractor items have the same predictive power as the item-to-item saccade information. 
novice participants were given a schematic map of a multi-level building and performed a series of wayfinding tasks. consistent with previous research, we found a mix of wayfinding strategies adopted by participants. further analysis showed that participants incrementally developed and used mental representations of the building by integrating perceptual cues and memories of visited locations with salient features and landmarks represented on the schematic maps. the formation and use of mental representations was found to correlate with spatial ability – participants with better spatial ability would more likely use mental representation to infer relative locations of landmarks and to derive directional guidance for navigation. as a result, the routes chosen were better than those who predominately rely on deictic references to the schematic maps and environment cues.
in the today’s information society, where information access is ubiquitous and data is abundantly available, the importance of memorization is giving way to information gathering skills (search, filtering, summarization), and this focus should also be reflected in the educational process. in this study, we focus on the problem-solving skills of information searching and editing (search-editing task) and investigate a cognitive model of the problem-solving process. according to the model in this study, we examine the cognitive processes of participants solving an essay problem in an environment where they can find the required information in a document using an electronic search interface. in addition, we analyze how the participants behaved while working on the task, based on their action-log and level of achievement, and investigate the factors affecting the problem solving skills of search-editing.
excess individual creativity can be detrimental to society because creators invest in unproven ideas at the expense of propagating proven ones. moreover, a proportion of individuals can benefit from creativity without being creative themselves by copying creators. we hypothesized that (1) societies increase their rate of cultural evolution by tempering the novelty-generating effects of creativity with the novelty-preserving effects of imitation, and (2) this is carried out by selectively rewarding and punishing creativity according to the value of the individuals' creative outputs. we tested this using an agent-based model of cultural evolution in which each agent self-regulated its invention-to-imitation ratio as a function of the fitness of its cultural outputs. in self-regulating societies, agents segregated into creators and imitators. the mean fitness of cultural outputs was higher than in non-self-regulating societies, and changes in diversity were rapider and more pronounced. we discuss limitations and possible social implications of our findings.
to investigate the contributions of language and education to theory of mind understanding, three nicaraguan groups were tested using a minimally verbal protocol in which they themselves experienced a false belief instead of being told of one. we also assessed the relationship of executive function abilities to false belief performance. homesigners, who have no linguistic community, did not succeed on either the false belief or executive function tasks. nicaraguan sign language users, who have educational experience and are part of an emerging linguistic community, performed the best on executive function, though less well on false belief, than spanish speakers who have little to no education. this study showed that: without a language community, succeeding on either task is difficult; executive function may not be as tied to false belief performance as previously believed; and education may play a greater role in executive function success than language does.
recent findings suggest that i) children can build initial verb entries on the basis of syntactic information alone without any additional information provided by a visual context, and ii) that the early representation of verbs encompasses statistical information on the co-occurrence of these verbs with their potential meanings/referents, enabling children to infer verb meanings under referential uncertainty. in this paper we present a computational model that acquires verb-general constructions under referential uncertainty. the model stores linguistic knowledge in line with construction grammar in the form of an interrelated network of constructions. learning proceeds in line with usage-based theories in an item-based fashion. computational results show that the model can account for the above-mentioned findings: the model produced patterns similar to those observed in these studies. our findings hence shed light on the potential mechanisms involved in the emergence of early verb entries and verb-general constructions as well as the representation and refinement of verb entries. 
information related to the self tends to be better remembered than other information. mentalization (i.e., attributing mind to an external entity) is one potential intervening factor in contrasting myself, others “like me”, and inanimate objects. twenty-seven undergraduates (mean age 23.6 years, 16 women) responded to a remember/know (r/k) recognition task. in the study phase, 78 words were presented at 3 levels of processing: self (item applies to myself), other (applies to the queen of england) and object (applies to statues). in test trials, subjects recognized items as old or new. after an "old" response, an r/k judgment was prompted. we observed significant differences in recognition reaction times (rts) between self/other and self/object conditions. r/k judgment rts showed significant differences between self/object conditions. results support self-reference at a deeper level of processing, but not in a continuum from self to other and to inanimate object. 
in order to be held responsible, a person's action has to have made some sort of difference to the outcome. in this paper, we  propose a counterfactual replacement model according to which people attribute responsibility by comparing their prior expectation about how an agent was going to act in a given situation, with their posterior expectation after having observed the agent's action. the model predicts blame if the posterior expectation is worse than the prior expectation and credit if it is better. in a novel experiment, we manipulate people's prior expectations by changing the framing of a structurally isomorphic task. as predicted by our counterfactual replacement model, people's prior expectations significantly influenced their responsibility attributions. we also show how our model can capture johnson and rips's (2013) findings that an agent is attributed less responsibility for bringing about a positive outcome when their action was suboptimal rather than optimal. 
the endowment effect describes people’s tendency to ask for more money when selling objects than they are willing to pay when buying these objects. previous research found that asian participants showed smaller endowment effects than western participants. these results were explained by culture-specific self-beliefs being transferred onto the endowed object. yet, asian self-concepts are not only more interdependent, but also more situation-contingent than western self-concepts. thus, we predicted cultural differences in endowment effects to depend on social contexts. in two studies, we asked participants to imagine being either the owner or the buyer of a coffee mug, and to imagine using this mug in either a public or private context. assessing participants’ monetary value of the mug, we found that asians showed endowment effects in private but not in public contexts. in contrast, westerners showed endowment effects across both social contexts. we discuss possible mechanisms that may underlie these findings.
inductive generalization is ubiquitous in human cognition; however, the factors underpinning this ability early in development remain contested. two alternative perspectives have been proposed for how children make inductive inferences: a naïve theory account (gelman & markman, 1986; markman, 1990) and a similarity-based account (sloutsky & fisher, 2004; 2012). although both theories claim considerable empirical support, the debate is ongoing and results of extant studies are often deemed inconclusive. we report an experiment designed to evaluate the predictions of each account. in this study, 2- to 5-year-old children were asked to make inferences about highly familiar object categories. the reported findings are not fully consistent with either the naïve theory or the similarity-based approach. therefore, we propose a revised version of the similarity-based account, which can account for the reported findings.
it is a widely accepted fact that coherence enables a text’s comprehensibility. a major source of coherence is discourse cohesion (textual properties of the text). lexical cohesion (e.g. synonymy) and discourse connectives are two major types of discourse cohesion. we investigate the contribution of these two types of cohesion to the overall comprehension of bi-clausal sentences in turkish. in a two-phase study, we ask the participants to judge the comprehensibility of sentences while we obtain eye-gaze data and then ask them to write recall protocols. we find that lexically cohesive sentences (labeled as high coherent) are judged more comprehensible and recalled better, and that in low coherent sentences (those lacking lexical cohesion), the fixation counts are high. this study shows that in short texts, lexical cohesion guides coherence and it is singled out as an important factor of discourse comprehension. the study concerns turkish discourse and may have implications on discourse coherence and discourse comprehension in other languages.
the dynamics of cooperation in repeated prisoner's dilemma (pd) interactions are captured by an instance-based learning model that assumes dynamic adjustment of expected outcomes (ibl-pd model). this research presents this model’s predictions across a large number of pd payoff matrices, in the absence of human data. rapoport and chammah (1965) test three hypotheses in a large set of pd payoff matrices: (1) as reward of cooperation increases, more cooperation is observed; (2) as the temptation to defect increases, less cooperation is observed; and (3) as punishment for defection increases, more cooperation is observed. we demonstrate that the same ibl-pd model that was found to predict the dynamics of cooperation in one particular payoff matrix of the pd produces accurate predictions of human cooperation behavior in six additional games. we also make detailed predictions of the dynamics of cooperation that support these three hypotheses. 
it has recently been suggested that much of the research in embodied cognition can be explained by a “disembodied” account in which conceptual and cognitive processes perform their computations in a modular fashion and the sensory and motor associations that show up in embodiment experiments may arise merely from spreading activation from the cognitive module to the sensory and motor systems (mahon & caramazza, 2008). in such a model, the cognitive module processes its information and accesses its representations exactly the same way as it always would have, and the embodiment effects are essentially epiphenomenal.  we test this idea by manipulating the sensory aspects of the perceptual input that triggers the activation of a concept. throughout the history of conceptual representation research, feature lists of concepts have been treated as a method for accessing the semantic content of those conceptual representations. when there are sensory differences in the font of the written word that triggers accessing of a concept, does the concept get accessed in a different way? are different conceptual features more prominent than others? we find a series of conceptual features that are more prominent when the concept is presented in one font versus the other. continuations of this research project involve reaction-time priming experiments to see if these differential access effects happen at the timescale of hundreds of milliseconds. our results are discussed in the context of competing or compatible accounts of embodied and symbolic cognitive processes. 
people often tacitly assume an egocentric perspective when describing spatial scenes, and then use ambiguous descriptions (e.g., “the bottle is on the left.”). however, they can also take an alternative perspective, for instance referencing an agent that is present in the scene to reduce ambiguity (e.g., “the bottle is on your right.”). in this experiment, participants viewed a computer screen that contained a photograph of a basket on a table. participants were given ambiguous spatial relationship directions for placing the objects (trials) in the scene (e.g., “place the x to the right of the basket.”). the goal was to determine, through mousetracking, how often people choose an other-centric perspective, and if they chose an egocentric perspective did they consider other viewpoints. results showed that the visual input (conditions) influenced the initiation times and maximum deviation of an egocentric response when a person was present in the scene compared to when a person was absent.
the standard approach to changing people’s energy consumption, which involves information about ap-propriately structured economic incentives, is becom-ing increasingly questioned. in an experiment, we in-vestigated if it is possible to affect the electricity con-sumption recommended for the average american citizen by priming participants with either pro-social aspects of the “american stereotype” (intrinsic val-ues) or by superficial and self-enhancing aspects of the “american stereotype” (extrinsic values). the re-sults showed that the participants that were primed with extrinsic values recommended significantly higher electricity consumption for the average amer-ican, as compared to both the intrinsic value priming condition and to a neutral control condition.    
what does semantic similarity between two concepts mean? how could we measure it? the way in which semantic similarity is calculated might differ depending on the theoretical notion of semantic representation. in an eye-tracking reading experiment, we investigated whether two widely used semantic similarity measures (based on featural or distributional representations) have distinctive effects on sentence reading times. in other words, we explored whether these measures of semantic similarity differ qualitatively. in addition, we examined whether visually perceived spatial distance interacts with either or both of these measures. our results showed that the effect of featural and distributional representations on reading times can differ both in direction and in its time course. moreover, both featural and distributional information interacted with spatial distance, yet in different sentence regions and reading measures. we conclude that featural and distributional representations are distinct components of semantic representation.
recent evidence from eye tracking during reading showed that non-referential spatial distance presented in a visual context can modulate semantic interpretation of similarity relations rapidly and incrementally. in two eye-tracking reading experiments we extended these findings in two important ways; first, we examined whether other semantic domains (social relations) could also be rapidly influenced by spatial distance during sentence comprehension. second, we aimed to further specify how abstract language is co-indexed with spatial information by varying the syntactic structure of sentences between experiments. spatial distance rapidly modulated reading times as a function of the social relation expressed by a sentence. moreover, our findings suggest that abstract language can be co-indexed as soon as critical information becomes available for the reader.
causal beliefs have been shown to affect performance in a wide variety of reasoning and problem solving tasks. one type of judgment bias that can result from implicit causal models is causal asymmetry - the tendency to judge predictive inferences as more plausible than comparable diagnostic inferences. the directionality of implicit causal models may also affect the application of formal methods. pairs of conditional probability (cp) problems were written depicting events e1 and e2, such that e1 either occurs before e2 or causes e2. probability problems were defined with respect to the order of events expressed in cps, so that p(e2|e1) represents the cp in schema-consistent, intact order by considering the occurrence of e1 before e2; while p(e1|e2) represents cp in schema-inconsistent, inverted order. participants had greater difficulty encoding cp for events in schema-inconsistent order than cp of events in the conventional deterministic order.
originality, a key aspect of creativity, is difficult to measure. we tested the relationship between originality and similarity in two semantic spaces: latent semantic analysis (lsa) and pointwise mutual information (pmi). similarity in both spaces was negatively correlated with human judgments of originality of responses on a test of divergent thinking. pmi was correlated more strongly both with human judgments of similarity and human judgments of originality. in particular, the average pmi between two phrases was found to be the strongest predictor of phrase similarity and originality, even performing better than participants' self assessments of their originality.
this project investigates the effects of gender in a human-robot collaboration interaction. in the experiment, participants completed four sudoku-like puzzles with a robot from which they could verbally elicit help. the robot was given the gendered characteristics of a gendered computer generated voice and either the name charlotte (female condition) or charley (male condition). contrary to expectations from psychology, male participants asked the robot for help more frequently regardless of its assigned gender. participants of both genders reported feeling more comfortable with a robot assigned the other gender and preferred the male robot's help. findings indicate that gender effects can be generated in human-robot collaboration through relatively unobtrusive gendering methods and that they may not align with predictions from psychology.
theories of causal reasoning and learning often implicitly assume that the structural implications of causal models and empirical evidence are consistent. however, for probabilistic causal relations this may not be the case. mismatches between structural implications and empirical evidence may lead to distortions of empirical evidence. previous work has shown that people may use the generative causal relations a → b and b → c to infer a positive relation between events a and c, despite data showing that these events are actually independent (von sydow et al., 2009, 2010). here we used an economic trial-by-trial learning scenario to investigate how transitive reasoning in intransitive situations with even negatively related distal events may relate to betting behavior. experiment 1 shows that transitive reasoning does affect not only probability estimates but betting as well. experiment 2 shows that the effect remains stable even after repeated betting and feedback.
classical syllogistic reasoning, also known as aristotelian reasoning, is of particular interest in cognition. such reasoning, which can seem simple at first, is known to be associated with high error rates. although some research has been done on this topic, the underlying mechanisms used by human beings remain largely unknown. to understand the underlying cognitive properties associated with solving syllogistic problems, this study uses a connectionist approach composed of three steps inspired from laird and bara (1984): spatial representation, associative memory, and alternative searching conclusion. results show that the network produces similar performances as humans.keywords: syllogistic reasoning; artificial neural network; neurodynamic modeling.
the use of virtual reality (vr) as a methodological tool is becoming increasingly popular in behavioural research due to its seemingly limitless possibilities. this new method has not been used frequently in the field of psycholinguistics, however, possibly due to the assumption that human-computer interaction does not accurately reflect human-human interaction. in the current study we compare participants’ language behaviour in a syntactic priming task with human versus avatar partners. our study shows comparable priming effects between human and avatar partners (human: 12.3%; avatar: 12.6% for passive sentences) suggesting that vr is a valid platform for conducting language research and studying dialogue interactions.
many properties of substances/materials are intensive, and children are widely believed to have difficulties with reasoning about intensive quantities. here we used a novel judgment method, together with a cross-cultural paradigm to study 4- to 9-year-olds’ understanding of the intensity/ concentration (sweetness) of sugar-water solutions. uk children knew from the youngest age that intensity increases with amount of solid, and a significant, but small effect for decreasing amount of liquid appeared by age 7, a couple of years prior to the age typically reported. hong kong children were more advanced, with strong liquid effects and the normative concentration pattern from the youngest age. problems with intensive quantity reasoning may not reflect a universal cognitive limitation, but seem to depend on cultural experience. this has implications for children’s chemistry reasoning and education. 
we introduce the new version of our virtual environment (ve) squareland. as its predecessor it enables researchers to create human wayfinding experiments with variations in route length and complexity, as well as in the availability of route information and landmarks. a newly developed aspect is that test participants can be given active movement control. now it also is much easier to create experiments in which participants are passively moved through the virtual environment. squareland 2.0 comes as a standalone executable file with easy setup controls. it was programmed in the game engine unity (unity technologies©) and is licensed under the general public license (gnu). it is highly adjustable and usable for many research questions in spatial cognition science.
repeated references have been found to be reduced as compared to references that are not repeated, both in speech and in gesture. in the present study we wanted to see whether certain factors can inhibit this reduction in repeated references. in a production experiment, speakers were confronted with negative feedback after an initial description of an object, indicating that the communication was unsuccessful. we found that after initial negative feedback, second references were reduced with regard to all speech variables. when the speakers were confronted with additional negative feedback, the ensuing third references were increased in the number of words and the duration, as compared to the second references, but further reduced in their speech rate. gesture rate increased in third references as compared to initial references. after (repeated) instances of unsuccessful communication, speakers speak slower and increase their gesture rate, thereby making their repeated references clearer for the addressee.
we developed a version of the joanisse and seidenberg (1999) past-tense model to address two issues: whether the model’s performance depended on the use of localist semantic representations, and the challenges to this account presented by a patient who was impaired in generating irregular past tenses despite apparently intact semantics. the model also demonstrates the frequency by regularity interaction from patterson et al (2001), and shows that a single-mechanism connectionist model can perform realistically on the past-tense task.
in the current study, strictly controlled moral dilemmas are used to study intuitions in moral judgments concerning situations in which one human life has to be sacrificed in order to save more human lives. the influence of two factors (inevitability of death and instrumentality of harm) is explored. both of them are found to influence moral judgments. to study the emotional processing in judgments, response times and skin-conductance reactions are analyzed.  it is found that responses to dilemmas involving incidental harm produce longer response times and are accompanied by higher arousal (as indexed by the skin conductance reactions). reported results imply that when instrumentality of harm is considered, judgment is influenced by emotional reactions. 
poor performance in goal-oriented sensory motor tasks is a common symptom among depressed individuals. however, it is unclear what the underlying causes of these deficits are. elucidating the underlying mechanisms is an important first step to develop more targeted behavioral interventions. here, using simple motor-control tasks, we propose an inverse optimal control approach to analyze and factorize performance deficits into two components of subjects’ behaviors: 1) sensory motor speed, 2) reward-processing. in task 1, subjects with beck depression inventory score ranging from 0 to 36 were instructed to push a joystick as quickly as possible once they observe motion onset of a virtual car. in task 2, they were instructed to drive a virtual car as quickly as possible and stop it as close as possible to a stop sign. based on the continuous joystick actions for each individual subject, we estimated perceptual motor efficiency parameters and recovered the underlying reward function that best explained the subject's behavior. initial results suggest, that relative to healthy controls, depressed individuals: 1) have deficits in sensory-motor processing speed, 2) have different goals but not significantly different accuracy/effort ratio. the results suggest that inverse optimal control may be a viable computational approach to quantify and factorize the underlying causes of sensory motor deficits in individuals with depression.
since the 1970s, researchers in psycholinguistics and the cognitive sciences have been aware of the language-as-fixed-effect fallacy, or the importance in statistical analyses to not only average across participants (f1) but also across items (f2). originally, the language-as-fixed-effect fallacy was countered by proposing a combined measure (minf’) calculated by participant (f1) and item (f2) analyses. the scientific community, however, reported separate participant and item (f1 and f2) regression analyses instead. more recently, researchers have started using linear mixed models, a more robust statistical methodology that considers both random participant and item factors together in the same analysis. there are various benefits to using mixed models, including being more robust to missing values and unequal cell sizes than other linear models, such as anovas. yet it is unclear how conservative or liberal mixed methods are in comparison to the traditional methods. moreover, reanalyzing previously completed work with linear mixed models seems cumbersome. it is therefore desirable to understand the benefits of linear mixed models and to know under what conditions results that are significant for one model might beget significant results for other models, in order to estimate the outcome of a mixed effect model based on traditional f1, f2, and minf’ analyses. the current paper demonstrates that it is possible, at least for the most simplistic model, for an f or p value from a linear mixed model to be estimated from the same values from more traditional analyses.
many studies have argued that language comprehension requires perceptual simulation. in previous work we have demonstrated that because language encodes perceptual relations, comprehenders can also rely on language statistics to bootstrap meaning through limited grounding. the extent comprehenders do this depends on the nature of the cognitive task, the stimulus, the individual, as well as the speed of processing, with linguistic representations preceding perceptual simulation. in the current study we report results that investigated whether time constraints impacted the use of perceptual and linguistic factors during language processing. participants made fast or slow speeded judgments about whether pairs of words were semantically related. subjects were also instructed to either respond as quickly as possible to the words they were presented, or respond as accurately as possible. the perceptual factor was operationalized as an iconicity rating of the stimulus pairs occurring in a particular orientation in the real world and the linguistic factor was operationalized as the frequency of the stimulus pairs in language. the linguistic factor best explained the rts when subjects had to respond quickly. on the other hand, when given more time to respond, both linguistic and perceptual factors explained response times. these findings support the view that language processing is both linguistic and embodied, with linguistic representations being relevant for quick good-enough representations and perceptual simulations being important for more precise information.
in sequential diagnostic reasoning the goal is to determine the most likely cause for a number of sequentially observed effects. potential hypotheses are narrowed down by integrating the cumulating observed evidence leading to the selection of one among several hypotheses. in the reported diagnostic reasoning experiment, thirty-eight participants were tested with quasi-medical problems consisting of four sequentially presented symptoms with four candidate diagnostic hypotheses. we used ambiguous sequences that could be equally caused by two chemicals to investigate possible order effects and explicitly highlighted alternative hypotheses by using a stepwise rating procedure that also enabled us to compare participants’ ratings with belief updating in a bayes net. even though alternatives were explicitly highlighted, participants were biased towards the initial hypothesis in a pair of equally supported hypotheses. we conclude that ambiguous symptom sets and non-diagnostic symptoms invite biased symptom processing and can produce primacy effects even in a step-by-step procedure. 
prepositions name spatial relationships (e.g., book on a table), but also abstract, non-spatial relationships (e.g., jordan is on a roll)—raising the question of how the abstract uses relate to the concrete spatial uses. the two most frequently extended prepositions are in and on, and there has been no consensus about what aspects of spatial meaning they retain when used abstractly. we propose that what is preserved is the relative degree of control between the located object (the figure) and the reference object (the ground). building on previous work showing that this aspect of meaning can distinguish conventional abstract uses of in and on (jamrozik & gentner, 2011), we found that it is also extended to the comprehension and production of novel abstract uses. we discuss the application of the findings to second language instruction.
this study examined children’s comprehension of the conventional implicature induced by but, combined with so and nevertheless, in ‘p but q’ sentences constructed as distancing-contrastive connections. based on the pragmatic tolerance hypothesis of katsos and bishop (2011), a three-point scale was used as response format. using a scale instead of a binary judgment task can reveal more insight in which factors are considered most important when processing ‘p but q’ sentences. the results indicated that the content of the p- and q-arguments plays a very important role when children process ‘p but q’ sentences. however, their use of the three-point scale also indicated that they are sensitive to the pragmatic meaning of but, so and nevertheless. these results must be interpreted cautiously since the children seemed to use the middle value on the scale around 30% of the time in each sentence category, which was not in line with our predictions. this might indicate that children experience a general incomprehension with this type of sentences and answer with the middle value on the scale because they simply don’t know the answer.
the mental models theory of relational reasoning postulates that individuals reason by constructing the possible models of the situation described by the premises. the present article reports two experiments about spatial relational reasoning and focuses on the possibility of training in experiment 1, we compared two different training methods, one in line with the mental models theory and one in line with the rule-based account both accuracy and training data supported the mental models theory. in experiment 2, we compared different training methods for children. again, results were in line with the mental models theory.
 counterfactual conditionals concern relations in other possible worlds. most of these possible worlds refer to how a situation would have unfolded forward from a counterfactual assumption. in some cases, however, reasoning goes backward from the assumption, a phenomenon that is called backtracking. in the current study, we propose that people backtrack if and only if doing so will make a counterfactual claim true in the alternative world. we present evidence to support the proposal
plausible reasoning has been proposed as an alternative to deductive and inductive norms of argument evaluation in informal logic. in this paper, we present the first systematic empirical contrast between the bayesian account of argumentation and a plausible reasoning model. results suggest that the bayesian approach to argumentation provides a more precise picture of how people evaluate the strength of appeals to witness testimony when considering coherence and argument structure as relevant factors.
the cognitive reflection test (crt) is increasingly employed to measure the tendency of an individual to override a prepotent but incorrect response and to subsequently engage in further reflection.  this interplay between fast intuitive responding and resource demanding reflection has been offered as a paradigmatic example of dual process theories of thinking. despite its growing popularity both for dual process theories and as an easily deployed measure of intelligence, the basic assumption that the crt relies on executive resources remains generally circumstantial.  the present study directly tested these dual process assumptions by presenting the standard bat-and-ball problem and a no-conflict control version while manipulating executive resources with a secondary load task.  with the no-conflict control problems, accuracy was uniformly at ceiling in no load, low load, and high load conditions.  in sharp contrast, in the standard conflict problems accuracy clearly declined with increasingly load.  these findings validate dual process assumptions by providing direct causal evidence that correctly resolving the bat-and-ball problem draws on executive resources.
efficient codes have been shown to perform well in image and audio classification tasks, but the impact of sparsity---and indeed the entire notion of efficient coding---has not yet been well explored in the context of human movements. this paper tests several coding approaches on a movement classification task and finds that efficient codes for kinematic (joint angle) data perform well for classifying many different types of movements. in particular, the best classification method relied on a sparse coding algorithm combined with a codebook that was tuned to kinematic movement data. the other approaches tested here---sparse coding with a random codebook, and "dense" coding using pca---provide interesting baseline results and allow us to investigate why sparse codes appear to work well.
people judge the strength of cause-and-effect relationships as a matter of routine, and often do so in the absence of evidence about the covariation between cause and effect. in the present study, we examine the possibility that explanatory power is used in making these judgments. to intervene on explanatory power without changing the target causal relation, we manipulated explanatory scope—the number of effects predicted by an explanation—in two different ways, finding downstream consequences of these manipulations on causal strength judgments (experiment 1). directly measuring perceived explanatory power for the same items also revealed item-by-item correlations between causal strength and explanatory power (experiment 2). these results suggest that explanatory power may be a useful heuristic for estimating causal strength in the absence of statistical evidence.
although wordforms are often arbitrarily linked to their meaning, many exhibit iconicity (resemblance between form and meaning). this is especially visible in the lexica of non-indo-european languages and signed languages. iconicity has been argued to play a role in grounding linguistic form to real-world experience, rendering language more learnable (perniss & vigliocco, in press). here we examine sound-shape iconicity, the ‘kiki-bouba’ effect, i.e. the tendency to associate bouba-type labels with round shapes, and kiki-type labels with spiky shapes. in a first experiment we show that this iconicity emerges in the course of iterated learning (presumably because it renders labels more learnable). however, it only emerges for the mapping between round shapes and bouba-type labels. in a second experiment (using cross-situational learning, see monaghan et al., 2012) greater learnability is observed for mappings of the bouba-to-round type but not of the kiki-to-spiky type. we discuss possible mechanisms underlying this difference. 
the process of learning a language requires that long-term memory stores the meanings of thousands of words encountered across a variety of situations. these word meanings form a network of associations that, influenced by environmental factors such as word frequency and contextual diversity, cause behavioral effects on measures such as lexical decision and naming times. we investigate the development of recognition priming as a function of explicit knowledge after repeated training and testing on a novel vocabulary. by varying the word frequency and contextual diversity of the training input, and examining learning trajectories as well as semantic knowledge effects, we shed light on which environmental factors most influence performance in language acquisition. contextual diversity and entropy--the uncertainty about a word's referents--are the two strongest factors predicting primed recognition times, and play a role along with frequency and context familiarity in predicting explicit learning.
there  is  ample  empirical  evidence  that  children  can sometimes learn during the course of even a few experimental trials. we propose that one mechanism for this is the use of analogical  generalizations  constructed  in  working  memory, producing  what  we  call  interim  generalizations.   prior research suggests that such generalizations can be constructed when  there  is  high  similarity  between  closely  spaced  items. this paper describes how structure-mapping simulations  can be  adapted  to  capture  this  phenomenon,  using  automatically encoded stimuli.   it is an advance over prior models in that it automatically  detects  when  rerepresentation  should  be  tried and carries it out to improve its performance.
in this paper, human heuristics have been identified that provide close to optimal solutions when solving capacitated vehicle routing problems (cvrps). results from previous experiments showed humans can produce good solutions relatively fast that compete with computer-based methods giving further support to previous research on traveling salesman problems (tsps). multiple regression analyses have been conducted to show the best heuristics adopted by participants and that lead to better cvrp solutions. identified heuristics are categorized in visuospatial and arithmetic heuristics. visuospatial heuristics (e.g. clustering, anchoring) performed better than the arithmetic (e.g. balancing).  strategy switching appears to be a critical step within cvrp solutions suggesting that heuristics adopted are fast yet not-so-frugal, complimenting the fast and frugal toolkit. results are discussed under the light of problem-solving theories and in terms of how best human heuristics can inform the current state-of-art computational algorithms used in optimization problem solving.
we prove that minerva 2, a widely-used model of biological long-term memory, is mathematically equivalent to an auto-associative memory implemented as a fourth order tensor.  we further propose an alternative implementation of minerva 2 as a holographic lateral inhibition network. our work clarifies the relationship between minerva 2 and other memory models, and shows that minerva 2 and derivative models can be neurally implemented and scaled-up to long-term learning tasks.
assertions of set membership, such as "amy is an artist", should not be confused with those of set inclusion, such as "all artists are bohemians." membership is not a transitive relation, whereas inclusion is. cognitive scientists have neglected the topic, and so we developed a theory of inferences yielding conclusions about membership, e.g., "amy is a bohemian," and about non-membership, "abbie is not an artist." the theory is implemented in a computer program, mreasoner, and it is based on mental models. the theory predicts that inferences that depend on a search for alternative models should be more difficult than those that do not. an experiment corroborated this prediction. the program contains a parameter, σ, which determines the probability of searching for alternative models. a search showed that its optimal value of .58 yielded a simulation that matched the participant's accuracy in making inferences. we discuss the results as a step towards a unified theory of reasoning about sets. 
there is now considerable evidence that emotion plays an important role in negotiation. emotions, such as anger and happiness, affect concession-making, not only in human vs. human negotiations but also in human vs. agent negotiations. recent research has demonstrated the impact of emotional expressions in morally-charged negotiations. thus, taking people’s moral concerns into account is crucial for building agents that operate in morally sensitive domains. this paper explores the interplay between people’s moral concerns, emotional expressions and concession-making during a morally charged negotiation. our results demonstrate that participants who had stronger concerns for the individualizing foundations (harm and fairness) make greater concessions for sacred negotiation items when faced with a sad opponent than an angry opponent. also, we find that participants who had high binding foundations (in-group, authority and purity) are more sensitive to social status, and make greater concessions in scenarios that involve agents in a higher social status.
when using mathematics in problem solving in everyday life, problem solvers must recognize and formulate problems by themselves because structured problems are not provided. therefore, it is an important task in general education to foster learner problem posing. although learning by solving examples is adopted in general education, it may not be sufficiently effective in fostering learner problem posing because cognitive skills differ between problem solving and problem posing. this study experimentally investigated the effects of three learning activities in problem posing: learning by solving an example, learning by reproducing an example, and learning by evaluating an example. in our experiment, undergraduates were asked to pose their own new and unique problems from a base problem initially given after learning an example by solving, reproducing, or evaluating it. the results indicated that learning by reproducing the example was the most effective in fostering the composition of new problems.
this study explored two factors that might have an impact on how participants perceive distance between objects in a visual scene: perceptual grouping and presentation mode (2d versus 3d). more specifically, we examined how these factors affect language production, asking if they cause speakers to include a redundant color attribute in their descriptions of objects. we expected speakers to use more redundant color attributes when distractor objects are perceptually close. our findings revealed effects of perceptual grouping, with speakers indeed using color more often when all objects in a scene were in the same perceptual group as compared to when this was not the case. an effect of presentation mode (whether scenes were presented in 2d or in 3d) was only partially borne out by the data. implications of our results for computational models of reference production are discussed.
an eye-tracking study compared the effects of actions (depicted as tools between on-screen characters) with those of a speaker’s gaze and head shift between the same two characters. in previous research, each of these cues has rapidly influenced language comprehension on its own, but few studies have directly compared these two cues or, more generally, distinct non-linguistic cues in their effects on real-time sentence comprehension. we investigated how participants used action tools and speaker gaze separately and in combination for visually anticipating the upcoming mention of a sentence referent. we discuss implications for accounts of visually situated language comprehension. 
the kappa effect is an illusion involving spatiotemporal integration in the cognitive process and is demonstrated with three successive signals delimiting two neighboring empty time intervals. the present experiment was conducted with single time intervals delimited by two signals, instead of three, to examine whether perceived duration would be modulated by space. each of the two flashes was delivered from the left or right side in one session (horizontal direction), while each was delivered from the upper or bottom side in the other session (vertical direction). empty time intervals were perceived as longer when two flashes were delivered from different locations than when delivered from an identical location, but only when the flashes were presented in the horizontal direction. given that the kappa effect can occur when three signals are presented vertically, spatiotemporal integration seemed difficult to occur with single time intervals compared to two neighboring intervals.
verbs like begin and enjoy have been assumed to select for events and would coerce an entity-denoting complement to an event in semantic representation; such type-shifting operation engenders additional processing cost. however, recent studies show that this effect is observable only for aspectual verbs (e.g. begin), but not psychological verbs (e.g. enjoy), suggesting the set of “coercion verbs” is heterogeneous. we hypothesize that aspectual verbs select for structured individuals instead of events. they lexically encode a set of functions, each applying on a dimension (e.g. eventive, informational, spatial) denoted by the complement. the parser must determine the verb’s specific function and the dimension from the complement. the processing cost results from (1) exhaustive activation of the verb’s lexical functions and (2) resolution of ambiguity created by dimension extraction from the complement. we show that processing aspectual verbs was more costly than psychological verbs and that it recruited wernicke’s area for cost 1 and lifg for cost 2.
previous work has shown that the information value of requests can be manipulated by controlling the sparsity of hypotheses, the degree to which category members are rare or common in the domain under consideration when making those requests. however, the degree to which people are sensitive to expected information value is unknown. this study examined a binary sorting task where sparsity differed across conditions. in contrast to previous work using hypotheses representable as visual areas, the stimuli in this study defined hypotheses in an abstract similarity space over geometric shapes. participants could request labels for either category members or non-members. while both request types were used in all conditions, most often evenly, the proportion of participants showing a preference for one type of request was strongly impacted by the information value of that request type. a small tendency to prefer requests from the designated target category was also observed.
the ability to determine that diverse samples provide better evidence for generalization than non-diverse samples is an important inductive skill. adults tend to utilize the diversity principle of induction (dp), but evidence regarding children’s ability to do so is mixed. the two experiments reported here examined whether the method by which evidence is presented would have an influence on children’s tendency to obey the dp. these experiments with undergraduates (n = 66, mage = 21.12 years) and preschoolers (n = 62, mage = 5.27 years) revealed that whether sample items were presented sequentially or simultaneously influenced diversity-based reasoning in children, and in some cases, adults. specifically, sequential presentation facilitated diversity-based reasoning, and simultaneous presentation did not. together these results indicate that processes elicited during the presentation of evidence have an important influence on how children and adults use evidence to make inductive generalizations. 
many linguists consider morphological awareness a major factor that affects children's reading development. a chinese character embedded in different compound words may carry related but different meanings. for example, ``商店(store)'', ``商品(commodity)'', ``商代(shang dynasty)'', and ``商朝(shang dynasty)'' can form two clusters: {``商店'', ``商品''} and {``商代'', ``商朝''}. in this paper, we aim at unsupervised clustering of a given family of morphologically related chinese words. successfully differentiating these words can contribute to both computer assisted chinese learning and natural language understanding. in experiment 1, we employed linguistic factors at the word, syntactic, semantic, and contextual levels in aggregated computational linguistics methods to handle the clustering task. in experiment 2, we recruited adults and children to perform the clustering task. experimental results indicate that our computational model achieved the same level of performance as children.
the current study investigated whether cognitive architectures tuned to the magnitudes of nonsymbolic ratios support the acquisition of symbolic fraction concepts and subsequent achievement in algebra.  participants’ performance on a novel battery of nonsymbolic ratio comparison tasks predicted their symbolic fraction knowledge and algebra achievement even after controlling for performance on control tasks.  these results provide initial behavioral evidence that recently discovered brain systems which represent nonsymbolic rational magnitude may be important for math learning, especially for developing a strong understanding of fraction concepts.
bayesian models have been strikingly successful in a wide range of domains. however, the stochastic search algorithms generally used by these models have been criticized for not capturing the error-driven nature of human learning. here, we incorporate error-driven proposals into a stochastic search algorithm and evaluate its performance on concept and theory learning problems. compared to a model with random proposals, we find that error-driven search requires fewer proposals and fewer evaluations against labelled data.
learning hierarchical concepts is a central problem in cognitive science.  this paper explores the nearest-merge algorithm for creating hierarchical clusters that can handle both feature-based and relational information, building on the sage model of analogical generalization.  we describe its results on three data sets, showing that it provides reasonable fits with human data and comparable results to bayesian models.
extreme events come to mind very easily and people overestimate their probability and overweight them in decision-making. in this paper we show that rational use of limited cognitive resources can generate these 'availability biases.'we hypothesize that availability helps people to quickly make good decisions in very risky situations. our analysis shows that agents who decide by simulating a finite number of possible outcomes (sampling) should over-sample outcomes with extreme utility. we derive a cognitive strategy with connections to fast-and-frugal heuristics, and we experimentally confirm its prediction that an event's extremity increases the factor by which people overestimate its frequency. our model also explains three context effects in decision-making under risk: framing effects, the allais paradox, and preference reversals.
music is highly relational and in this manner shares much in common with other characteristically human behavior. while this may suggest that the processes used in music perception could be domain general, the nature and flexibility of these representations remain less understood. if the underlying representations and manipulations required for perceiving music overlap with those in other cognitive domains, it should be fairly easy to map such representations across domains. this hypothesis was tested and supported using a novel experiment with melodic stimuli in the auditory modality and analogous visual sequential stimuli (gabor sequences) in the visual modality. testing for transfer across the two modalities and for the two types of representations (contour and intervallic) was done through four counterbalanced conditions. cross-modal mapping was successful in three out of the four conditions, implying general flexibility of representational transfer. implications for representational flexibility, sequential learning and future studies are discussed.
analogy is an important cognitive process that has been researched extensively. functional accounts of it typically involve at least four stages of processing (access, mapping, transfer, and evaluation, e.g., see kokinov & french, 2002), however, they take the way in which the base analog is understood, along with its relational structure, for granted. the goal of this paper is to open a discussion about how this process (which we will call “relational recognition”) may occur. to this end, this paper describes two experiments that vary the level of relational complexity across exemplars. it was found that relational recognition tasks benefit from increased complexity, while mapping tasks suffer from it.
the acquisition of a non-native phonetic distinction by second-language learners relies on basic sensory and perceptual processes. in the present study we examined whether central capacity limitations in attention and immediate memory affected both metalinguistic awareness of phonemic properties of stimuli and the ease with which listeners could perceptually reorganize native phonemic categories. immediate memory was positively related to performance when listeners had to monitor their performance whereas attention was positively related to performance in identifying stimuli along the acoustic continuum.
computer simulations have been used to study various aspects about the emergence of communication. but there have been only a few works on the underlying representation processes occurring during the interpretation by an agent of a representation produced by another agent. here we present a study on representation processes in the emergence of communication occurring in a frequently used cognitive architecture in such experiments, artificial neural networks. we investigate the neural network’s activations during the emergence of communication in search for representational and referential processes. results show that it is possible to evaluate such processes along the evolution of communication and analyze interpretation accordingly.
we propose a single chunk model of long-term memory that combines the basic features of the act-r theory and the multiple trace memory architecture. the pivot point of the developed theory is a mathematical description of the creation of new memory traces caused by learning a certain fragment of information pattern and affected by the fragments of this pattern already retained by the current moment of time. using the available psychological and physiological data these constructions are justified. the final equation governing the learning and forgetting processes is constructed in the form of the differential equation with caputo type fractional time derivative. several characteristic situations of the learning (continuous and discontinuous) and forgetting processes are studied numerically. 
understanding macro cognition is important for understanding how experts and lay people function in the real world, and for building safer, more effective socio-technical systems.  we present a framework and a methodology for creating and evaluating process models of highly dynamic expert tasks and illustrate it with two models.
in this study, we experimentally investigated the effects of the interaction between two individual systems, an automation system that conducts tasks and an alert system that monitors automation performance and alerts users to automation failures. the experimental results showed that when users used automation and alert systems together, when the alert system missed automation failures, the participants lowered their trust not only in the alert system but also in the automation system. it means that the participants confused trust in the automation system with that in the alert system. moreover, when the participants highly trusted the automation system, they slowly responded to a true alert from the alert system. these results were discussed on the basis of the theory shown in previous studies.
in this article we review tononi’s (2008) theory of consciousnessas integrated information. we argue that previous formalizationsof integrated information (e.g. griffith, 2014) dependon information loss. since lossy integration would necessitatecontinuous damage to existing memories, we propose it ismore natural to frame consciousness as a lossless integrativeprocess and provide a formalization of this idea using algorithmicinformation theory. we prove that complete losslessintegration requires noncomputable functions. this result impliesthat if unitary consciousness exists, it cannot be modelledcomputationally.
according to the dual process theory, there are two systems in the mind: an intuitive and automatic system 1 and a logical and effortful system 2. this study focused on the system 2 process for large number estimation. first, we constructed a process model of estimation. the model, corresponding to the problem-solving process, consisted of creating subgoals (system 2), retrieving values (system 1), and applying operations (system 2). additionally, a knowledge network was used for the estimation process. second, the results of an experiment based on our model showed that the deliberative system 2 process did not improve the value estimated by the intuitive system 1 process.
the study of eye movements has enjoyed a history of supporting theories of attention in different task settings by expanding our understanding of how people navigate tasks such as natural scene perception, reading and categorization. the theories and models that these data inform, however, are largely based on fixation patterns. presently lacking is an understanding of how the eye movements preceding these fixations are affected by the task environment and if they change as a function of a shift in the state of knowledge. in an effort to close this gap, we report changing saccade velocities in two category learning experiments, evidencing the importance of understanding saccades in developing a stronger theory of the deployment of visual attention as it is influenced by higher level cognitive changes.
when counting, the final word used to tag the final item in a set represents the cardinality, or total number, of the set. understanding of this concept serves as a foundation for children’s basic mathematical skills. however, little is known about how the early learning environment can be structured to help children understand this important concept. the current study examined the effects of the representational status of to-be-counted items on preschoolers’ understanding of cardinality. children (m age = 3 years, 6 months) were randomly assigned to receive counting practice with either physical objects or pictures over five practice sessions. children’s counting skill and understanding of cardinality were assessed at pretest and posttest. results revealed that only children in the picture condition increased their understanding of cardinality from pretest to posttest. these results suggest that picture books are better than physical objects at supporting children’s understanding of cardinality.
we propose a bayesian sequential sampling model of choice reaction time (rt) which incorporates uncertainties about stimulus identity, onset, and duration. the model is the now-standard random-walk/drift-diffusion model, with a threshold-based response mechanism. the "substance" of the drift, however, is the posterior probability (belief) that a participant updates on a moment-to-moment basis during a trial — the update is done by combining the likelihood function on the evidence (modeling trial-dependent perception) with prior probability about stimulus identity, onset time, and duration (modeling trial-independent task knowledge). response threshold, which equals the probability of correct response in choosing each alternative conditioned on prior knowledge and accumulated evidence, modulates speed-accuracy tradeoff. while sequential bayesian updating without temporal uncertainty (regarding stimulus onset/offset) is trivial, we overcome the hurdle of incorporating the temporal prior into the dynamics of belief updating to derive an analytic expression for bayesian belief. the advantage of the bayesian formulation is to allow full control of where and how many free parameters appear: in likelihood functions, priors, or response threshold. comparison of computer simulation of our model with human performance data (smith, 1995) will be reported.
one study found that observers retained more information from hand gestures that speakers gazed at, possibly because speaker-gaze shifted observers' attention covertly. speaker-gaze may thus modulate the role of gestures in communication. one hypothesized communicative function of gestures, and specifically of the inter-personal repetition of gestures, is to facilitate the process of creating common ground (grounding). therefore, speaker-gaze may also influence the inter-personal repetition of gestures. in an experimental study, we found that participants were more likely to repeat another speaker's gestures if the original speaker gazed at the gestures. moreover, speaker-gaze was a better predictor of this repetition than participants' own gaze. this supports the hypothesis that speakers' gaze at their gestures leads to covert attention shifts in observers, causing the gestures to be processed differently. speaker-gaze could therefore be a valuable cue to the processing and production of gestures by artificial systems that interact with humans. 
people often compare sets of numbers informally, in considering prices or sports performance. children who lack knowledge of formal comparison strategies (e.g., statistics) may use intuitive strategies like estimation that create summary values with approximations of means and variance. there were two goals for this experiment: (1) to classify data comparison strategies and (2) to evaluate whether children’s strategy discovery and selection is effective. using eye tracking, we identified strategies used by 41 8-12-year-old children when comparing number sets, by examining how the properties of the data sets (e.g., mean ratios and variance) influenced accuracy and confidence in differences. we classified strategies from eye tracking patterns; these strategies were associated with different levels of accuracy, and strategy selection was adaptive in that selection was related to the statistical properties of the sets being compared. the results demonstrate that children are quite adept at informally comparing data sets and adaptively select strategies to match the properties of the sets themselves. 
i introduce a combination of information-theoretical and causal modeling to study the cascading of changes between the morphology and the syntax of a language on a diachronic scale. through the analysis of a historical treebank of icelandic language ranging from the xii to the xxi century, i show that it is changes in the inflectional morphology of the language that triggered changes in its syntax. this offers a novel and powerful approach to draw conclusions in historical linguistics from a macroscopic perspective. in addition, these findings have implications for the dynamical properties of the linguistic system.
games can be won or lost, and the outcome of the game often determines our facial expression. thus, game players’ facial expression possibly provides information about the game outcome. the connection between such nonverbal cues and accuracy at which game outcome could be deduced is investigated in a perception experiment. facial expressions of chinese and dutch children playing a game, either alone or in pairs, were shown to chinese and dutch judges who had to evaluate their expressivity and game outcome. no one-to-one mapping between perceived expressivity and guessing accuracy across conditions was revealed. a positive correlation was observed between expressivity and accuracy for both chinese and dutch children playing in pairs as well as alone, but only when they were winning. in fact, nonexpressivity was consistently interpreted by judges as a signal for losing. our findings contribute to the identification of conditions in which expressivity can reliably aid perception.
upon reading headlines like “traffic fatalities increased/decreased last year,” people often overestimate how well they would have anticipated changes. this hindsight bias has been linked to causal sensemaking that minimizes one’s feeling of surprise after learning an outcome. in this paper, we consider whether the sensemaking process, which contributes to bias in hindsight, could be recruited to our benefit in foresight. we found that 1. foresight participants—who estimated fatality statistics and listed causal factors before learning true statistics—were more surprised than hindsight participants—who listed causal factors only after learning true statistics. 2. to the extent that foresight participants were successful in listing causal factors in the opposite of their expected direction, they showed improvement in a second set of estimates they made prior to learning the true statistics; however, this improvement did not correspond to decreased surprise when they learned true statistics. we discuss implications for contrast vs. uncertainty theories of surprise, and for the possibility of useful belief revision triggered by unexpected statistics and consideration of alternative causation. 
using eye-tracking, two studies investigated whether a dynamic vs. static emotional facial expression can influence how a listener interprets an emotionally-valenced utterance in relation to a visual context. we assessed whether such facial priming changes with the comprehender’s age. participants inspected a static or a dynamic happy or sad facial expression. subsequently, participants saw two pictures of opposite valence and heard an either positively or negatively valenced sentence describe one of these pictures. the emotional face influenced visual attention on the pictures and during the processing of the sentence. these influences were modulated by age. older adults were more strongly influenced by the positive prime face, younger adults by the negative facial expression. these results suggest that the negativity and the positivity bias observed in visual attention in young and older adults respectively extends to face-sentence priming. however, static and dynamic emotional faces had similar priming effects on sentence processing.
knobe (2003) demonstrated that people’s intentionality judgments in side effects depend on the outcome of the sideeffect,indicating that people’s judgments of intentionality of action depend on not only the intention of the actor but also on the result of the action. however, on the basis of findings in judgment and decision making (e.g., harris, corner, & hahn, 2009), the current study proposes another hypothesis to knobe’s (2003) results: the participants’ intentionality judgments depended on the probabilities of outcomes provided by the action, rather than on the outcomes itself. to test this hypothesis, the present study employed an identical experimental procedure to knobe (2003), except that it required not only intentionality and probability judgments for outcomes that resulted from the actions of a companypresident. the results replicated the findings of knobe (2003) and showed a relationship between probability and intentionality judgment. 
context effects in multi-attribute decision making are important findings that challenge large classes of rational choice theories, while also providing innovative consumer product strategies. trueblood (2012) is the first demonstration of the attraction, similarity and compromise context effects using the same experimental paradigm. a closer examination of the attraction effect experiment reveals that the choice probability estimation procedure gives rise to systematic properties in the choice sets, which in this paper are collectively termed as the sum-highest property. conducting a simulation study reveals that the sum-highest property can affect a large number of choice sets. this is followed by an experiment that shows that people are biased towards options which satisfy the sum-highest property. these results provide a plausible alternate explanation to the attraction effect in studies which use similar estimation procedures, while also highlighting choice behavior under the sum-highest property as a potential principle of multi-attribute decision making.
several recent studies showed the effect of eye gaze direction on both instructed and spontaneous imitative behavior, as well as the acquisition of action-effect binding. in particular, direct eye gaze of a model gesturer/talker, compared to averted eye gaze, gives rise to faster gesture imitation and better vocal imitation, and reinforces intersubjective stimulus-effect learning. in an experiment with autism spectrum disorder participants and a control group (n = 32), we explored vocal imitation in conditions with engaged eye gaze, averted gaze and gaze establishing joint attention. we found that speakers from both groups were least likely to mimic the vocal patterns of the model talker in a condition with joint attention. the finding suggests that establishing joint attention by gaze directing negatively affects vocal imitative behavior.
previous work suggests that negative sentences are more difficult to process than positive sentences. a supportive context, however, can mitigate this effect.  we investigate the role of context on negation by measuring the processing cost of negation with and without a visual context (study 1) and then systematically varying the strength of the context (study 2).  we find that a supportive visual context has a graded effect on negation processing.  we then create a model to compute the informativeness of an utterance in context, and find that a model that considers both the surprisal of an utterance and the surprisal of seeing a referent is highly correlated with reaction times.  our data suggest that pragmatic factors likely explain the processing costs of negation.  
information-processing approaches to voter decision-making, and how ‘correct’ voters are, have been largely confined to the usa political system (lau & redlawsk, 1998; 2006). in a lab-based study based on the uk voting system, we tested the effects of increasing task complexity and one proposed heuristic, 'party label' on rates of voting in line with one's policy attitudes ('correct voting'). increasing the number of candidates from two to three decreases correct voting rates. however, when participants had to choose between two candidates, rates of correct voting were higher when the party affiliation of the candidates was presented, with no effect when there were three candidates in the choice set. implications of these results are discussed.
in an interactive decision-making process like a face-to-face consultation (a situation in which subjective information can be obtained), we dynamically change the emphasizing points during the interaction in which an adviser provided new information and subjective interpretations. in previous work, we proposed and evaluated a method to dynamically estimate emphasizing points (deep) but the method only included the intrinsic emphasizing points of each person. in this study, we investigated the effect of extrinsic subjective interpretations of the adviser in interactive decision-making. we used tightly controlled embodied conversational agents (ecas) as the adviser to evaluate the effect. we conducted an experiment that compared the results of interactive decision-making with two types of ecas: a facilitative agent who provided subjective opinions to realize divergent and convergent processes in decision-making and an estimation agent who only provided proposals that reflected the emphasizing points of each participant. as a result, we can confirm that the facilitative agent increased the participant's satisfaction of interaction with the eca, the naturalness of eca's interaction, and the impression of decision-making process. in addition, we developed a concept called the ``bubbling intention.'' we think the concept is useful to design human-agent interaction.
in a series of three experiments we examined how preschool children assess testimony in relation to the relative desirability of the outcome for themselves and for the individual providing the testimony. the first two experiments reveal evidence for an outcome bias: children are more likely to believe an extraordinary claim when they have little to lose in doing so (exp.1), and when they stand to gain if the claim is true (exp. 2). the final experiment (exp. 3) showed that children are less likely to believe extraordinary claims when the person making the claim has ulterior motives (e.g., stands to potentially gain from the child’s belief). these data show that children’s beliefs acquired from testimony are subject to outcome bias, and that children are capable of exercising skepticism when the source of testimony is likely to have ulterior motives.
this paper compares descriptivist approaches for concept acquisition with essentialist approaches by exploring the conditions under which people use generic sentences (sentences such as ‘apples are round’ which contrast with sentences about particulars like ‘all/most of the apples are round’). it fleshes out the essentialist approach in terms of the baptism theory of concept acquisition (oved, 2009; 2014), which is made precise with an implementation in which concepts are values of latent variables in a bayesian network, posited as explanations for observed patterns in objects’ perceptible properties (oved & fasel, 2011). two experiments measuring the use of generics are described and used as support for this essentialist approach over descriptivist approaches. 
the present study compares two cases of blending between episodes: blending of episodes that share a number of elements (superficially similar episodes) and blending of episodes that share the same structure of relations but do not share the same elements. according to classic theories and models of blending, superficially similar episodes are more likely to be blended because there is a larger overlap of the feature vectors representing them. in contrast, according to the ambr model of analogy-making and memory, analogous episodes are more likely to be blended. the results obtained in the present study support the prediction of the ambr model: people blend structurally similar episodes much more often than superficially similar ones. these results are consistent with previous experiments on the influence of analogy-making on constructive memory. 
a recent trend in dyadic interaction research utilizes multiple modalities to better understand phenomena encompassing behavior matching (e.g., synchrony, alignment). concurrent research has focused on a complementary framework of interaction, assessing the matching of power law distributions of behavior across two people: complexity matching. while both frameworks provide useful insights into dyadic interaction, they have done so independent of one another. we visualize the multimodal, multiscale coordination of dyads engaged in a tower-building task as networks based on the analyses of behavioral and complexity matching in speech and movement. we find that network strength relates to task performance and that high-performing dyads have weaker network strength, which we argue opens up more degrees of freedom affording more flexibility in the dyadic system.
since the earliest televised debates, cognitive and political sciences have been interested in how voters respond to political candidates and their messages, both verbal and nonverbal. the present work draws from this long tradition and combines it with work on persuasion and rhetoric to inform analyses of a new corpus of debate data: 48 transcripts from the intelligence squared u.s. series, televised oxford-style debates on relevant sociopolitical issues (http://www.iq2us.org). as a first look at this corpus, we focus on how linguistic content (i.e., hedging and pronoun use) and debater traits (i.e., attractiveness and negativity) interact with arbitrary group identity (i.e., “for” vs. “against”) to affect debate outcomes. interestingly, we find that arbitrary group identity (i.e., “for” vs. “against” labels created by the framing of the debate rather than the actual opinions held) significantly affects the ways in which linguistic content and debater traits influence voters. 
we present a model of object location memory developed within the act-r cognitive architecture and compare the model's performance to that of human participants in a modified version of the toy test.  the results of the experiment reveal that the accuracy of location recall is significantly affected by both the number of objects in the set and the order in which objects are selected for relocation. the model provides a close fit to the human data and is able to account for the combined effects of set size and selection order found in the experiment using act-r's declarative memory processes---in particular the similarity-based blending mechanism which combines the values of related memory elements to produced an aggregate response.
there is debate in the numerical cognition literature concerning symbolic and nonsymbolic number representation systems as foundations for more complex mathematical skills. the purpose of this study was to investigate the relation between these number representation systems and calculation fluency. the present study used 51 university students. participants completed symbolic and nonsymbolic magnitude comparison and ordinality tasks on an ipad as well as a pen-and-paper version of the addition and subtraction-multiplication subtest of the kit of factor-referenced cognitive tests (french, ekstron, & price, 1963). data reductions were performed and a symbolic and a nonsymbolic factor were constructed. a multiple regression analysis revealed that the symbolic factor was a significant predictor of calculation fluency, but the nonsymbolic factor was not. two separate repeated measures anovas revealed 3-way interactions between task, distance, and format for both accuracy and response time. these results support the view that the two systems develop separately.
many theoretical accounts of generalization suggest that with increasing data, people should tighten their generalizations. however, these accounts presume that the additional data points are all distinct. other accounts, such as the adaptor grammar framework in linguistics (johnson, griffiths, & goldwater, 2007), suggest that when the additional data points are identical, generalizations about grammaticality need nottighten appreciably: they may be made on the basis of type frequency rather than token frequency (although token frequency can affect other types of learning). we investigated what happens in this situation by presenting participants with identical data in both a linguistic and a non-linguistic context, some ten times as much as others, and asking them to generalize to novel exemplars. we find that people are insensitive to token frequencies when determining how far to generalize, though memory has a small mediating effect: generalizations tighten slightly more when people may rely on a memory aid.
it is well known that the context of a scene can have a strong effect on the identification of objects in the scene (e.g., biederman, 1972). however, it is unclear what role global versus local context plays on episodic memory for objects. we present results from a series of experiments that evaluate the degree to which the global and local context contributes to memory performance: partial scene context, where global context was partially removed, no-spatial scene context, where the local spatial relationships among objects was distorted, and random context, where the associative relationship among objects was altered. study time was also manipulated. we compare the findings to memory performance for objects in natural scenes (hemmer & steyvers, 2009; steyvers & hemmer, 2012). results show that background context of a scene is important for initial scene interpretation. in addition, associative and spatial context is important for the retention of a larger number of objects in memory. 
ownership is central in our thinking about other people and objects. we consider ownership when deciding whether we are permitted to use an object and when predicting how owners would feel if their property was lost or broken. recognizing and understanding ownership is not just evident in adults. even young children appreciate ownership and its consequences. in this experiment, we show that children aged three years (n = 40) predict that an individual would be sadder when her property went missing than when someone else’s property went missing. these findings show that young children have a rich appreciation of ownership, and grasp relations between ownership and psychological states.
identifying useful items from fluent speech is one of the first tasks children must accomplish during language acquisition. typically, this task is described as word segmentation, with the idea that words are the basic useful unit that scaffolds future acquisition processes. however, it may be that other useful items are available and easy to segment from fluent speech, such as sub-word morphology and meaningful word combinations. a successful early learning strategy for identifying words in english is statistical learning, implemented via bayesian inference (goldwater et al., 2009; pearl et al., 2011; phillips & pearl, 2012). here, we test this learning strategy on child-directed speech from seven languages, and discover it is effective cross-linguistically, especially when the segmentation goal is expanded to include these other kinds of useful units. we also discuss which useful units are easy to segment from the different languages using this learning strategy, as the useful unit varies across languages.
cognitive science recognizes two kinds of systematicity: (1) as the property where certain cognitive capacities imply certain other related cognitive capacities (fodor & pylyshyn, 1988); and (2) as the principle that analogical mappings based on collections of connected relations are preferred over relations in isolation (gentner, 1983). these two kinds of systematicity were shown to derive from one type of (universal) construction (phillips, 2014), using category theory (mac lane, 2000). underlying both forms of systematicity is a kind of optimization. we provide an informal summary of this result, and suggest an extension to address other (semantic) aspects of analogy.
if a distinctive event is amid other, non-distinctive events, often the memory for the item that immediately precedes the distinctive one is severely impaired. one explanation is that memory for the preceding items is reduced because when the priority item is detected, all attentional resources are directed to it, and the encoding of the preceding item is prematurely disrupted. because perceptually defined priority is detected earlier in time, compared to semantically defined priority, the encoding of the preceding item should be disrupted at an earlier stage, and the impairment should be greater. an experiment confirmed this prediction by showing that retrograde amnesia was present when participants had to preferentially remember the word written in capital letters (rabbit), but not when the priority item was defined by being a kind of animal (rabbit). these results can explain the reason behind recent failed replications and they provide evidence for the encoding hypothesis.
recent work on causal learning has investigated the possible role of generic priors in guiding human judgments of causal strength. one proposal has been that people have a preference for causes that are sparse and strong—i.e., few in number and individually strong (lu et al., 2008). sparse-and-strong priors predict that competition can be observed between candidate causes of the same polarity (i.e., generative or else preventive) even if they occur independently. for instance, the strength of a moderately strong cause should be underestimated when a strong cause is also present, relative to when a weaker cause is present. in previous work (powell et al., 2013) we found such competition effects for causal set- ups involving multiple generative causes. here we investigate whether analogous competition is found for strength judgments about multiple preventive causes. an experiment revealed that a cue competition effect is indeed observed for preventive causes; moreover, the effect appears to be more persistent (as the number of observations increases) than the corresponding effect observed for generative causes. these findings, which are consistent with predictions of a bayesian learning model with sparse-and-strong priors, provide further evidence that a preference for parsimony guides inferences about causal strength.
the cognitive reflection test (crt) is a short measure of a person’s ability to resist intuitive response tendencies, and to produce a normative response which is based on effortful reasoning. although the crt is a very popular measure, there is virtually no available data about its psychometric properties. the present study aimed at investigating the psychometric properties of the crt, and to verify the suitability of a longer version of the test, which was obtained by adding five new items to the three original ones. we applied item response theory analyses. the two-parameter logistic model was used in order to estimate item parameters, and the test information function was computed to assess the measurement precision of both the original and the longer versions of the test. the results demonstrated that the longer version of the scale measures with high precision a wider range of the cognitive reflection latent trait.
joint attention—when child and caregiver share attention to an object or location—is an important part of early language learning. identifying when two people are in joint attention is an important practical question for analyzing large-scale video datasets; in addition, identifying reliable cues to joint attention may provide insights into how children accomplish this feat. we use techniques from computer vision to identify features related to joint attention from both egocentric and fixed- camera videos of children and caregiver interacting with objects. we find that the presence of caregivers’ faces in the child’s egocentric view and the motion of objects in the fixed camera both correlate with human-annotated joint attention. we use a classifier to predict joint attention using these features and find some initial success; in addition, classifier performance is substantially increased by interpolating features across automatically-extracted “attention chunks” in the egocentric video.
studies of category learning have supported the idea that people rely on at least two cognitive systems when learning categories. a verbally-mediated system is best suited for learning rule-based categories, and a nonverbal system is best suited for learning categories not defined by a rule. to examine the cognitive systems involved in categorization, two experiments explored developmental differences in perceptual category learning. in experiment 1, children and adults were asked to learn a set of categories consisting of stimuli equated on feature salience. a single-feature rule or overall similarity would allow for perfect performance. we found that adults made significantly more rule-based responses to the test stimuli than did children. experiment 2 examined non-rule-based category learning by having children and adults complete a prototype abstraction task. children showed evidence of prototype abstraction, with many children showing a similar pattern of responding to adults. results are discussed within the covis framework.
considerable effort has been put to understand how infants may utilize statistical regularities of speech in early word segmentation. some studies suggest that infants are able to discover word boundaries at the points of high unpredictability across subsequent linguistic units such as phonemes or syllables. meanwhile, the possible role of the statistical regularities in the temporal organization of the speech at a pre-linguistic acoustic level has not been widely addressed. the current work examines how the short-term temporal predictability of the acoustic speech signal correlates with linguistically motivated phone-, syllable-, and word-level units. the results indicate that the points of low predictability correlate mainly with the boundaries between phone-like segments. this suggests that the same statistical learning mechanisms hypothesized to operate at the word level can also aid in temporal organization of the speech stream into phone-like temporal segments before knowing the phonemic or syllabic units of the language. 
conceptual metaphor theory proposes that the conceptual structure of emotions emerges through metaphorization from concrete concepts such spatial orientation and physical containment. primary metaphors for emotions have been described in a wide range of languages. here we show the results of a corpus analysis revealing that certain metaphors such as emotions are fluids in containers and emotions are bounded spaces are quite natural in spanish. moreover, the corpus data reveals that bounded space source domain is more frequently mapped onto negative emotions. second, we consider the question of whether the instantiation of metaphorical framing influences the way we reason about emotions. a questionnaire experiment was conducted to explore this question focusing on the case of locura (madness). our results show that when madness is framed as a fluid filling a container (the body) people tend to rate symptoms as less enduring and as more likely to be caused by social and environmental factors compared to when it is framed as an enclosed space.   
the purpose in diagnostic reasoning is to find the cause of observed effects by applying knowledge about the effects and their potential causes. in the causal structure linking causes and effects, effects can share causes or be linked more indirectly. the causal diversity effect reflects the increased support of a cause by a more widespread distribution of effects within the underlying causal structure. we report two experiments, in which participants acquired knowledge about causal structures and then evaluated diverse and proximal effect patterns with regard to their support for inferring a cause. the diversity effect in diagnostic reasoning was stronger if participants had acquired integrated knowledge about causal structures. moreover, teaching a reduced structure with less nodes open to alternative causation of proximal effects decreased the diversity effect. this confirmed that the causal diversity effect results from considering alternative causation and more generally that diagnostic reasoning draws on causal representations.
gift cards are a common form of restricted funds: the balance of a closed-loop (brand-specific) gift card can only be redeemed at the originating brand. we propose that this restriction compels the recipient of a gift card to consider how the funds can be spent, which leads to the formation of a brand-specific spending goal and corresponding mental account. because purchases more representative of the retailer will be more strongly associated with the spending goal and mental account, we predict that individuals shopping with retailer-specific gift cards have an increased preference for products typical of the retailer.
games of timing reflect dynamic decision-making under uncertainty, as it takes place in many real-world situations, including health care, safety and security.  rather than making discrete decisions, participants choose one or more points in time that determine the outcome.  we study individual's biases and characteristics in such games of timing.  we examine risk propensity as a personal preference affecting timing decisions and document a bias, impatience.  experiment 1 analyzes people's strategy in timing games in relation to a rational model.  contrasting two cognitive models suggests that individuals apply risk propensity to the probability distributions underlying short games and when unfamiliar with the situation, but that, over time, impatience takes over as a linear adjustment.  in experiment 2, impatient participants risk their incentive payment in order to play early, even if they receive no advantage from doing so.
resolving relational spatial phrases requires that a coherent mapping emerges between a visual scene and a triad of two objects and a relational term. we present a theoretical account that solves this problem based on neural principles. a neural dynamic architecture represents perceptual information in activation fields that make detection and selection decisions through neural interaction. activation nodes and their connectivity to the perceptual fields represent concepts. dynamic instabilities enable the autonomous sequential organization of the processing steps needed to resolve relational spatial phrases. these include bringing visual objects into the attentional foreground, performing spatial transformations, and making matching decisions. we demonstrate how the neural architecture may autonomously test different hypotheses to resolve relational spatial phrases. we discuss how this neural process account relates to existing theoretical perspectives and how to move beyond the entry point sketched here. 
is the direction of the script able to cause spatial biases in the mental models that understanders build when listening to language? in order to answer this question, we manipulated experimentally the experience of reading a script with different directionalities. spanish monolinguals read either normal (left-to-right), mirror reversed (right-to-left), rotated downward (up-down), or rotatedupward (down-up) text, and then drew the contents of auditory descriptions such as “the square is between the cross and the triangle”. the directionality of the drawings showed that a brief reading experience is enough to cause congruent and very specific spatial biases in mental model construction. however, there were limits to this flexibility: there was a strong overall preference to arrange the models along the horizontal dimension.
the monty hall dilemma (mhd) is a notorious brain teaser that received a lot of attention because both novices and statistical experts fail to reason correctly when solving this problem. in the current paper, we try to shed more light on the previous mhd research findings by discussing them in relationship to the equiprobability bias, which is known to develop with age and statistical education. besides investigating behavioral performances on the mhd, the experiment described in this paper focuses on the level of understanding of the problem and how the latter can be improved. the results show that by increasing the number of alternatives in the mhd, both behavioral performance and understanding of the problem improved. however, full understanding of the mhd was only reached by some participants, and depended on participants’ age and the number of choice alternatives in the mhd.
previous studies have suggested that learning is improved when people actively intervene rather than when they passively observe in causal structure learning tasks. two experiments were conducted to investigate whether a facilitative effect will occur in the judgment of causal strength. in experiment 1, participants were asked to learn causal strength in a situation where the target cause and context independently produced the effect. the intervention group could manipulate the state of the cause, which was later presented to the observation group (i.e., yoked-control procedure). the results demonstrated that participants made similar evaluations for the target cause, but not for the context. experiment 2 was designed to examine whether different estimations were because of facilitation or bias in which participants undervalue other causes. the results provide support for a facilitative effect, but suggest that the improvement with intervention may be limited to the estimation of weak causal strength.
many languages have a word class whose speech sounds are linked to sensory experiences (sound symbolism). here we investigated sound symbolism in taste. specifically, we performed psychological experiments to study the relationship between phonemes of japanese sound symbolic words and emotional evaluations of objects in taste. in the experiment, when participants drank something, they were asked to express the taste sensation using japanese sound symbolic words and then rate the comfort of the object with the semantic differential (sd) method. this experiment was aimed at specifying the systematic association between phonemes of japanese onomatopoeic words and taste-emotion evaluations. our results showed the existence of unique associations between the phonemes of the words for expressing the sensation and the evaluations of comfort/discomfort in taste and showed the possibility to clarify taste categories using sound symbolic method. as previous studies have suggested, onomatopoeic words expressing food texture are more easily used for emotional evaluations in taste than those expressing taste itself. however, we found a strong association between phonemes and sd scales related to taste such as “sweet”, “bitter”, and “salty”. therefore, we showed that sound symbolic words could be important indexes in investigating various level of perceptual dimension of taste including emotional evaluations like comfort/discomfort.
we investigate the processing and neurological basis of light verb constructions (lvcs) such as "the girl gives a kiss (to the boy)" where the thrust of the event argument structure is provided not by the verb "give" but by the np "a kiss". lvcs contrasts with  "heavy" counterparts (hvc) as in "photograph" in "the girl photographs a kiss (between her friends)". we examine two questions: 1) whether the heavy reading is derived from the "light" reading, or instead the "heavy" reading is lexically stored alongside the light counterpart, and 2) whether lvcs are lexically stored as idioms or instead, they are built compositionally during real-time comprehension. the results support a view of lvcs that is compositional (in real-time terms), semantic  in nature, and supported by the workings of the lif cortex, an area previously robustly associated with argument structure composition. 
we analyze the information discrepancy between diagrammatic representations and logical reasoning, which we call visual biases in diagrammatic reasoning. diagrammatic representations contain semantic information, which is based on the topological configurations of objects, and visual information, such as geometric location. in principle, visual information is unnecessary to the validity of logical reasoning. however, people are so sensitive to visual information such as size and shape in diagrams that they occasionally do not ignore irrelevant information. this phenomenon leads to mistakes in logical reasoning. we addressed this issue in the present study. in experiment 1, we assessed whether and how a visual bias of external diagrams affects reasoning performance. we asked participants to directly manipulate size-fixed (euler) diagrams while solving syllogistic tasks. in experiment 2, we tested whether size-scalable diagrams were able to reduce a visual bias of diagrams in logical reasoning.
how should we choose a model that predicts human choices? two important factors in this choice are a model's predictive power and a model's fexibility. in this paper, we compare these aspects of models in a large set of models applied to an experiment in which participants chose between brands of fictitious chocolate bars and a quasi-experiment predicting movies' gross revenue. we show that there is a trade-off between flexibility and predictive power, but that this trade-off appears to lie more towards the "flexible" side than what was previously thought.
language learners are sometimes faced with the problem of learning from input that is inconsistent or unexpected. unexpected patterns may be typologically rare (marked) or contrary to the pattern in the first language. using a novel game-like experimental paradigm, we examine the interaction of these factors for a set of artificial languages differing in the consistency and naturalness of number marking. the interaction of these factors in determining the degree of regularization is highly significant, and arises from individual differences that pose challenges for formal models.
the present study investigates how easily it can be detected whether a child is being truthful or not, and explores the cue validity of a child’s body movement for such type of classification. to achieve this, we introduce a combination of methods, in particular a perception test, and an automated body movement analysis. film fragments from truthful and deceptive children were shown to human judges who were given the task to decide whether the recorded child was being truthful or not. results reveal that judges are able to reliably and accurately distinguish truthful clips from lying clips. the automated movement analysis revealed a positive correlation between the amount of movement in a child and the perception of lies, i.e., the more movement the children exhibited during a clip, the higher the chance that the clip was perceived as a lie. 
humans are exceptionally good at inferring the intentions behind particular behavior even when the situation is complex or the context is completely new. in this paper we explore the hypothesis that a kind of analogical transfer from past experience to present situations plays an important role in the process of attributing intentions to ambiguous actions. the participants in our experiment were presented with two stories, the latter containing an ambiguous action. they were asked to evaluate how plausible was that the actor in the second story had a particular intention, either positive, or negative, or neutral. we found that the participants rated higher the plausibility of a negative intention when the preceding story was relationally similar and its actor manifested negative intentions. the attribution of intention to the ambiguous action was not different from that in the control condition when the preceding story was dissimilar or perceptually similar, or when its actor manifested positive intentions. these findings suggest that an analogical transfer of intentions does play a role in the attribution of intentions to ambiguous actions but the effect is limited to the attribution of negative intentions. 
spoken words have robust acoustic variation.  how listeners understand spoken words despite this variation remains an issue central to theories of speech perception. current models predict listener behavior based on the frequency of a variant in production. a phonological variant, though, is often investigated independent of phonetic variation that provides listeners with information about talkers. in this study, we investigate whether standard variants in words produced by a talker with a standard voice are recognized more quickly than standard variants in words produced by a talker with a non-standard voice. conversely, we investigate whether non-standard variants in words produced by a talker with a standard voice are recognized more slowly than standard variants in words produced by a talker with a non-standard voice.  these comparisons enable us to assess limitations of current theory, illuminating the understudied influence of talker voice in the understanding of spoken words with different phonological variants.
rating one’s own personality traits is a common self-referential information processing task. the current paper examined the mechanism underlying this sort of trait-rating task by using a pc cursor tracing technique (shiina, 2011a, b). the target phenomenon of interest was the inverted-u effect observed in trait ratings. the pc cursor tracing technique analyzed response times, tangential velocities, and rapid cursor movements (strokes). results supported klein’s notion (klein et al., 2002) that self-referenced episodic and semantic memories are used independently when making these trait decisions.
recent theories of semantic memory have proposed that concepts are grounded in sensorimotor activity and mediated by the context from which the knowledge is drawn (barsalou, 1999, 2003, 2008). conceptual knowledge draws upon information from all modalities and therefore includes knowledge of associated object actions linked with both function and general movement (bub, masson, & cree, 2008). the following experiment examined the conditions under which action information exerts an influence on experimental tasks particularly when taxonomic information is present. the experiment used a forced-choice triad task giving participants the choice of selecting between items that shared either a taxonomic or an action based relation with the target. the results showed that when the objects were presented as images on a white background (context-lean condition), participants were more likely to select the taxonomically related item. in contrast, when the same triads were presented as images being used in a functional scene (context-rich condition) they were more likely to select the action-related item. the results show that action knowledge is not automatic but is context-dependent. in line with views on embodied semantics, action-related information is drawn upon when objects are viewed and this influences task performance despite being unnecessary for the task. 
anthropomorphism is a default strategy for making the unfamiliar familiar, but is it a uniform strategy? do all dimensions of anthropomorphism “hang together”? we explored this question by involving adults (n = 99) in a speeded property-attribution task in which they decided, as quickly as possible, whether properties of two types— psychological and physiological—could be attributed to god. participants not only attributed more psychological properties to god than physiological properties, but they were also faster, more consistent, and more confident in making those attributions. participants showed the reverse pattern when denying properties to god. that is, they were slower, less consistent, and less confident in denying psychological properties to god than in denying physiological ones. these findings suggest that god is conceptualized, by default, as having a mind but not a body—a distinction that has important implications for the nature and origin of god concepts in particular and supernatural concepts in general.
understanding scientific theories like evolution by natural selection, classical mechanics, or plate tectonics requires knowledge restructuring at the level of individual concepts, or conceptual change. here, we investigate the role of cognitive reflection (frederick, 2005) in achieving conceptual change. college undergraduates (n = 184) were administered a 45-question survey probing their understanding of six domains of science requiring conceptual change – astronomy, evolution, geology, mechanics, perception, and thermodynamics – as well as (a) their ability to analyze covariation-based data, (b) their understanding of the nature of science (nos), and (c) their disposition towards cognitive reflection. cognitive reflection was a significant predictor of science understanding in all domains, as well as an independent predictor, explaining significantly more variance in science understanding than that explained by covariation analysis ability and nos understanding combined. these results suggest that cognitive reflection may be a prerequisite for changing certain cognitive structures, namely, concepts and theories.
this paper addresses the question of whether the presence of grammatical category evidentiality in language, traditionally defined as an expression of information source, affects cognitive performance. our research paradigm bridges together two theoretical perspectives from linguistics and cognitive psychology: (i) the position that evidentiality encodes epistemic commitment, specifically, that evidential forms present events as less certain and psychologically more distant from the here and now; (ii) the assumption that manipulation of psychological distance affects how events are perceived by the speaker, originating from construal level theory. results from study 1 provide experimental support for the hypothesis that evidentiality implies psychological distance: evidential forms consistently trigger the perception of an event as being less certain, further remote in time and space, and involving distant social relations. however, study 2 shows that evidentiality does not affect the level of abstraction with which an event is conceptualized, thus arguing against the sapir-whorf hypothesis.
optimism is a prevalent bias in human cognition including variations like self-serving beliefs, illusions of control and overly positive views of one's own future. further, optimism has been linked with both success and happiness. in fact, it has been described as a part of human mental well-being which has otherwise been assumed to be about being connected to reality. in reality, only people suffering from depression are realistic. here we study a formalization of optimism within a dual process framework and study its usefulness beyond human needs in a way that also applies to artificial reinforcement learning agents. optimism enables systematic exploration which is essential in an (partially) unknown world. the key property of an optimistic hypothesis is that if it is not contradicted when one acts greedily with respect to it, then one is well rewarded even if it is wrong.
a growing body of evidence suggests that implicit information processing has considerable effects on the higher-order cognitive processes such as insight problem solving. is such implicit information stored within the working memory system, or is it processed in a storage system other than working memory? to differentiate these two possibilities, the present study examined solution of the t-puzzle, an insight problem, after participants were or were not subliminally presented with the hint images by using the continuous flash suppression (cfs). a spatial tapping task, which is deemed to interfere with spatial working memory, was introduced during cfs. the two hypotheses each predicted deteriorated and maintained performance on the t-puzzle after the tapping task. contrary to these hypotheses, participants tended to exhibit better solution performance and relaxation of constraints after having the tapping task, either with or without subliminal presentation of the hints. mechanisms by which the secondary task may facilitate insight problem solving are discussed.
this study looks into children’s use of head gestures to express their appreciation for objects, comparing cases in which the gestures match or do not match their true attitude. children of about 5, 6 and 7 years old were asked to tell an experimenter whether or not they would like to have shown objects  as presents for their birthday. in a first round, children were not given any additional instructions, so that their feedback matched their genuine attitude towards the objects. in a second round, they were asked to give feedback  in a way that was the opposite of what they felt. analyses of their verbal reactions and  response delays suggest that the youngest children found it harder to produce incongruent feedback. while the relative use of head gestures decreases with age, all children produce more head gestures in the congruent condition, and produce more shaking gestures.
strategies used by people to verify quantified sentences, like `most cars are white', have been a popular research topic on the intersection of linguistics, computer science, philosophy, and psychology. a prominent computational model of the task, semantic automata, has been introduced by van benthem in 1983. in this paper we present a probabilistic extension of the model. we show that the model explains counting errors in the verification process. furthermore, we observe that the variation in quantifier verification data cannot be explained by approximate number sense, a prominent approach to probabilistic number estimation.
the ability to accurately assess math problem solving strategy is an important part of understanding the effects of practice. unfortunately the measures researchers trust are often unreliable and ill suited for studying the effects of practice. in the current study we are interested in identifying intermediary strategies that emerge as people switch from computational to retrieval strategies. to build a more accurate assessment of strategy we combine latency, neural evidence, and verbal reports using a mixture model. we compare the model’s predictions of strategy use with concurrent assessments collected during the problem solving. the results suggest that while participants consider a partial computation-retrieval strategy, distinct from pure computation, our model finds no evidence of such a partial state; however, distinction is found between early and well-practiced retrieval. these results suggest a discrepancy between the distinctions people make when reporting strategy use and the distinctions in the cognitive processes underlying strategy use.
similarity-based generalization is fundamental to human cognition, and the ability to draw analogies based on relational similarities between superficially different domains is crucial for reasoning and inference. learning to base generalization on shared relations rather than (or in the face of) shared perceptual features has been identified as an important developmental milestone. however, recent research has shown that children and adults can flexibly generalize based on perceptual or relational similarity, depending on what has been an effective strategy in the past in a given context. here we demonstrate that this pattern of behavior naturally emerges over the course of development in a domain-general statistical learning model that employs distributed, sub-symbolic representations. we suggest that this model offers a parsimonious account of the development of context-sensitive, similarity-based generalization and may provide several key advantages over other popular structured or symbolic approaches to modeling analogical inference.
research on the acquisition and use of communicative categories in domains such as language and music is largely divided between approaches suggesting innate cognitive constraints on domain-specific communicative forms, and approaches suggesting domain-general mechanisms through which specific communicative forms are learned. the present study investigates the effect of greater or lesser enculturation in the communicative system of western tonal music on peoples’ ability to discriminate culturally familiar and culturally unfamiliar pitch categories. the results indicate that while prior musical training affects peoples’ overall approach to pitch discrimination, the advantage is dependent on the familiarity (in both pitch and timbre) of the aural stimulus, and is negligible under conditions of maximal musical unfamiliarity. observed differences in pitch discrimination ability therefore appear to result from enculturation effects of exposure to western music, not from a relationship between musical training and innate perceptual categories.
social psychology aims to reveal how social behaviors are acquired through interactions with others (i.e., past interpersonal experiences) whereas social neuroscience investigates the neural substrates that correlate with acquired social behaviors. for example, people with greater ingroup bias are known to avoid or have avoided interactions with outgroup members than those with weaker ingroup bias, and their brain activation patterns are more distinct when viewing an ingroup member from an outgroup member. the present study aimed to examine the causal relation of these findings from different disciplines and integrate them within a single framework. a connectionist model was trained with/without the training regime reflecting the interpersonal experiences that were assumed to increase ingroup bias. as a result, if trained with such a training environment, the model’s internal representations of ingroup exemplars were more distinct from those of outgroup exemplars. thus, this model reproduced the dissimilarity structure in the neural representations of ingroup bias. in contrast, training without such a regime alleviated the representation dissimilarities.
human-robot interaction studies and human-human interaction studies often obtain similar findings. when manipulating high-level apparent cognitive cues in robots, however, this is not always the case. we investigated to what extent the type of agent (human or robot) and the type of behavior (honest or dishonest) affected perceived features of agency and trustworthiness in the context of a competitive game. we predicted that the human and robot in the dishonest manipulation would receive lower attributions of trustworthiness than the human and robot in the honest manipulation, and that the robot would be perceived as less intelligent and intentional than the human overall. the human and robot in the dishonest manipulation received lower attributions of trustworthiness as predicted, but, surprisingly, the robot was perceived to be more intelligent than the human.
this paper reports on a set of studies designed to investigate how people understand superhuman concepts that are of interest to cognitive scientists of religion. similar to findings of previous studies of surprising social conceptual combinations, we found that people generated numerous emergentproperties for such concepts. these results support the knowledge-based models of conceptual combination, in particular the context-based model of the minimal counterintuitiveness effect.
a number of studies on network analysis have found the small-world and scale-free properties in the network of free word association, which reflects human semantic knowledge. nevertheless, there have been very few attempts to apply network analysis to distributional semantic models (dsms), despite the fact that dsms have been extensively studied as a model of human semantic knowledge. in this paper, therefore, we analyze the small-world and scale-free properties of dsm networks. we demonstrate that dsm networks exhibit the same properties as the word association network. especially, we show that dsm networks have the distribution of the number of connections that follows the truncated power law, which is also observed in the association network. this result indicates that dsms provide a plausible model of semantic knowledge. furthermore, we propose a modified version of steyvers and tenenbaum's (2005) growing network model, which involves the processes of semantic differentiation and experiential correlation. this model can better explain different distributions generated by various dsm implementations.
whether it is in mining distal cultural influences or using more proximal artefacts, problem solving in the wild routinely scaffolds on the basis of interacting with resources outside the head. individuals often gesture, point or use objects as an aid to solving quotidian arithmetic problems. interactivity has been linked to better performance in problem solving, possibly due to a more efficient allocation of attentional resources and better distribution of cognitive load. different levels of interactivity were examined with a series of mental arithmetic problems. the integration of artefacts, such as tokens or a pen, enabled individuals to explore the opportunities afforded by a dynamic modification of the problem. mental arithmetic performance was more accurate and more efficient under these conditions. these findings underscore the importance of engineering task environments that support distributed problem representation and adequate levels of interactivity that creates a dynamically shifting topography of action affordances.
pantomimes are gestures that occur in absence of speech, which have no conventional meaning. since their meaning is not conventionalized, the question arises as to what extent they are idiosyncratic. to study this, we collected pantomimes for a standardized set of objects and annotated what representation techniques people used. this resulted in the (to our knowledge) first database of pantomimes. analyses show that there are regularities in the use of pantomime. that is similar techniques are used for objects across individuals. this shows that pantomime is not fully idiosyncratic. as pantomime is based on people’s mental representation of objects, the observed regularities seem to be a result of intrinsically similar mental representations. our database gives insight into pantomime 'norms' and could be used as a baseline against which clinical groups (e.g., people with aphasia) can be compared.
we explored the relationships between a perceptual-attention task and a word-verification task using event-related potential (erps) in preschool children. adopting an embodied multiple representation perspective, we set up the relationships between online (visual attention) and offline (mental imagery) simulation in the two tasks to test key aspects of abstract word acquisition. online visualization of all word types, during visual selective attention, elicited early frontal and occipital activation (~ 100 ms). the extent of such activation was correlated with a higher occipital late component (800 ms) during offline visualization concurrent with processing of more abstract/difficult words. consistent with developmental vision-language interaction embodiment models, our results support the tenet that the transmission of word meanings by typically developing children may be intimately linked to the visual perceptual contexts in which words are learned.
varying combinations of perceptual cues may be relevant for learning and action-selection. however, storing all possible cue combinations in memory is computationally implausible in sufficiently complex environments due to a state-space explosion. some psychological models suggest that cue combinations, i.e. chunks, should be generated at a conservative rate (epam/chrest; e.g. feigenbaum & simon, 1984). other models suggest that chunk retrieval is based on statistical regularities in the environment (i.e. recency and frequency; anderson & schooler, 1991). we present a computational model of chunk generation based on these two principles, and demonstrate how combining these principles alleviates state-space explosion, producing great savings in memory while maintaining a high level of performance.
according to the sensorimotor account, vision does not imply the construction of internally generated representations of the environment, but it is the skillful exercise of the sensorimotor contingencies obeying sense-specific laws. in this short study, i focus on the notion of “sensorimotor law” and characterize the kind of explanation provided by the sensorimotor theory as a form of covering law model. i then question the nature of such sensorimotor laws and describe them as mechanisms. i show that a mechanistic interpretation provides a better account of the sensorimotor invariances, which fosters us to rebalance the explanatory burden of sensorimotor action and information. finally, i show that the question of the role of representations within the sensorimotor theory should be reconsidered. 
we describe the overall theory of the soilie model of the human imagination. in this description, we outline cognitive capacities for learning and storage, image component selection and placement, as well as analogical reasoning. the guiding theory behind soilie is that visual imagination is constrained by regularities in visual memories.
the “shape bias” describes the finding that, starting around 24 months of age, children generalize object categories based upon shape to a greater degree than other perceptual features.  to date, research on the shape bias has consisted of debates about how attentional mechanisms engender the development of the shape bias. the current work moves beyond theoretical explanations grounded in attention processes and examines potential consequences of the shape bias in memory processes. in this experiment, children and adults’ memory performance for features of objects was examined in relation to their categorical biases. the results of the experiment demonstrated that, across the lifespan, learners with a shape bias were more likely to remember the shape of objects than they were the color and size. taken together, this work suggests the development of a shape bias may lead to more than just differences in attention to features of objects, but a memory bias for shape information.
recursive bayesian models of linguistic communication capture avariety of intricate kinds of pragmatic enrichment, but they tend todepend on the unrealistic assumption that agents are invariablyoptimal reasoners. we present a discriminative model that seeks tocapitalize on the insights of such approaches while addressing theseconcerns about inferential power. the model relies on only approximaterepresentations of language and context, and its recursive propertiesare limited to the training phase. the resulting behavior is often notoptimal, but we present experimental evidence that this suboptimalbehavior is closely aligned with human performance on both simple andcomplex reference games.
listening to music often drives people to move along to the beat of that music. past research has suggested that motor resources are recruited not just to produce a beat, but also to perceive a beat. the present study extends this correlational work and examines whether the motor system plays a functional role in beat perception using a dual-task behavioral paradigm. while performance on a beat perception task was affected by a simultaneous motor task compared to a control task (experiment 1), pitch perception was not affected (experiment 2). furthermore, this effect was mediated by whether or not participants had received formal musical training. the results suggest that the motor system may play a functional role in beat perception, even when people are not overtly moving in time to the beat. 
chinese has been recognized as one of most major languages in the world, and it is evident that more and more people are interested in understanding or using chinese. thus,  developing an efficient approach for learning chinese characters is considered as an important issue. certain previous studies have suggested various methods to learning chinese characters for the purpose of showing students how to read chinese characters. in chinese, the components can offer learners phonological and morphological meanings similar to the prefixes and suffixes in english, and character frequency provides learners a character list which can be widely used in daily life. however, very few studies have considered integrating the characteristics of component and character frequency. in this study, we have developed an effective and systematic approach for learning chinese characters based on both components and character frequency. the purpose of the study is to propose a traditional chinese character learning metric and to present a method for learning only a few components and then the resulting reading of more high frequency characters made up of these components. combining components and character frequency advantages, it can present an effective, systematic and rapid mechanism for learning traditional chinese characters.
human randomness perception is commonly described as biased. this is because when generating random sequences humans tend to systematically under- and over-represent certain sub-sequences relative to the number expected from an unbiased random process. in a purely theoretical analysis we have previously suggested that common misperceptions of randomness may actually reflect genuine aspects of the statistical environment, once cognitive constraints are taken into account which impact on how that environment is actually experienced. in the present study we provide a preliminary test of this account, comparing human-generated against unbiased process-generated binary sequences. crucially we apply metrics to both sets of sequences that reflect constraints on human experience. in addition, sequences are compared using statistics that are shown to be more appropriate than a standard expected value analysis. we find preliminary evidence in support of our theoretical account and challenge the notion of bias in human randomness perception.
knowledge monitoring is an important metacognitive process which can help students improve study habits and thereby increase academic performance. which is more useful in predicting test performance: knowing what you know, or knowing what you do not know? two distinct constructs of knowledge monitoring calibration, sensitivity and specificity, were used along with the more traditional gamma to predict performance on tests in an undergraduate educational psychology course.  it was found that sensitivity, a measure of correctly identifying known items, was the most useful in predicting overall test scores as well as final exam scores. specificity, on the other hand, had no significant impact on exam performance.  results suggest that sensitivity and specificity may be more meaningful measures of knowledge monitoring calibration when it comes to predicting academic achievement, as well as being better adapted for missing values in any one cell of the data.
this study investigated mind wandering during video lectures in an online course. working memory capacity and interest were also considered. higher mind wandering predicted lower performance. lower working memory capacity predicted higher mind wandering.  higher interest predicted lesser mind wandering. social media and technology accounted for 29% of off-task thinking.
‘explanation’ appears to be ambiguous between a representational-artifact, an objective, and a doxastic sense. that the distinctions between the three are still poorly understood we regard as an impediment to progress in the philosophy of science and as a source of the field’s resistance to greater integration with experimental psychology. we begin to elucidate the overlapping contours of the three sense of ‘explanation’ using a variation on powell & horne’s semantic integration paradigm, showing that both laypeople and scientists regard doxastic explanations as constitutive of representational-artifact, but not of objective, explanations and accuracy as closely connected to objective, but not representational-artifact, explanations.
the secondary distinctiveness effect is the effect that stimuli that are unusual or different from stored knowledge are remembered better than common stimuli. we investigate the processing time explanation for this effect, i.e., that distinctive stimuli receive more attention and thus more processing time during encoding, by combining methodology from object recognition with memory tasks. participants in our experiment name common and distinctive items (typically and atypically colored objects), and then memory is tested. our results replicate the secondary distinctiveness effect, as recognition scores are higher for atypically colored objects than for typical ones. crucially, analyses of response times in the naming task show that atypically colored objects are processed significantly slower than typical ones. we take these findings as providing support for the processing time hypothesis for the secondary distinctiveness effect.
humans have accumulated a wealth of knowledge over the course of many generations, implementing a kind of "cultural ratchet".  past work has used models and experiments in the iterated learning paradigm to understand how knowledge is acquired and changed over generations.  however, this work has assumed that learners receive extremely rich testimony from their teacher: the teacher's entire posterior distribution over possible states of the world.  we relax this assumption and show that much sparser testimony may still be sufficient for learners to improve over time, although with limits on the concepts that can be learned.  we experimentally demonstrate this result by running an iterated learning experiment based on a classic category learning task.
two experiments explored the effects of changes in distance and location on the accessibility of event-related information during language comprehension. in experiment 1, listeners viewed visual scenes depicting a location containing several objects, while they listened to narratives describing an agent either staying in that initial location, or moving to a new one (either close or far away), and then thinking about one of the depicted objects. we found that eye movements to these objects were modulated (reduced) by changes in location, rather than distance. in experiment 2, listeners viewed scenes depicting two rooms, while they listened to narratives describing an object moving either between the rooms, or within one room. when the object was mentioned following the event, we found fewer eye movements to it when the movement occurred between rooms. we discuss these results in relation to the event horizon model.
40 high school students were given a battery of paper and pencil tests, which collectively assessed a variety of spatial abilities, graph and table competencies, conceptual mastery of calculus, and achievement in common topics from typical precalculus and calculus courses.  in addition, students completed a computer-presented measure of coordinating multiple representations (cmr), in which they had to assess whether two mathematical representations (e.g. an equation and a graph) depicted the same underlying mathematical function.  gaze data were captured during this measure, using a tobii t60 eye tracker.  findings suggest that good or  poor performance on several paper measures is associated with distinct and specific gaze behaviors.  better achievement scores are associated with fewer fixations near the centerline of the graph, and with fewer point-plotting and function scanning behaviors.  these findings are discussed in terms of differing approaches or strategies for engaging in cmr.
this paper describes a computational emotion-theoretic model (i.e., clarion-e) used to capture the dynamics of appraisal and coping by victims of school bullying. it provides an over-view of recent research concerning bullying appraisals and coping strategies by students who reported themselves as being the victims of school bullying. it also demonstrates how such processes may be expressed computationally.
the main purpose of this study is to examine how people learn time-varying categories as well as whether order effect exists in such learning. to this end, we design three types of category structures, in which the stimuli vary along trials in an ascending, descending, and quadratic trend. also, tendency to repeat preceding category label as current response is regarded as evidence for order effect. the results show a clear order effect in these experiments. the modeling results reveal that gcm, which is modified to be sensitive to trial order and sdgcm, which relies on the similarity and dissimilarity to the exemplars for categorization, provide a good fit for all experiments. however, the rule-based model used by navarro, perfors, and vong (2013), which changes the boundary trial by trial has difficulty accommodating the learning pattern in quadratic trend. 
this study examined the processing of two types of japanese causative cleft constructions (subject-gap vs. object-gap) by conducting an event-related brain potential (erp) experiment to clarify the processing mechanism of long-distance dependencies. the results demonstrated that the subject-gap constructions elicited larger p600 effects compared with object-gap constructions. based on these findings, we argue that the linear distance between the extracted argument (filler) and its original gap position is a crucial factor in determining the processing costs in japanese causative cleft constructions.
the wisdom of the crowd technique has been shown to be very effective in producing judgments more accurate than those of individuals. however, its performance in situations in which the intended estimates would involve responses of greatly differing magnitudes is less well understood. we first carried out an experiment to elicit people's estimates in one such domain, populations of u.s. metropolitan areas. results indicated that there were indeed vast between-subjects differences in magnitudes of responses. we then proposed a hierarchical bayesian model that incorporates different respondents' biases in terms of the overall magnitudes of their answers and the amount of individual uncertainties. we implemented three variations of this model with different ways of instantiating the individual differences in overall magnitude. estimates produced by the variation that accounts for the stochasticities in response magnitude outperformed those based on standard wisdom of the crowd aggregation methods and other variations.
a central problem in philosophy of mind concerns the relationship between subjective experiences and the physical processes that subserve them.   there seems to be an unbridgeable ``explanatory gap'' between the two.  whereas other scientific explanations (e.g. the explanation of temperature in terms of kinetic energy) involve determinate relationships between two kinds of phenomena, correlations between patterns of neural activity and conscious experiences seem to be arbitrary.  i argue that by developing computer models of embodied agents, and interpreting them using the tools of philosophical phenomenology, the relationship between neural and conscious processes can be seen to be systematic, and non-arbitrary.  visualizations of these models serve as ``bridge metaphors'' that further emphasize how systematic neuro-phenomenological relations are.  by showing that links between brain states and conscious states are non-arbitrary, the explanatory gap is narrowed.
we investigated how closely speakers’ production preferences were interconnected with comprehenders’ processing difficulty, using dative sentences in korean, based on the behavioral data that we obtained from a production study and an eye-tracking reading study, respectively. in both studies, we tested the long-before-short preference such that long words/phrases were highly likely to be placed prior to short words/phrases (yamashita & chang, 2001). both speakers and comprehenders preferred dative sentences of which target arguments (i.e., recipients and patients) were canonically ordered when the length of the arguments did not differ and when the length of recipients was longer than that of patients. however, when the length of patients was longer than that of recipients, the canonical order of arguments was not preferred. our data indicated that speakers and comprehension observed the length constraint, although they eventually violated the canonicality constraint. the asymmetry of argument order modulated by long-before-short preference was further examined in the linear mixed-effect regression model to see the relationship between production and comprehension. the results revealed that comprehenders felt easier to process sentences as the degree of speakers’ structural preferences increased. altogether, we present our results as evidence showing that speakers and comprehenders are closely interconnected each other, supporting the claim that the processes in production and comprehension are not dichotomy (pickering & garrod, 2013). 
understanding how humans control unstable systems is central to many research problems, with applications ranging from quiet standing to aircraft landing. increasingly much evidence appears in favor of event-driven control hypothesis: human operators are passive by default and only start actively controlling the system when the discrepancy between the current and desired system states becomes large. the present study proposes a cognitive model describing the transitions between the passive and the active phase of control behavior. the model is based on the concept of random walk in double-well potential widely employed in physics. unlike the conventionally used model of fixed threshold, the proposed model is intrinsically stochastic and thus conforms to the physiological interpretation of the threshold as a probabilistic rather than deterministic notion. the model is studied numerically and is confronted to the experimental data on virtual stick balancing. the results confirm the validity of the model and suggest that the double-well potential can be used in modeling human control behavior in a diverse range of applications.
our ability to detect patterns and observe regularities is a fundamental part of reasoning and learning. various theoretical accounts conceptualize induction in different ways. in the current study, we used the balance-scale task and mouse-tracking techniques as a means to explore the cognitive dynamics that underlie inductive pattern recognition. although we did not replicate an expected interaction between problem difficulty and task instruction because of a procedural constraint, we were still able to examine the implicit cognitive dynamics underlying explicit behavioral responses as a function of problem difficulty. in particular, we found some support that newer, non-algorithmic accounts of cognition on such tasks better characterize performance than rule-based accounts.  
a number of studies indicate that eye movements play an integral role in visuospatial memory during perceptual-motor tasks like making a sandwich or drawing a recently perceived scene from short-term memory.  the present study analyzed spatial distributions of eye movements to test the decay of visuospatial memory and its effect on perceptual-motor task performance.  participants viewed images of natural scenes for 30 seconds each, and after each image was removed for either a 15 or 30 second delay, participants drew the image from memory.  results showed that eye movements during drawing became less like those during viewing after the longer delay compared with the shorter one. this decoupling of eye movements was also reflected in performance, in that drawings were nominally less similar to their corresponding images after the longer delay period.
the current study focused on young students’ prediction accuracy and recall confidence. the main goal was to investigate the students’ prediction accuracy and confidence on their prediction. three hundred and sixty (grades: 1-6) students participated in the study (60 from each grade). participants were tested individually in a quiet room located in their schools. they were asked to learn 10 pictures, judge their recall prediction, rate their confidence in prediction, and then recall the pictures. results showed that students (1-3) had low prediction accuracy. the 4-6 graders were significantly better at calibration than all other grades. together, these results suggest that young students are indeed inaccurate but showing progress in their academic courses. implications and future research are discussed. 
previous research indicates that when correlations are represented as scatter plots, people's ability to discriminate correlations increases as the strength of the correlations increase. for example, 0.9 is discriminated from 0.7 more accurately than 0.7 is discriminated from .5, despite the constant difference of 0.2.  the present research identifies a similar phenomenon when the stimuli are columns of number-pairs rather than scatter plots. the results imply a cognitive model wherein the perceiver samples a subset of the data from each of two stimulus arrays, computes a correlation for each, then compares the two correlations. statistically, when the correlations are strong, a sub-sample of data is likely to be highly linear, regardless of which random subset happens to be drawn. but for weak correlations, the correlation exhibited by a sub-sample will be highly unstable. thus, sampling variability in the environment combines with incomplete psychological sampling to produce the observed behavior. 
learning to categorize objects is known to have systematic effects on how those objects are judged (e.g., similarity or same-different judgments). these so-called learned categorical perception (cp) effects have been demonstrated with a wide variety of stimuli, particularly visual stimuli. however, it does not appear that they have ever been explored with visual motion features that are arguably characteristic of many real categories, such as animals and vehicles. this project’s goal is to develop visual stimuli that vary on dimensions such as speed or direction of movement in order to test for learned cp effects of learning to categorize such stimuli. this effort poses new challenges of isolating, measuring, and independently varying dimensions of visual movement, as well as addressing whether the resulting dimensions are similar to real world category-relevant dimensions of movement. meeting these challenges will allow for an important test of the generality of learned cp effects.
avoiding and treating illness is vital to a person’s wellbeing. yet, people vary in their conceptions of the causes, transmission, prevention, and treatment of everyday illnesses such as colds and the flu. in semi-structured interviews, we examined u.s. and indonesian adults’ beliefs about these illnesses, and explored an illness concept that is pervasive in indonesian culture, "masuk angin" (literally “trapped wind”). the results revealed some interesting findings. first, indonesians’ conceptions of colds and flu were less differentiated than u.s. participants’. second, indonesians often described illness transmission in terms of environmental factors (e.g., the weather), whereas u.s. participants described interpersonal factors (e.g., touching sick people). third, while most participants focused on medical treatments for colds and flu, indonesian novices described behavioral treatments for masuk angin (e.g., scraping). finally, indonesian medical experts were reluctant to provide explanations for masuk angin, either dismissing it as illusory or integrating it into the colds/flu category.
we explore two types of spatial alignment, overlay and gesture, during an engineering lesson on bridge building. spatial alignment via juxtaposition (gentner et al., under review) or overlay (applebaum et al., in prep) has been found to promote understanding triangular bracing in stable structures. gestures tracing a triangle may also support learning this concept. we used a 2(gesture, no gesture) x 2(overlay, no overlay) design to teach children ages 6-9 about triangles in bridges. in study 1, children learned regardless of condition, but they learned significantly less in the gesture conditions, which used a fast tracing gesture (β=-1.62, p=.01; m(improve_gesture)=.30, sd=.38, m(improve_no_gesture)=.48, sd=.33; alignment conditions: β=-.05, p&gt;.1; m(improve_alignment)=.42, sd=.40, m(improve_no_alignment)=.38, sd=.34). in study 2, we presented videos with a slower, deliberate tracing gesture. preliminary results suggest that gesture can facilitate learning by highlighting the relationship between the individual components shared by the triangle and the larger structure.
this study suggests the possibility of application of utility theory to causal inference. arai (2011) has shown that people tend to think causality stronger when they are involved in the task than when they are not. therefore we attempted to explain the effect of ego-involvement on causal reasoning by gain and loss. two hundreds and thirty-five university students inferred the relation between cause and effect and decided their action in terms of taking the action of cause in an imaginary content. each participant was allocated into one of four conditions: gain, loss, involvement or control. the result indicated the action was less in loss group than in ego-involvement group. this is consistent with a prediction from utility theories. based on these findings, it appears that the effect of ego-involvement on causal reasoning can be explained by utility.
 in recent work (laszlo & armstrong, 2013; armstrong & laszlo, 2013), we have been laying the foundation for developing connectionist models of the n400 erp component that are sensitive to the context in which lexical item occurs via the incorporation of a neural fatigue dynamic. here, we test the capacities of a prior model, to which this dynamic has been added, in accounting for a range of identity-repetition context effects measured in a coordinated electrophysiological study. these effects include the standard reduction of mean amplitude in the time domain and concurrent modulation of spectral power in the frequency domain. evaluating whether the model accounts for these effects puts the strength of domain-general principles in generating “emergent” phenomena to the test because it requires generalization to novel dimensions including: context, new lexical types, and effects in the frequency domain. we show that the model explains core effects on all these fronts. 
research in the field of music cognition typically focuses either on low-level, technically oriented approaches or on highly abstract ontological discussions that lack direct grounding in evidence. to bridge this gap, we propose a revision of the ontology underlying such research, from a perspective restricted to the acoustic and individual aspects of music to an embodied, extended, and anti-individualist approach. we explore the application of these ideas to empirical research by discussing two experiments conducted by our group. one of them tests whether the ability to play an instrument has an influence in how a subject listens to music; the other one explores the impact of visual information in the perception of sound as music. we comment on the results obtained and its theoretical significance. our work shows that it is possible for abstract theorizing and concrete experimentation to go hand in hand in the field of music studies.
why we feel uneasy in communication against artificial agent? previous research suggested that frequent changes of depth of reasoning to opponent generate rich communication between humans. the deepest reasoning was inference of own mental model based on opponent model. this research indicates that lack of depth of reasoning made human-agent interaction difficult. we defined the inference of own mental model based on opponent model as “meta-opponent model” and made an experiment to investigate whether the model can be used in interaction with artificial-agents. in this experiment, we executed verbal protocol analysis and fnirs analysis using a simple selection game. the experiment has consisted of four conditions; we used as agents three different programs that explained "opponent is an artificial agent" and one program that explained "opponent is a human". as the results, when there were sufficient complex system and proper instruction, we observed the applying meta-opponent model to artificial agents.
students have trouble using and interpreting topographic maps. experienced map-users identify patterns of contour lines representing topographic structures and visualize that information in 3d. novices struggle with both recognizing 2d patterns and visualizing 3d structures from contour lines. in this study, the pattern identification group received instruction focused on identifying contour patterns for three topographic forms, the 3d visualization group received instruction focused on visualizing three forms in 3d, and a control text-based instruction group received basic written instruction. the pattern identification group performed better than the text-based instruction group on a measure of topographic map use. the 3d visualization group performed between the two groups. performance on a perspective-taking test predicted skills for map use in all three groups, and the water level test predicted skills for map use in the 3d visualization group. learning to identify meaningful contour patterns appears to be the most effective strategy for novice map-users. 
introduction: among various brain regions involved in aesthetic judgment, medial prefrontal cortex has a pivotal role in judging the beauty of visual stimuli.  it seems that this region’s influence in aesthetic preference is an effect of its role in affective processes. in the following study, we have used transcranial direct current stimulation (tdcs) in order to evaluate the role of medial prefrontal cortex in aesthetic judgment.method: we used three different types of tdcs stimulation, that is, anodal, cathodal, and sham. 36 participants (18 female) undertook in three experimental sessions randomly in which they received 1ma stimulation for 20 min on their medial prefrontal cortex.  active electrodes were located bilaterally on the forehead and the reference electrode was on the right arm.  ten minutes after the onset of stimulation, subjects got involved in the on-line computerized task of the aesthetic judgment.results: in general, the effect of tdcs on medial prefrontal cortex on aesthetic judgment was significant f(2 & 37.84)=3.89, p=0.029). the results show that anodal stimulation of the medial prefrontal cortex affect the aesthetic preference significantly (p=0.036), while no such effect was seen in cathodal stimulation (p=0.663). there was no sex-related effect (f(1 & 33.48)=3.39, p=0.074).discussion: medial prefrontal cortex through its top-down control over affective side of aesthetic preference can reduce the preference.
research has demonstrated that in some types of human computer interactions people behave toward an artificially intelligent agent (aig) as if it had moral agency. anthropomorphic behaviors such as sparing a computer’s “feelings” and holding it morally responsible for cheating have been observed. however, research has not examined human capacity to act against one’s own interest as a result of perceived moral agency of an aig. using the ultimatum game paradigm, this study investigates whether participants who engage in an online chat interaction with a partner whom they believe to be an aig will reject unfair offers from that aig at a similar rate as participants who believe their partner to be a human. using a $10 stake, preliminary data suggest participants would rather lose real money (always offered $2) than allow the aig to “keep” the remaining $8, even when the artificial nature of the aig is made highly salient. 
performance on perceptual-motor (pm) tasks should not be affected by cognitive workload (cw). subjects performed a novel task that combined a "recall" version of the n-back task and a pm distractor task. subjects' performance was significantly worse on the pm task when cw was increased. as cw was manipulated, the perceptual and motor requirements of both the n-back task and the pm task remained the same, with only the working-memory requirement varying. the comparable perceptual and motor requirements across all levels of cw implies that increasing cw resulted in degraded pm performance; however, possible mediators still need to be examined, such as the higher level of negative feedback resulting from increased errors. a comparison between multiple causal models that include mediators is planned, to help determine if this apparent relationship between cw and pm performance degradation can be better explained by other variables that vary when increasing cw. 
computer-based scaffolding is instructional support that assists students as they generate solutions to complex and ill-structured problems, goals, or tasks, helping to increase and integrate higher-order skills in the process. in this preliminary meta-analysis in stem education, we coded 35 studies, resulting in 97 outcomes. the average effect size for scaffolding was 0.44. performance-adapted fading/adding led to significantly higher effect sizes than fixed fading. there were no other statistically significant differences, though trends favored adding scaffolding over fading and no-fading; principles and application-level assessment over concept level; group random over quasi-experimental and random; and under-represented over low-performing and low-income.this poster describes our work to date in this meta-analysis project. by the end of the project, we will have coded about 150 studies. this will not be complete by cogsci2014, but estimates to date of effect sizes should be fairly accurate, with confidence intervals shrinking as we code more studies. 
selective attention requires both the ability to inhibit irrelevant distractors, as well as the ability to activate and focus on relevant stimuli. research in adults suggests that these are two separate processes that function together during efficient attentional selection. less is known about how these two processes contribute to selective attention in early development. in this study, we presented young children with a visual search task that measured distractor inhibition and the target activation. children searched for the same target among the same distractors for several trials. immediately after, half of the children searched for a new target among the same distractors, providing a measure of inhibiting abilities, while the other half searched for the same target among new distractors, providing a measure of target activation abilities. results point to the importance of these two processes for selective attention in early childhood.
 inter-individual differences in cognition, emotion, and behaviour are pervasive mediators of social interaction. higgins and scholer (2008) suggest that personality is revealed through motivated preferences and biases in the way people interact with their environment. we investigate personality attribution using a paradigm where a human participant is tasked with assessing the personality of an autonomous virtual characters (avc) responding to affective stimuli. we evoke different impressions of personality by varying the characteristics of the mapping between affective quality of the stimulus and overt behavioral response of the avc. the characteristics of the mapping draws upon prior empirical evidence and the bis/bas model of personality (carver and white, 1994). we present first results of an implementation using the smartbody character animation platform (thiebaux et al, 2008). our work illustrates how autonomous virtual characters can be used as a platform to develop models of human cognition, affect, and behavior.
touchscreens are quickly becoming a pervasive platform for human-computer interactions, and very large touchscreens pose interesting challenges to human users. the visual material displayed on very large screens (over 50-inches on the diagonal) can quickly outstrip the focal abilities of the human user. touch interactions require users to position themselves close to the screen, further narrowing the field of view, and require larger body and limb movements than typical mouse, stylus, or keyboard interactions. the present effort characterized touch-based interactions with a very large, 82-inch touchscreen, including pointing/tapping, constrained and unconstrained straight path tracing, and constrained curved path tracing. movement time performance conformed to fitts’ and steering laws. additional hazard function analysis confirms the efficacy of the difficulty manipulations and provides a novel, functional measure of information throughput in this domain. juxtaposition of these two analyses provides additional insights into the notion of “efficiency” for human-computer touchscreen interactions.
research has shown that wrapping a visit to a museum around a story makes that visit more memorable. blessing and skowronek (2013) embedded activities for children at the glazer children’s museum in a story that motivated each activity. we hypothesize that personalizing the story more, by including the child’s first name and other particular information provided by the child, will make the visit even more memorable. we performed a study at the museum where half the families toured the museum with a personalized story for the child and half received an identical, but un-personalized, story. the story, activities, and short quizzes were contained in an ipad application, which kept track of time, success at the quizzes, and also recorded conversations. children also provided answers to a questionnaire about their experiences two weeks after their visit. we compare performance between the conditions to assess the power of personalization.
previous neuroimaging studies (e.g., green et al., 2010; kmiecik & morrison, 2013) suggest the neurocognitive processes responsible for verbal analogical reasoning vary with the semantic distance between source and target. in order to further investigate how semantic and relational similarity interacts during reasoning, we presented the a-, b-, c-, and d-terms of verbal analogies sequentially while participants judged whether problems were valid analogies. a:b and c:d pairs of the analogies were either semantically near or far as judged by latent semantic analysis. alternate versions were created so that every-word appeared in every position across participants. we recorded eeg to access the level of priming at various stages during reasoning. our results suggest that relational priming impacts processing as early as the c-term, but becomes increasingly important as the d-term of the analogy is revealed. we discuss these results with respect to different models of analogical processing.
expert-based estimation is the most common and preferred method to estimate the effort for software development project because it is fast, less expensive and reasonably accuracy. expert software developers use his intuition and experience during effort estimation task. estimation by analogy of features is also used to compare the new feature to similar in past development. this paper extends recent studies and shows how experts are able to perceive similarities between two features and to categorize their complexities using software chunks with semantics information based on their intuition and perception of software features cues. the results of this experiment showed experts judgment and analogy to estimate features effort are almost identical and accurate when compared to actual project. the current research proposes a cognitive model to explain expert judgment and analogy for software development effort estimation. 
people are very good at learning from instructions. whenever a person receives a novel instruction, she can proactively build a plan in her head and then execute it with a very high accuracy. this proactive planning strategy gets faster over time. here we test whether training people on proactive strategies will improve their abilities on other tasks that benefit from proactive approaches. people were trained on rapid instruction task learning (ritl; e.g. cole, laurent, & stocco, 2013), with or without having to plan their approach to solving the problem. they were then tested on a task switching task. preliminary results show that the proactive approach does not transfer to task switching. this indicates that training people on a forced proactive strategy may not improve their spontaneous proactive behavior.
we assessed the role of the drd2 dopaminergic striatal gene polymorphism on performance in unidimensional and conjunctive rule-based category learning tasks. the unidimensional task requires a rule along a single stimulus dimension, while the conjunctive rule task utilizes a combination of two dimensions to distinguish members of each category. the results show that drd2 c957t t allele carriers outperformed cc homozygotes on both the unidimensional and conjunctive rule tasks.  we also observed effects for two other dopaminergic genes.  darpp-32 aa homozygotes outperformed g allele carriers on both tasks, and comt met allele carriers outperformed val homozygotes in the conjunctive rule task, but not in the unidimensional task. our results suggest that while striatal dopamine binding might play a critical role in both types of rule-based tasks, prefrontal dopamine binding is important for performing well in more complex conjunctive rule tasks.  we discuss implications for neurobiological models of category-learning.
semantic systems vary substantially across languages, but may nonetheless be constrained by structure in the world. malt et al. (2008) advanced such an argument in the domain of locomotion. in their study, speakers of english, spanish, japanese, and belgian dutch named video clips of an individual locomoting on a treadmill. in all four languages, naming respected the distinction between walking and running gaits, suggesting a universal semantic constraint based on a biomechanical discontinuity. here, we replicate this finding using a more complex and naturalistic stimulus set (clips from film trailers and online videos containing locomotion), and show that it generalizes to additional languages (mandarin and korean) and dialects (netherlands dutch). at the same time, we find that naming sometimes crosscuts the biomechanical walk-run distinction when locomotion is ambiguous. in the case of dutch, we find that basic-level locomotion terms sometimes take on superordinate meanings, straddling the basic-level category boundary.
previous research has suggested that studying categories in either interleaved or blocked fashion can be beneficial for inductive learning. these conflicting results can be explained by considering that different category structures benefit differentially from blocked or interleaved study (carvalho & goldstone, 2013). however, memory-based theories have related the advantage of interleaved study with retrieval dynamics between study and test. one prediction of these theories is that previous results showing differential benefit of one schedule over the other might be related with the immediate test used. here, participants were tested immediately and 24h after studying categories either interleaved or blocked. the findings are consistent with previous evidence using shorter retention intervals. the increased temporal delay between study and test does not seem to affect transfer performance for different types of category structures. these results are in agreement with the theory put forward by carvalho and goldstone (2013).
what consequences does the embodied and situative nature of cognition have for problem solving? research on situative and embodied cognition has shown that certain aspects of attention and perception are attuned to physical characteristics and settings (bhalla & proffitt, 1999). further, some recent research has suggested that the cognitive and neural substrates of search processes in semantic memory are shared with search/foraging processes in the world, and that search constraints in the physical environment can shape search patterns in both physical foraging and in semantic memory (hills et al., 2008, 2012). in a series of studies, we explore whether and how this might have consequences for search processes in problem solving. specifically, we examine whether and how performance on divergent (requiring many alternative solutions) and convergent (requiring a single “best” solution) problem-solving tasks differs depending on the size of the physical environment in which the problem solver is situated. we reasoned that larger rooms afford broader physical movements and search, and might therefore similarly activate a broader search in semantic memory during divergent problem solving. participants solved divergent (alternative uses, visual invention task) and convergent problems (letter series extrapolation task, remote associates test) in either a small space (small room) or large space (large hall). across a range of problem solving performance indicators (e.g., fluency, novelty, quality), we found that performance on divergent tasks was slightly but reliably higher in the larger space, compared to the smaller space. however, we found no such variation on convergent task performance across the two types of environments. these findings suggest that problem-solving processes (specifically divergent search in semantic memory) may be influenced by constraints and affordances in one’s physical environment.
active machine learning research shows that training of classifiers can be improved when the learning algorithm itself selects training data (e.g., choosing examples for which it is uncertain). recent work with humans documents similar improvements whereby "active" learners who can select their own training examples are faster at learning simple classification rules than "passive" learners who observe data selected by another source. one explanation for this advantage is that active learners are able to choose data that tests the hypothesis they are currently considering, whereas for passive learners, data is independent of the learner's belief. we explore whether the efficiency of passive learning can be improved with "adaptive teachers” that estimate a learner's current hypothesis and generate training data that is expected to be most helpful. our successes and failures with this approach highlight the need to consider principles of human learning in the design of effective adaptive teachers.
linguistic ambiguity and semantic inference are commonly used as a technique to generate humor. the purpose of this study was to investigate the interaction between semantic processing and humor. sixty undergraduate students participated in this study. the independent variables of semantic processing (ambiguity/bridge inference) and humor (funny/non-funny) were manipulated. dependent variables were reaction times, comprehensibility, and funniness, respectively. stimuli were presented using e-prime 2.0 software. 240 stimuli were selected, including 60 stimuli for each of four different conditions: the ambiguous jokes, inference jokes, ambiguous sentences, and inference sentences. the interaction was no significant for funniness rating in behavioral research. the unexpected results revealed that inference joke was no significantly funnier than ambiguous joke, suggesting that readers did not spend a longer time for apprehending backward-inference jokes and then felt significantly higher funniness. however, the results of neural correlates indicated that the interaction was significant differences between semantic and humor effects. this more complete understanding of the interaction between semantic processing and humor will allow us to further specify the neural circuit of humor developed in our previous research (chan et al., 2012, 2013).
median thinkers are able to consider things from different perspectives and integrate information efficiently for situationally appropriate decisions. previous research has found that high median thinkers tend to adopt a global and flexible processing strategy compared to low median thinkers, but less is known about how one’s processing capacity is related to his/her median thinking style. processing capacity represents the changes in processing efficiency as a function of workload, and it constrains the selection of decision strategies. here we examined how the processing capacity is related to the median thinking style. a redundant-target detection task was conducted to measure the processing capacity. results showed that high median thinkers have higher processing capacity than low median thinkers, suggesting that high median thinkers process information more efficiently in an integrated way. these results cohere with previous reports on individual differences between median thinkers in terms of cognitive processing style.
previous studies have shown that transitive agentive descriptions of an accident tend to lead the readers to attributing more blame and liability to the agent of the accident than intransitive non-agentive descriptions (borodisky & fausey, 2010; fausey & boroditsky, 2011). we examined this linguistic effect in chinese by contrasting the non-agentive descriptions with two types of agentive descriptions, namely the svo construction and the ba construction. participants read only one version of two accident descriptions and answered questions about how much the person was to blame for the accidents and how much money should the person be asked to pay for the loss. the results revealed no significant difference among the three types of descriptions either in blame or financial liability. one possible explanation of the null results may have to do with the stronger field-dependence of the chinese people for whom contextual information attracts more attention and may have overridden the subtle linguistic cues that distinguished the different descriptions.
to establish the implicit associations of stimulus-response connection in a word color discrimination task, the participants have to learn the patterns of actions and feel the weights of pictoral objects through successive trials of vertifying the statements in the sentences or pictures. two particular response keys were arranged to represent the actions and the word colors respectively, and the objects having different weight values associate the specific actions. the crtical words in the word-color discrimination task are related to the feeling of weights from the imagined actions given by the experimental instruction. praticipants¡¦ mission of experiment 1 was to imagine that they move objects up-staris or down-stairs, and the mission of experiment 2 was to imagine that they exchange objects with others. the stimulus-response compatibility effects in experiment 1 were found related to the directions of actions, and the effects in experiment 2 were constrained by the feeling of weight after imagining the actions. the overall findings show that the patterns of moving objects could shape the comprehension of imagined situation differently. we suggest a hypothetical ¡§situation modular¡¨ in the information processing model of stimulus-response compatibility for the function of creating embodied representations that participants can use to acquire the implicit associations among concepts.
backward associative strength (bas) is considered as a good predictor of false memory (fm) produced by deese-roediger-mcdermott (drm) task. previous study found that both semantic properties and bas load on the same factor of the task (brainerd et al., 2008). it is proposed that drm lists composed of situation properties (sp) can elicit high fm at low bas (cann et al., 2011). we assume that sp could influence metacognitive monitoring for drm task. the present study investigates if sp lists and bas influence metacognitive monitoring of fm. both gamma and c (cheng, 2010) values are used to measure the metacognitive monitoring of drm task in roediger’s (2013) paradigm. the results show that sp reduces metacognitive monitoring of fm.
the present study investigated whether phonological information is activated automatically and, if so, how it affects handwritten production of chinese characters. the form preparation paradigm was adopted. in the homogeneous blocks, target characters shared the first orthographic component and the pronunciation (experiment 1), shared the first orthographic component only (experiment 2), or shared the pronunciation only (experiment 3). in the heterogeneous blocks, they shared neither orthographic component nor pronunciation. handwritten response times show a significant preparation effect for shared orthographic component only (90 ms) and no preparation effect for shared pronunciation only. there was also a significant preparation effect for shared orthographic component and pronunciation, but the size of the effect was half of that for shared orthographic component only (45 ms). these results indicate that only the orthographic information is relevant for the handwriting of a chinese character. nonetheless, the phonological information can become activated automatically and interferes with production. it is suggested that the phonological interference takes place at the level of lexical selection, which is made more difficult by the automatic activation of homophonous non-targets.
most everyday actions are guided by multisensory input, which bestows considerable behavioral advantages. for instance, when tapping in time to an external event (such as a metronome) one receives both tactile feedback, via contact of the effector with the contact surface, and auditory feedback, from the event itself. previous findings demonstrate that if tactile feedback is removed when tapping in time to an external metronome, variance of timing error increases (studenka, zelaznik, & balasubramaniam, 2012). the present study investigates the role of acoustic feedback on rhythmic sequence production. participants move their dominant hand in the sagittal plane while their motion is recorded in 3d. they receive either auditory feedback, generated when their hand crosses a virtual surface, or receive no feedback. we discuss the effects of the absence of audio feedback on the variance of timing errors, and in the context of rhythmic coordination.
most research on decision-making attends more to cognitive rules than to the situations in which these rules are employed. one characteristic of these situations is the correlation among the features or cues they reveal. we simulated thousands of decision situations that varied in 1) the number of alternatives, 2) the number of features, and 3) the correlations among features. six, simple decision rules were then used to choose an alternative and their choices were compared to those generated by a mathematically optimal rule. results show that all rules, including some that do very poorly when features are uncorrelated, greatly increase their chances of making optimal decisions as feature correlations rise. we discuss some implications of these results for the use of simple decision rules in the real world. 
one of the obstacles to fully ensure the semantic contents of words is how to grab the meanings of a word from various probabilities it associates with other words. according to shannon’s (1948) information theory, entropy can provide indications of amount of information and extent of uncertainty of a given variable by calculating the probability distributions of event occurrence. therefore, entropy based on word-word co-occurrences of a document would disclose the semantic clues for word meanings. in the present study, the computed entropy values of eighty thousand chinese words excepted from academia sinica electronic dictionary are calculated according to the word-pair occurrences. the findings show that the level of entropy correlated positively with the variety of semantics. furthermore, the conditional entropy value for a given word can be used to differentiate the extent of how that word constrains the meaning of the subsequent words in the same text. it is also found that entropy values can reveal the differences of the amount of information carried for words having parallel translation definitions in chinese and english.
related words/concepts prime one another, but the notion of semantic relatedness is notoriously difficult to pin down and may be due to linguistic association (reflecting the likelihood of two words appearing in shared/similar contexts) and/or true semantic overlap (reflecting how similar two words are in conceptual representation).  in the present work, we propose a novel measure of semantic relatedness, perceptual distance, which represents the overlap in modality-specific perceptual experience of the words' referent concepts.  we contrasted lsa scores as a measure of linguistic association, with perceptual distance as a measure of semantic overlap, in predicting semantic priming effects in both lexical decision and naming tasks.  results showed that perceptual distance best predicted semantic priming effects at 1200ms isi, and lsa at 200ms isi, supporting previous findings that simulation effects emerge later than linguistic effects in conceptual processing.  perceptual distance therefore represents an effective measure of semantic relatedness that is independent of lexical associations, and demonstrates true semantic priming that is separable from associative priming.
as a step toward a science of visual information design, this paper offers a perceptual cognitive model that describes and distinguishes two fundamental properties of graphics: pictorial and symbolic properties. these emerge through two interrelated aspects of the perception-reaction loop: pickup and simulation. i will describe how pictorial properties engage relatively more ‘pickup,’ while symbolic properties engage relatively more ‘simulation.’ i will demonstrate that the relevant aspect of pickup is the structure of the light that is perceptually processed from a graphic. i will also demonstrate that the relevant aspect of simulation is how the item being picked up is processed to enable the viewer to appropriately anticipate, predict, or 'simulate' an author’s intention. 
two studies are reported that explore the usefulness of diagrams for solving normal distribution probability problems. study 1 analyzed performance on normal probability problems from a midterm exam in a graduate level introductory statistics course. for each problem, we coded whether or not students used a diagram in their work, and whether the diagram was correct, and complete. we also coded correctness of the answer and "procedural correctness" - whether the answer used a correct solution strategy (even if computational errors resulted in the wrong answer). use of a diagram was associated with procedural correctness of the solution. study 2 gave normal probability problems to an online sample of participants screened to have had at least one statistics course. participants provided with a diagram "hint" did better than participants given no hint. the results add to the body of research showing facilitative effects of diagrams in problem solving.
we examined the cognitive dynamics on an inductive reasoning task in which children and adults made predictions about which of two cars would go faster. participants attempted to induce an underlying rule that was either plausible or implausible, and where one perceptually salient feature (e.g., color) and one less salient feature (e.g., tailfin) were causal factors. on each trial, accuracy, response time, and mouse trajectory data were recorded. mouse trajectories revealed that participants deviated more from an idealized path to the correct response when there was less perceptual difference between two cars and the underlying rule was implausible relative to trials with perceptually salient differences and a plausible rule. adults were more accurate and faster than children, but the motor dynamics were remarkably similar. our data suggest that both global (rule) and local (stimulus features) constraints affected the relative activations of competing representations over single trials and across the experiment.
evidence indicates that dopaminergic neurons in basal ganglia implement a form of temporal difference (td) reinforcement learning. yet, while phasic dopamine levels encode prediction errors of rewarding outcomes, the encoding of punishing outcomes is weaker and less precise. we posit that this asymmetry between reward and punishment reflects functional design. in order to test this hypothesis, we constructed a reinforcement learning algorithm that parameterizes td learning separately for reward and punishment. we find that the optimal model relies on temporal difference learning for rewards alone. moreover, this differentiated model provides a significantly better fit to human behavioral data, similarly showing td learning for rewards more than for punishments. this may be because information about future rewards must shape an earlier sequence of choices, while information about future punishments need only bias the immediately preceding choice.
is student learning enhanced when a math curriculum is revised using research-based principles? the national center for cognition and mathematics instruction, funded by the us department of education, aims to determine whether and how applying research to practice improves student outcomes. a full year of student and teacher materials for grade 7 math were revised according to principles of visual mapping, using worked examples, spacing learning over time, and formative assessment. ninety-one teachers at 64 schools with a total of 6,541 students participated in the study. classes were randomly assigned to either the revised or existing materials at the school level. data sources included demographic data, pretest, attitudes survey, teacher pedagogical content knowledge, teaching logs, unit posttests, and an end of year measure. complete data were available for 4,749 students. we will report results from hlm analyses and discuss practical considerations for applying research to practice.
infants can make probabilistic inferences, inferring the composition of a sample from a population. preschoolers and toddlers will infer a constraint on a sampling process when samples are unrepresentative of populations. in the present experiment, we asked whether 11-month-olds can use probability information to infer a physical constraint on object movement in a looking-time experiment. infants in one condition saw a population with a ratio of many large blue balls to few small pink balls and infants in another condition saw the opposite ratios. when five small balls are randomly sampled from the boxes, this constitutes an unrepresentative sample in the former condition and a representative sample in the latter condition. infants who saw the population with a larger proportion of large balls inferred a constraint on the sampling process: that the opening for the balls must be small. infants in the other condition did not infer a constraint.
two experiments were conducted to find effective reading strategies. generating keywords, summarizing, answering questions, and rereading strategies were tested in experiment 1. answering questions yielded the best performance both in comprehension and the accuracy of judgment of learning(jol). in experiment 2, four reading strategies were tested to find the key aspects of answering question strategy. three strategies related with question answering - generating questions, generating and answering questions, answering peer generated questions - and rereading strategy were tested. generating condition yielded the best performance, whereas generating and answering questions yielded the worst performance. results of the two experiments showed that answering question is the best strategy both in comprehension and metacomprehension, especially when the questions included the most important point of the text. the results suggested that both the depth of processing and the cognitive load of the strategy affected the effectiveness of reading strategies.
this paper is designed to advance a dialog about integrating cognitive science with current techniques in machine-based natural language processing. i address the issue of cognitive plausibility and present a multi-layer, multi-path approach to nlp. this approach is first explained as an abstraction with respect to neuroanatomy. it is then motivated and an explanation of its uniqueness is provided. finally, examples of integrations between cognitive science and nlp with respect to the multi-layer, multi-path model are given. the examples are listed by the cognitive findings to which they refer. this approach demonstrates that nlp and cognitive science are not as incompatible as they may seem.
reproduction errors are biased towards the mean of a stimulus set that varies along a perceptual dimension (gu & meck, 2011; huttenlocher et. al., 2000). we investigated a) whether this central-tendency bias exists across sensory modalities (vision and audition), and b) how the bias unfolds over time. visual and auditory stimuli were presented for durations ranging from 300 to 2800 ms. participants reproduced the stimulus durations following a variable delay period (200-6200 ms). errors for individual items were biased towards the mean of the stimulus set in both vision and audition. moreover, the magnitude of the bias was positively associated with the duration of the delay, becoming more pronounced over time, especially for vision. together, these results provide evidence that the central-tendency bias is present in multiple sensory modalities, and that it unfolds over time, reflecting a dynamically evolving rather than discrete cognitive process.
an important part of understanding the embodied nature of cognition involves uncovering the factors that influence individuals’ decisions to offload cognitive demands onto their body or physical environment. in the present investigation we explore these factors in the context of a task that involves using the physical environment to store information. in particular, we investigate the influence of memory load and individual differences in stm capacity on the tendency to write down items (when free to do so) in a memory task. results demonstrate that the tendency to offload memory demands is driven by both factors and that individuals offload well before their stm capacity would suggest they needed to. in addition, the likelihood of offloading was also related to how much effort a participant was willing to invest in the task. implications of these results for our understanding of cognitive offloading behaviour will be discussed.
perceptual accuracy is unnecessary for the control of action. for purposes of motor control, sensitivity is more important than accuracy: systematic (i.e., stable) bias can be corrected for by calibration; variance cannot. our experiments show that there is a systematic perceptual (i.e., in phenomenology) expansion of angular perceptual variables, such as surface orientation and gaze declination and that this angular expansion can account for a great deal of data concerning long-standing observations regarding the misperception of locomotor space -- including pervasive evidence of egocentric distance underestimation. angular expansion is an efficient coding scheme (like huffman coding) that maintains greater sensitivity to deviations in angular variables most useful for action. fitt's law governing the speed of targeted action is related to perceived size rather than physical size, indicating a perceptual bottleneck for motor control. angular expansion in perception is therefore an excellent strategy for enhancing motor control in locomotor space.
human languages can be seen as socially evolved systems that have been structured to optimize information flow in communication. in particular, it appears that communication proceeds both more efficiently and more smoothly when information is distributed evenly across the linguistic signal. in previous work (ramscar et al. 2013), we used tools from information theory to examine how naming systems evolved to meet this requirement historically, and how, over the past several hundred years, social legislation and rapid population growth have disrupted naming practices in the west, making names ever harder to process and remember. in support of these observations, we present findings from four empirical studies, including tests of name fluency, recognition, and recall, and an artificial learning experiment. these results provide converging evidence for an optimal solution to name design, and offer a more nuanced understanding of how social engineering has impaired the structure of names in memory.
through metaphor, we are able to characterize very different domains with the same words, relying on the language of our shared physical experiences to help ground more abstract, less intuitive concepts. prior research suggests that our shared ways of talking about the concrete and the abstract can produce priming effects that bridge modalities. here, we examine this phenomena in the domains of taste and emotion. in particular, we look to nostalgia, a feeling that is often described as 'bittersweet'. can a bitter taste sharpen the sadness of nostalgic feeling, while a sweet taste heightens the happy memories of yesteryear? in a series of experiments, we investigate the influence of gustation on emotional perception, and reveal the extent to which these links are verbally mediated. further, we show how cataloging a word's usage patterns can yield fine-grained predictions about the nature and strength of cross-domain priming effects.
distributional models of semantics assume that the meaning of a word is a function of the contexts in which it occurs. in line with this, prior research suggests that a word’s semantic representation can be manipulated – pushed toward a target meaning, e.g. – by situating that word in distributional contexts frequented by the target. left open to question is the role that sequence plays in the distributional construction of meaning. in particular, learning occurs in time, and it can produce asymmetric outcomes depending on the order in which information is presented. learning theory predicts that systematically manipulating a word's preceding context should more strongly influence its meaning than should varying what follows. we find support for this hypothesis in two experiments in which we manipulated subjects’ contextual experience with both high and low frequency words, while varying the location of manipulation. we consider the implications for various modeling approaches.
accounts of the stroop effect postulate that participants read the words despite instructions to ignore them and focus on the print colour. recent research, however, suggests that context and task demands can moderate the extent of reading in stroop experiments (e.g., melara & algom, 2003). in the current study we employ an innovative experimental methodology to investigate the depth and frequency of reading in the stroop task. a novel forced-reading task serves as a benchmark, where each and every word is known to be fully processed. stroop effect was calculated from analysis of arm-reaching trajectories, for both the classic and forced-reading tasks. the effect was considerately larger in the forced-reading task, suggesting that in the classic stroop task reading may not occur on every trial, or that words may not be fully processed. 
we investigated the effects of repeating aloud and of an unfamiliar accent onmemory for words. at study, native english speakers heard english words spoken by a native speaker of american english or by a foreign national. they listened only for half of the items and they listened and then repeated aloud (produce) for the other half. at test, producing interacted with accent in recognition memory for those words. for words that they listened to, performance was better for foreign-accented than for american accented words. when participants repeated words aloud performance improved but accent did not matter. experiment 2 included repetition and imitation as well as listen only at study. mouse tracking measures revealed effects of study condition on memory including benefits of imitation over repetition.
mindfulness is a type of active awareness that is purposeful, in the present moment, and non-judgmental (kabat-zinn, 2005). mindfulness interventions have been shown to benefit attentional engagement (e.g., mrazek, smallwood, & schooler, 2012) and, increasingly, have been implemented in educational settings. however, prior work has rarely explored the impact of such interventions on learning and transfer. to investigate whether mindfulness could improve students’ learning and transfer of novel concepts, we conducted a study in which we assessed dispositional mindfulness and gave a brief mindful breathing intervention. we analyzed students’ learning behaviors to test the hypothesis that students who were more mindful during the learning task would be more attentive and non-judgmental about their learning, making them more likely to learn from mistakes and fill in the gaps in their understanding. we also tested whether this learning would aid solving conceptually related transfer problems with different surface features.
the current research examines how the representation of imagined events is constrained by grammatical aspect (imperfective/perfective), lexical aspect (activities/accomplishments), and first versus third person perspective taking. in one experiment, participants imagined events based on written cues that framed events as completed or as ongoing (e.g., i was exercising). in a follow-up experiment, participants read written stimuli describing ongoing activities from first or third-person perspective. during reading, slow cortical potential amplitudes were recorded to index the difficulty associated with imagining events. it was found that imperfective-accomplishments and perfective-activity cues are more difficult to imagine than perfective-accomplishments and imperfective-activity cues. greater difficulty was also associated with taking third versus first-person perspective when imagining ongoing activities. this research provides novel insight into how temporal information associated with verbs and perspective influence event representations.
an english double-embedded relative clause from which the middle verb is omitted can often be processed more easily than its grammatical counterpart; a phenomenon known as the grammaticality illusion. this effect is known to be reversed in german, suggesting that the illusion is language specific rather than being a consequence of universal working-memory constraints. we present results from three self-paced reading experiments which show that dutch native speakers also do not show the grammaticality illusion in dutch, whereas both german and dutch native speakers do show the illusion when reading english sentences. these findings form evidence against working-memory constraints as an explanation for the observed effect in english. we propose an alternative account based on the statistical patterns of the languages involved. this alternative correctly predicts that the dutch participants, being more proficient in english than the german group, display a stronger grammaticality illusion.
to study cognitive control, many computer-generated tasks based on stimulus-stimulus (stroop) or stimulus-response (simon) conflict has been designed where a controlled response is required while inhibiting automatic behaviour. cognitive control can also be measured in the context of more ecological multistep everyday activities for example to avoid the use of distracting objects in the scene. the aim of this research was to test the relations between these two forms of measuring cognitive control (in experimental conflict tasks and in ecological everyday tasks) in both a group of frontal lobe patients and control participants. frontal patients showed larger interference in all experimental conflict tasks and more commission errors in adl in comparison to controls. in addition, s-r (simon) type of conflict but not other s-s confict types, was highly related to commission errors in adl. we concluded that adlcommission errors are mainly due to difficulties to control prepotent actions towards irrelevant objects in the scene. 
in this paper we test the effects of social interactions in embodied problem solving by employing a scrabble-like setting. 28 pairs of participants had to generate as many words as possible from 2 balanced sets of 7 letters, which they could manipulate, either individually or collectively. collaborating makes pairs significantly more productive (m=68.7 sd=16.7) than the best of the two individuals alone (m=63.3, sd=19): f(1,28)=5.66, p=.024, η2=.17. two parameters have a significant impact on the efficacy of collaboration: i)pairs, whose performance is more similar in individual trials, gain higher benefit from collaboration: r(1,27)=-0.51, r2=.26, p=.005. ii)pairs having the collective condition first perform better: f(1,28)=8.55, p=.007, η2=.23. this points to collaboration catalysing optimal solution strategies which can be used in the successive individual trial.
creativity is commonly thought to involve searching and selecting amongst multiple discrete idea candidates. honing theory, which grew out of a quantum theory of concept combination, predicts that it involves actualizing the potentiality of as few as a single ill-defined idea by viewing it from different contexts. this paper reports on a study designed to test between these theories. participants were invited to “create a painting that expresses yourself in any style that appeals to you,” and asked “were all of your ideas for your painting distinct and separate ideas?” naïve judges were provided with descriptions of the two theories of creativity, sample answers, and practice responses to classify. the judges were significantly more likely to classify the artists’ responses as ‘h’, indicative of honing theory rather than ‘s’ indicative of a search/select view of creativity.
prediction errors in time series forecasting tasks are usually attributed to the use of heuristics. these heuristics are described as irrational because they do not take into account all the information available. however, ecological rationality theory suggests that the rational standard should not be absolute, but rather defined in relation to environmental constraints. according to this view of rationality, heuristics can be more accurate than rational strategies such as linear judgment in certain conditions due to their robustness to noise and their minimal sampling requirements. simulation results demonstrate that heuristics can perform better than a rational model of judgment and that this modulation depends in part on environmental constraints. human experiments results suggest that individuals apply different strategies depending on environmental constraints and that the applied strategy is generally appropriate regarding the nature of the situation. taken together, these results support an ecological vision of rationality.
identity, personality and self-consciousness are often seen in cognitive science as almost the same cognitive capacity. in this paper we will justify an alternative and in many ways opposite opinion: that identity, at least in its most basic way, is a non-exclusive protocultural factor that requires cognitive capacities that are linked to social competence and to organism cooperation, and that it is not formed from self consciousness, although in its wider expression uses it. furthermore we will support that identity is widely exogenous in the sense that it involves the group social capacities and not only endogenous in the sense that our brain is by itself the generator of identity. for this we revise some observations from not human private behaviour. 
direct gaze is a salient nonverbal signal for social interest and the intention to communicate. in particular, the duration of another’s direct gaze can modulate our perception of the social meaning of gaze cues. however, both poor eye contact and deficits in social cognitive processing of gaze are specific diagnostic features of autism. therefore, investigating neural mechanisms of gaze may provide key insights into the neural mechanisms related to autistic symptoms. employing functional magnetic resonance imaging (fmri) and a parametric design, we investigated the neural correlates of the influence of gaze direction and gaze duration on person perception in individuals with high-functioning autism (hfa) and a matched control group. for this purpose, dynamically animated faces of virtual characters, displaying averted or direct gaze of different durations (1 sec, 2.5 sec and 4 sec) were evaluated on a four-point likeability scale. behavioral results revealed that hfa participants showed no significant difference in likeability ratings depending on gaze duration, while the control group rated the virtual characters as increasingly likeable with increasing gaze duration. on the neural level, direct gaze and increasing direct gaze duration recruit regions of the social neural network (snn) in control participants, indicating the processing of social salience and a perceived communicative intent. in participants with hfa however, regions of the social neural network were more engaged by averted and decreasing amounts of gaze, while the neural response for processing direct gaze in hfa was not suggestive of any social information processing.
tetris has a long history in artificial intelligence (fahey, 2014) and cognitive science (mayer, in press). we combine both traditions to ask, "what can tetris and these two approaches to tetris, tell us about human expertise?" in our research, we use cross-entropy reinforcement learning (szita and larincz, 2006) to produce two very different types of models; an unsupervised version trained directly on the game and a reversed-engineered version fed the sequence of choices made by human players and asked to determine the best fitting weights for that series of human choices. for a given set of features, we can explore differences in weights that provide the highest score for the machines versus the set that provides the best fit to human data. by varying the set of features we can determine if different features provide better fits to human data while producing poorer performance in machines.note: this work is related to submission 641, if possible could these posters be next to each other during the same session.
in his 1998 review paper, wolfe failed to find evidence of bimodal distributions in over 2,400 pairs of visual search slopes (the relationship between search time and the number of distractors) and concluded that “any effort to divide tasks into serial and parallel search on the basis of search slope alone will be futile.” additionally, search slope alone confounds the serial/parallel distinction with cognitive workload. systems factorial technology (sft; townsend & nozawa, 1995) is specifically formulated for measuring architecture and workload without confusing the two. in this study, participants searched for a target (a red circle) in a field of uniform distractors that differed from the target in shape, color, or both. search times were evaluated using the capacity coefficient and survivor interaction contrast (sic) from sft. results provide strong evidence against serial processing while suggesting either independent parallel or coactive processing of shape and color.
this study endeavors to complement the theory of anthropogenesis worked out by michael tomasello and his colleagues with a theory of cultural development, entitled cccd (communicative and cognitive cultural development) theory. in the paper both the structure of this theory and its theoretical underpinnings and empirical evidence are outlined. four levels of cognitive development in cccd are marked out: cognitive skills on the level a are distinctive features of the great apes, the level b characterizes cognitive skills of primitive cultures, the level c is an attribute of early theoretical cultures, the level d is a characteristic of modern industrial cultures. 
we propose a logical analysis of the concept of typicality, central in human cognition (rosch,1978). we start from an extension of description logic alc (a computationally tractable fragment of first order logic, used to represent concept inclusions and ontologies) with a typicality operator t to consistently represent inheritance with exceptions (e.g. (i)typical birds fly, (ii) penguins are birds but (iii)typical penguins don't fly), and we strengthen it to separately reason about typicality for different aspects (e.g., flying, being feathered). the resulting logic enforces interesting non monotonic inferences, assumes individuals are as typical as possible, deals with irrelevance. differently from previous approaches, it deals with separate inheritance of typical properties among subclasses (e.g., penguins do not inherit the property of flying but can nonetheless inherit other properties e.g., being feathered). the strength of this approach, with respect to more procedural alternatives, is its strong, simple semantic characterization of typicality and entailment.
participants learning about unbelievable causes tend to place less weight on cell frequency data than those given believable causes (goedert, ellefson & rehder, 2013). however, in that prior work, participants made judgments about outcomes which had a large number of possible causes. we hypothesized that belief-based alteration in data-weighting depends on the consideration of alternative causes. here, we presented subjects with either implausible or plausible causes of outcomes that had few causal alternatives (colon cancer and chemical reactions). on each of 16 trials, participants saw complete frequency information (i.e., corresponding to all four cells of the 2x2 contingency table) and made a causal judgment. in contrast to the prior work using outcomes with lots of causal alternatives, we observed similar patterns of data-weighting for the implausible and plausible causes. these results suggest a role for the consideration of causal alternatives in the modification of belief-based data-weighting. 
the extent to which chinese is represented phonologically or orthographically in verbal short-term memory was investigated using a short-term cued recall task (tehan & humphreys, 1998). in all conditions, proactive interference was induced by providing a retrieval cue (e.g. wild animal) that subsumed a to-be-recalled target word (e.g. leopard) and a to-be-forgotten foil word (e.g. tiger), so that the foil was sometimes recalled instead of the target. in twocritical conditions, filler words presented with the target word shared orthographic properties with the foil word, or shared phonological properties with the foil word.  these two conditions increased the level of foil intrusions observed relative to the standard interference condition where the retrieval cue subsumed target and foil semantically, but not orthographically or phonologically. the results suggest that both phonological and orthographic codes are represented in verbal short-term memory for chinese words.
recent findings indicate that both primates and insects can extract direction from high-order forms of local motion. the reichardt model only works for motion signals with two-point spatiotemporal correlations. higher-order motions have three- or four-point correlations and lack global two-point correlations, so the conventional reichardt model fails. here we generate models that extract direction from movie stimuli with two-, three- and four-point correlations. we used a supervised neural network with two layers and sigmoidal nonlinearities. the models were trained and tested using an 80-20 cross-validation scheme on white noise movies with motion energy to the left or right. we evaluate the performance and the learned receptive fields for different motions as a function of the number of hidden units. the networks learned the reichardt detector as well as more complex receptive fields for higher-order motions. we use these results to speculate on how high-order motions are processed in physiology. 
in previous research (kim, porter, & goolkasian, 2014), we examined conceptual priming within and across modalities and found that target categorization was facilitated by the advanced presentation of conceptually related exemplars, but there were differences in effectiveness when pictures and environmental sounds appeared as primes.  the present study follows up this research by manipulating the prime/target pairs in one of four ways to explore the priming effect in a comprehensive manner.  results showed a strong effect of target modality and two distinct patterns of conceptual priming effects with picture and environmental sound targets.  when picture targets are preceded by same item, but not same category primes, target categorization is facilitated.  for sound targets, the priming effect was restricted to comparisons between the same item and neutral primes.  the findings suggest that auditory and visual features about a single item in a conceptual category may be more tightly connected than two different items from the same category.
the role of simpson’s paradox effects oncooperation in one-shot intra- and inter-group prisoner’sdilemma  games is explored.  three  experimental  conditions  areconsidered in a between-subject design – a group that playsgames only within the group (intra-group condition), a groupthat plays games only with members of the other group (inter-group condition), and a group which plays a combination ofintra-group and inter-group games (mixed condition). it wasfound that cooperation in the intra-group games in the mixedcondition is higher than cooperation in the intra-group purecondition which can be an effect of the simpson’s paradoxeffect. the results are discussed in the light of theearlier findings of chater, vlaev, & grinberg (2008) wheresimilar results were obtained in a different context.
human languages carve the world into category systems that are highly informative (e.g. kemp & regier, 2012)—but how do such systems develop? one possibility is that these systems result from the process of cultural transmission. xu, dowman, and griffiths (2013) showed that human simulation of cultural transmission in the lab creates systems of categories that converge toward those in natural language—but they did not test whether those systems also converge toward greater informativeness. here, we test that proposal in an iterated learning experiment. we find that learners do modify category systems over generations in the direction of greater informativeness, and that this increase in informativeness is closely tied to the systems’ similarity to natural languages. these findings support accounts of linguistic universals as the natural result of shared communicative principles across communities of language learners.
new lexical elements such as lol are appearing in natural digital language at high frequencies. the usage of these elements suggests that they are being treated like real words. the first step in examining this type of element is to identify them. we gathered 2,798 messages within a 10-mile radius of a specific gps location for a 10.5 hour period. the novel elements were identified by excluding words found within an english word list. the majority of the novel high-frequency elements were manually identified as abbreviations, slang, emoticons or shortened words. a larger follow-up data collection of over 580,000 messages within the same area, but over several months, produced correlated usage frequencies but, as expected, revealed more subtle frequency differences and challenges associated with the temporal aspect of the data. we conclude by describing how we are currently evaluating the mental processing of these novel elements through behavioral measures.
it is common to simplify models within a given architecture, but those abstractions must not ignore what the architecture demands or recommends. failing to do so can result in unworkable assumptions when applied to other data. the act-r accounts of the fan-effect provide illustrative examples. each of the following assumptions is at odds with the architecture, undermining the utility of their respective models. ignoring the study phase and base-level learning masks act-r’s prediction that high-fan chunks will require more rehearsals and consequentially have higher activations than their faster/more accurate low-fan counterparts. similarly, the decision process for foils assumes they are based on recall-to-reject or biased guess strategies, even though act-r’s retrieval dynamics predict a benefit for high-fan chunks with those strategies. these, and other, assumptions need to be reconsidered as modelers move from a priori associative strengths to ones that are actually learned.
the purpose of this study was to examine whether there was a difference in false memories between negative and positive contexts by using the deese-roediger-mcdermott (drm) paradigm. here, 116 undergraduate students listened to eight lists of 15 words. half of the lists consisted of words with negative valence, and the remaining four lists consisted of words with positive valence. each list was composed of associates of one non-presented word, i.e. a critical lure. participants also responded the scale for negative rumination. the results demonstrated that the proportion of false recognition of critical lures for words with negative valence was higher than that for words with positive valence. furthermore, the proportion of false recognition of critical lures for words with negative valence was associated with the intensity of the participants’ negative rumination. these results suggest that more false memories occur for a negative context than for a positive context. 
recently, there have been two process-based computational cognitive models of theory of mind (tom) (hiatt & trafton, 2010; arslan, taatgen, & verbrugge, 2013). ours (hiatt & trafton, 2010) models the development of tom cognitive mechanisms, such as simulation, and focuses on first-order false belief tasks; the other (arslan et al., 2013) learns to perform tom using the activation of declarative strategy chunks, and answers second-order false belief tasks.arslan et al. suggest several advantages of their model over existing models. here, we address several of those comments and show that our model can perform second-order false belief tasks.
collaborative problem solving (cops) comprises the combined competence  of complex problem solving and communication skills as in cops  situations a shared problem understanding has to be established and  knowledge, skills and efforts of the individual team members have to  be aligned to reach the common goal (c.f. care & griffin, in prep., p.  6; oecd, 2013, p.6). although cops skills are of interest to  researchers and practitioners there is a lack of valid and reliable  diagnostic instruments. we developed an instrument to assess cops that  focuses on structured communication between the participant and  computer-simulated agents using a menubased chat system. in addition  to communicating, participants can also interact with the task  presented on the screen. results of qualitative pretests point out  that our instrument seems to be appropriate to assess cops skills and  is a promising method for research in the field of cops.
this paper analyzes the learning constraints imposed by cognitive limitations on memory and processing in the domain of word segmentation. we analyze the properties of three learning algorithms that rely on the same probability model: an incremental, constrained learner proposed by venkataraman (2001), a batch version of venkataraman’s learner, and a variant of the batch model that imposes memory constraints mimicking incremental processing. we show that while venkataraman’s original incremental learner performs well, the batch version predicts massive undersegmentation. we identify the crucial properties of the probability model responsible for undersegmentation and show how memory constraints impose an opposing pressure favoring segmentation. our results indicate that cognitive limitations exert pressures during learning that shape learning outcomes in ways that can be advantageous. specifically, we show that the inclusion of memory constraints actually favors segmentation and that cognitive limitations may themselves play an important role in the word segmentation task.
there is a still ongoing debate as to whether rule-based and similarity-based category learning are mediated by different extremes of one single system or mediated by two independent systems. most recent attempts to demonstrate independence has focused on dissociations between performance in rule-based (rb) and information-integration (ii) category-learning tasks. these studies can be criticised on two grounds. first, it is questionable whether rb- and ii-tasks constitute process-pure measures. second, not even double dissociations do exclude single-system explanations. we argue that both criticisms are evaded by demonstrating reversed associations between rule-based and similiarity-based categorization of transfer items after successful learning of training items. the preliminary results of two experiments indicate that rule-based and similarity-based categorization of transfer items can be affected in both the same (experiment 1) and the different (experiment 2) direction by manipulating instructions. it is concluded that the results of these experiments are incompatible with a single-system model.
categories can affect our perception of the world, rendering between-category differences more salient than within-category ones — a phenomenon known as categorical perception (cp). previous research has shown that basic color categories across a variety of languages yield cp in speakers of those languages. here, we provide evidence that cp generalizes to color categories beyond the basic level. specifically, we show cp in english speakers for categories corresponding to the non-basic, non-color-specific terms "warm" and "cool," a distinction claimed to represent the earliest stage of color lexicon evolution. notably, we found cp for the warm-cool distinction in the right visual field, but not the left — the same behavioral signature previously observed for basic color categories. our findings suggest that category distinctions beyond the basic-level repertoire of one's native language can be sufficiently salient to affect perceptual discrimination, and hence merit greater categorical status in the mind than previously recognized.
deferred decision making (ddm) refers to when an individual collects evidence about two or more risky alternatives and decides when to stop and make a final choice. real world examples include physicians running tests before diagnosing an illness, or commanders collecting intelligence before taking military action. we conducted a ddm study aimed at investigating how people know when to defer a decision and when to stop sampling and make a choice. participants could purchase up to ten independent observations about two mutually exclusive hypotheses before making a final choice. their goal was to make accurate choices, while minimizing sampling costs. we tested several cognitive models and found that a sequential sampling model (ssm) outperformed others build on heuristic or planning frameworks. according to the ssm, individuals make explicit decisions to wait and sample more, and require less evidence to make a final choice over time due to collapsing decision bounds.
in howe’ s study (2002), humor originates from perceiving the thoughts of the subject in the humor. we assume that humor and theory of mind (tom), the ability to infer one’s metal states, could have some relationships. however, the relationships are not clearly known. the present research is aimed to explore the issue by using tom-jokes, non-tom jokes, and their unfunny version. the unfunny version is used as the baseline to compare the possible differences. children between 11-12 years old participated the study and rated the funniness and comprehension scores of the jokes. participants also rated emotion quotient (baron-cohen, 2004) as their tom score. the results revealed that higher subjects’ tom scores lead to higher levels of the funniness and comprehensibility of tom jokes. the findings offer an evidence for the relationship between tom and the processing of humor from a developmental perspective.
the purpose of this study is to develop a chinese version of empathy quotient (baron-cohen, 2004). the original version of empathy quotient (eq) is a self-report questionnaire including cognitive and affective aspects of empathy. we translated the empathy quotient into chinese and asked 360 subjects to fill up the questionnaire. the results of confirmatory factor analyses showed that the factor loading does not fit exactly with the three-factor structure proposed by lawrence et al. (2004). but the exploratory factor analysis revealed an alternative three-factor structure. compared with other language versions of the empathy quotient, factor 1, named cognitive empathy, is similar to the other versions. this result indicates that the cognitive empathy is culturally universal. in addition, the analysis showed less number of items for factor 3 compared to other versions. the findings suggest to reconsider the cultural differences probed by the empathy quotient questionnaire.
this study investigated whether mandarin-speaking children can demonstrate adult-like syntactic competence. mandarin-speaking 2-, 3-, 4-, 5-year-olds’ and adults’ comprehension of agent-patient relations across four mandarin transitive constructions with the novel verbs: svo construction, ba-construction, subjectless ba-construciton, and topicalization construction were examined using a forced choice pointing paradigm when identical actions were used with only participants reversed in the foil and target videos. mandarin-speaking children and adults demonstrated a similar pattern on comprehending the agent-patient relations across these four types of transitive constructions, though younger children employed a partial but abstract representation for comprehension. mandarin-speakers tend to use a good enough syntactic representation of [1st np-agent, 2nd np-patient] and the salience of the objective marker ba to comprehend the transitive construction
the responses of neurons in the primary visual cortex (v1) are modulated by stimuli outside their classical receptive fields. this same phenomenon, called center-surround modulation, has also been found in psychophysical studies in cases where a visual target’s detectability is influenced by its surroundings. however, whether the surround modulation occurs only after binocular integration (at or after v1) is still considered to be controversial. in order to investigate this, using a pattern masking paradigm, the detection threshold of the target (horizontal gabor, 2 cpd) is systematically measured under different mask and surround contrasts in order to derive the visual system’s contrast-response functions. the modulation effects are compared under different eye origin combinations, and a two-stage binocular contrast gain control model is adopted so that “lesions” in the pathways of the model can be generated to compare the behavioral results. the model not only successfully described the results but also showed that the surrounding suppression occurred before binocular summation and interocular suppression were involved.
in crosslinguistic investigations, expressions of time are closely connected to space (alverson, 1994; boroditsky, 2000, 2011; lakoff and johnson, 1980; radden, 2003; haspelmath (1997). the manifestations of time is space metaphor should, however, be scrutinized from a relativist viewpoint. different cultures’ concepts of time may differ as a result of life experience, shared community beliefs, and available spatial representations. in cross-cultural communication, such differences may lead to communication breakdowns or misunderstandings, and should be tackled with extra prudence. in this study, we use the circle test (cottle 1976) to assess the concept of time in spatial representations. 61 taiwanese college students were asked to draw three circles on a computer screen to respectively represent present, past, and future. the size, distance, and overlapping areas were analyzed, and the result shows that taiwanese college students have a relatively larger zone for future, but only slightly bigger than now. the past is the smallest. zone relatedness is found between now and future (33 out of 40/61), and now and past (33/61), but not for past and future (16/61). we also gave the same group of participants a duration inventory questionnaire (trompenaars and hampden-turner 1997). taiwanese college students are found to have long-termism. the average time zone of past is 6.18, and 6.13 for future. trompenaars and hampden-turner (1997) reported hong kong, as an extreme case of long-termism, had an average of 6.17 for past and 5.8 for future. in our study, we found taiwanese college students had a prolonged concept of future, even longer than hong kong. studies of time zone are an example of how human beings use spatial ideas to manage time, and how cultures differ in terms of perceived length or size of temporal domains. the data from taiwan is expected to increase our understanding of time zone. 
the debate surrounding how emotion and cognition are organized in the brain has recently been drawn toward damasio’s somatic marker hypothesis. the theory endorses a highly interactive process that emotion has with cognition, but has been criticized for: 1) being too broad to capture the specific processes that emotion offers cognition, and 2) implicitly endorsing that emotion operates from a separate neural architecture that is functionally dissociable from cognition. the iowa gambling task has been used to support the theory, but the findings are misconstrued as they can promote a false dichotomy between emotion and cognition. issues will be raised regarding the theory as ill formulated in accounting for the specific phases of decision making, which makes assessing the theory with the iowa gambling task problematic. further theoretical work is proposed that may align the task with damasio’s view of emotion as integrated with cognition.
this study aims to investigate how phonological complexity in chinese impacts word learning skills in deaf children with cochlear implants (ci, 20-40 months old), and their chronological age-matched, normal-hearing peers. it has been suggested that the phonological loop plays a crucial role in word learning. however, while cis seem to have a more limited phonological working memory capacity, generally leading to poor performance on language learning, it remains unclear how different phonological complexity affects word learning ability, and how it interacts with auditory function.to this end, three phonological structures are used as testing items: one-syllable (e.g., /du/), vs. two-distinct-syllable (e.g., /dudi/) vs. two-identical-syllable (e.g., /dudu/). each of them represents a different degree of phonological complexity. moreover, in order to gain more information on children’s real-time behavior, we utilize the eye-tracking technique in combination with intermodal preferential looking paradigm to examine their ability in learning novel words–objects pairings.
taking a canonical perspective of an object provides rich information about its 3d structure. furthermore, this detail has been suggested to enhance cognitive processing of the object. following this logic, the pictogram, a descriptive symbol used to illustrate information, should be designed in 3d form. however, pictograms must also be designed simply, without shading or fine lines, in order to serve as a clear and representative example. to determine whether pictograms should designed in 2d or 3d form, participants rated the semantic clarity and canonical view quality of 2d pictograms and 3d pictograms. results indicate that semantic clarity significantly correlated with view canonicality of objects in pictograms. also, both semantic clarity and canonical view quality of 2d pictograms are better than 3d pictograms. these results suggest that 3d pictograms may difficult to understand and they should be redesigned. 
film trailers have specific features defining a distinct visual media genre. trailer structural features and viewers’ parsing strategies were analyzed in 21 trailers – a set of comedy, drama, and action film per decade from 1940 - 2010. trailers’ structural features show a shot duration pattern that replicates the gradual decrease in hollywood film over the same period (cutting et al., 2011; salt, 1983). trailers from 1960 to 2010 consistently decrease in shot duration. dissolves and fades, also decreasing, mimic the hollywood film evolution. the trailer parsers used an interface system eliciting an exposition-complication-resolution segmentation (thompson & bordwell, 1999). the segmentation follows the 1/4 – 1/2 – 1/4 three-act pattern, with drama and action having roughly half of the total time as complication. the viewer agreement increases with trailer shot duration. trailer structure mimics the hollywood film evolution. trailer viewers identify narrative content segments despite the trailer’s scrambled nature. 
prior studies have found equivalent or even better performance on raven’s progressive matrices tasks for those with autism spectrum disorders (asd) in comparison to normal controls (e.g., chen, planche, & lemonnier, 2010; mottron, 2009). we investigated the extent to which subscales of the autism-spectrum quotient would predict better performance on a verbal analogy task in a non-clinical sample of young adults. for each analogy stem, (oak : tree :: spoon : ______ ), participants had to choose between the correct answer (silverware) and one distracter, which was either high (fork) or low (drawer) in salience. controlling for sex and individual differences in working memory, better attention to detail predicted higher accuracies for the analogies with low but not high salient distracters. thus, attention to detail facilitates recognizing analogical relations but only when there is not also a need to inhibit the superficial similarity of a high salient distracter. 
it has long been argued that people use own mental states to infer those of others but direct evidence is scant because of methodological problems. we hypothesized this mindreading strategy which is called projection can be modeled as anchoring-and-adjustment processes and sought for the evidence using the reaction time paradigm. in the three experiments, participants judged the preferences of both themselves and the other person. if the projection is used to infer the other’s preferences, it is predicted that the reaction time becomes longer when judgments of the other’s and own preference are inconsistent than when they are consistent. as is predicted, this pattern was observed only when a target of judgment was the other person who is similar to participants but not when the target was the self or the dissimilar other. all the results support our hypothesis that the projection is used when judging others similar to oneself.
past research has suggested that the use of a foreign language worsen decision making because of the heavier cognitive load imposed by a foreign language than by a native language (takano & noda, 1993). we discovered, however, that the foreign language usage can be beneficial to decision making under information overload (when it is based upon a large amount of information). seventy-eight japanese university students participated in the experiment. first, they were presented with a complex decision problem either in a native language (japanese) or in a foreign language (english). foreign language fostered better decision making. second, they underwent recognition task that measured their memory. foreign language evoked greater gist memory reliance, and this reliance predicted the decision making performance. finally, we measured the cognitive load imposed by the language usage. foreign language imposed the heavier cognitive load, and interestingly, the magnitude of this load predicted the decision making performance.
we conducted two experiments targeting the development of understanding privileged access with subjects between 6 and 9 years of age. in the first experiment we found a developmental trend and a question-type-specific effect in attributing privileged access to self and others. reversing the order of first-person and third-person-related questions in the second experiment eliminated all the effects found in the first one. this result appears consistent with the idea that children’s understanding of privileged access proceeds from their first-person perspective toward a generalization to other people. our data suggest that at the age of six, children are quite close to being able to formulate a content-independent inference ruel of privileged access (e.g., ’people know their states of mind better than anyone else’). even though most of them cannot spontaneously apply this rule to other people, they readily recognize and start using it when primed with questions about first-person privileged access. 
the first step of successful analogical transfer is relational retrieval—retrieval that is based on common relational structure, such as an underlying principle or pattern. unfortunately, purely relational retrieval often fails. previous work has shown that schema abstraction via comparing two examples can improve relational retrieval. we asked whether labels that name relational structure might also promote schema abstraction and improve retrieval. using a cued-recall paradigm, we varied the presence of relational labels at encoding and at test. we also varied whether labels were presented before or after the examples. the likelihood of relational retrieval improved (relative to baseline) when labels were given at encoding and test, and also when labels were given only at encoding. there was also a trend suggesting that labels were particularly helpful when presented before named examples. these findings suggest that one simple way to improve relational retrieval is through the use of relational labels. 
we investigated the extent to which individual differences in working memory (wm) and interference control (ic) differentially predicted performance on a verbal analogy task with participants selecting the d-term for each analogy stem (a:b::c:__). we varied the semantic distance of each analogy by having an a:b pair that was either far (leather : saddle) or near (platinum : necklace) the correct c:d pair (gold : earring). we also manipulated distracter salience with greater semantic closeness to the c-term for the high salient (sivler) than the low salient (aluminum) distracters. wm predicted higher accuracies across each of the four analogy conditions, and better ic predicted faster rts. controlling for ic, wm predicted faster rts for the analogies with high but not low salient distracters. results have important implications for the separate and joint influences of wm and ic on the underlying analogical component processes of relational integration, mapping, and response selection. 
previous data indicate that individuals who continuously track a stimulus that suddenly vanishes indicate a vanishing point further ahead from where the stimulus actually vanished in the direction of momentum (hubbard, 1995b).  implied forces (e.g., friction; hubbard, 1995b) and typical motion (reed & vinson, 1996) have been shown to affect the perceptual planning associated with tracking a stimulus.  participants controlled an arbitrary stimulus (i.e., a bullet-train vs. a house) in two implied friction contexts (i.e., no surface and surface below), indicated the vanishing point of the stimulus, and made estimates of trials times after every trial.  there was a main effect of friction on spatial displacement but not on time.  concepts, however, influence the perception of space and time differently.  participants controlling a bullet-train indicated less time per trial than participants controlling a house.  this finding is further verified by no differences between concepts in actual trial times.
if depicted objects visually remain where they are, but are linguistically described as moving to new locations (‘onto the table’), subsequent reference to them directs attention to their new locations. but, do these attentional shifts depend on updated spatial screen coordinates, or new object associations? we investigated situations wherein depicted containers moved between spatial locations after non-depicted referents were described as moving between these containers. listeners heard ‘the boy will pour the sweetcorn from the bowl into the jar... and… taste the sweetcorn’, while viewing arrays with a bowl, jar, and distractors. in static conditions, containers remained in one location; in scrambled conditions, they moved to new locations before ‘and’. during the discourse-final ‘sweetcorn’, we observed virtually no fixations to pre-scramble coordinates, but more fixations to the depicted jar than bowl, although this was delayed in scrambled vs. static conditions. we argue that discourse-based object associations drive these attentional shifts. 
the cognitive science research group at ets conducts research and development at the forefront of educational assessment, using cognitive theory in the design of assessments, building cognitive models to guide interpretation of test-takers’ performance, and researching cognitive issues in the context of assessment. moving beyond traditional (e.g., multiple-choice) tests, the group investigates reliable and valid assessment (both summative and formative) using innovative, highly interactive digital environments such as online games, virtual labs or other simulations, and human-agent conversation-based interactions. researchers also investigate how to draw appropriate inferences about test-takers' knowledge and skills from complex data sources such as eye-movements, interaction logs, and other sequential information. i will provide an overview of the group’s research, including the use of cognitive models to interpret test-takers’ actions within interactive assessment tasks and empirical studies on how people coordinate between internal and external representations during assessments in domains such as writing and scientific inquiry.
the present research examines evidence for the sentimentalist claim that emotions are the foundation of moral judgment. it considers the psychopath, known for his deficient emotional capacities, as a case study to test intuitions about the emotion's role in moral judgment. graham and colleagues (2009) examined moral judgment differences between psychopaths and non-psychopaths. psychopaths showed lack of concern for moral fairness and harm. however, they showed as much concern as non-psychopaths for moral foundations of in-group loyalty, purity, and authority. i propose that a sentimentalist theory best explains these findings. it is a result of psychopaths' deficient guilt and sympathy that they are unable to develop appreciation for harm and fairness. the other foundations are tied to emotions that remain intact in psychopaths; for example, psychopaths have appropriate disgust reactions and purity is tied to disgust. these intact emotions result in their ability to express according moral judgment.
to mold the innovators of the future, engineering schools must educate engineers who can generate creative solutions to design problems. we examined the innovation capabilities of freshman and senior undergraduate engineering students through a concept generation exercise using the 6-3-5 method. their concepts were scored for originality, and originality was correlated with individual differences such as academic performance (gpa) and engineering design self-efficacy. in contrast to previous results, seniors and freshmen did not differ in originality. freshman students with low gpa and low self-efficacy produced the lowest originality scores. the creativity of senior students was also assessed longitudinally by comparing their originality on two design problems given across one academic year. an order effect was found: receiving design problem a followed by design problem b led to an increase in originality, while the opposite order showed no change. the results are discussed in relation to practical applications for engineering curricula.
since robotics requires problem-solving and collaboration (bers, 2008), using robotics in education has a high potential of helping students learn 21st century skills (lowther, inan, ross, & strahl, 2012). student engagement is also critical in k-12 education; even students who tend not to be attracted to academic tasks tend to be engaged when robotics activities are used in class (baker, 2011). robotics provides a great tool for teachers to facilitate active learning (perritt, 2010). however, such benefits cannot be achieved without effective teacher preparation (greenberg, mckee, & walsh, 2013). in this presentation, we introduce research on and development of a portal for open education resources (oers) for the use of robotics in teaching and learning. such oers are designed to help teachers learn how to integrate robotics into teaching. example oers include (a) videos showcasing how to teach with certain robots, and (b) toolboxes consisting of lesson and programming samples.
mathematical proficiency is central to success in everyday life, yet its cognitive foundations remain unclear. in previous study, two cognitive abilities have emerged as likely prerequisites – proficiency with symbolic and non-symbolic numbers. in this study, we examined arithmetic proficiency as a function of individual differences in six tasks: symbolic and non-symbolic addition, numerical estimation, and number comparison. as in previous studies, true was robust ratio effect evident in our tasks, while the weber fraction implied from two tasks did not correlate with arithmetic proficiency, nor between tasks, nor even between blocks of the one task. in contrast, accuracy of numerical estimation was correlated with arithmetic proficiency, with other accuracy of estimation, and was reliable within subjects. these findings indicate that numeracy is a better predictor for mathematical proficiency than number acuity.
in a bayesian speech production framework, the selection of forms to produce during speech planning is formalized as noisy-channel communication between different levels of mental processing. each level of processing maintains a probabilistic distribution over possible forms to produce, and iteratively updates this distribution as evidence is received from other levels. the amount of evidence required to select a form for production corresponds to empirically observed latencies, and depends in part on prior biases encoded at a level of processing. as a novel contribution to the psycholinguistic modeling of speech production, we show that a speaker's grammatical knowledge can be easily incorporated into this prior bias if grammar takes the form a constraint-based maximum entropy model. simulation results are provided indicating that a phonological level of processing with prior biases based on a phonotactic grammar of english is faster to produce phonotactically probable forms, in accordance with the empirical literature.
this paper describes how people's future needs are derived by applying cognitive chrono-ethnography (cce), a study methodology for understanding people's in situ behavior selections in daily life. cce starts by defining critical parameters for understanding people's behavior by considering the nature of behavior selection processes in the field in question, and then designing ethnographical field observations. the participant's behavior is recorded, followed by a series of structured retrospective interviews. analysis of the interview results aids in developing models of present behavior selections and their chronological changes in the past. this paper claims that these models should serve as defining future needs of persons who would follow the same developing paths with a certain amount of time delay. this paper illustrates a cce study of spectators of  baseball games at a ballpark who have become frequent visitors in 5 years to show the utility of cce for defining future needs.
the present study investigated the roles of songs in memory. in experiment 1, we examined whether or not listening to a series of the nonsense syllables as a familiar song could be effective in remembering them. the results showed that the participants who were presented with the stimuli both visually and auditorily as a song recalled more syllables than those who were presented only visually. in experiment 2, we examined the effects of singing on memory. the results showed that the participants who sang the stimuli did not performed better than those in the control condition, but those who read aloud the stimuli did. combining the data in the two experiments, we examined the effects of the articulatory movement and of the melody on memory. based on the results, we concluded that listening to the stimuli as a song can enhance memory.
we have developed a tourist map system based on the way people create associations between colors and affective words related to tourist attractions. this study examines such associations. in the first experiment, a participant was required to choose one color from among the seven rainbow colors and one gray-scale level from among seven gray-scale levels to associate with an affective word related to a tourist attraction. in the second experiment, a participant was asked to name a tourist attraction evoked by an affective word, and then choose a color and gray-scale level to associate with the attraction, as in the first experiment. the results indicated that an affective word could be tagged to a specific color and gray-scale level in relation to a tourist attraction, and that the color images of some affective words could be related to color images of the attractions evoked by those words.
previous computational models of jazz improvisation typically employ algorithms designed to “think” like an improvising jazz musician, each offering distinct advantages and disadvantages. creating a model that successfully produces jazz improvisation would (1) offer insights into a unique cognitive expertise, (2) elucidate more general creative processes and, (3) create algorithms that require “creativity” within well-defined constraints. first, the present study proposes a multidimensional scale to measure successful production of jazz improvisation and evaluates the strengths and weakness of twelve existing models. second, the present study proposes new solutions to weakness identified with each model and notes which models have complementary strengths and weaknesses. third, the present study proposes existing learning algorithms that could be implemented for the production of improvisation. finally, the present study suggests that future approaches to creating an improvising algorithm should take into account the methods employed in existing pedagogical treatises of jazz improvisation.
although music exists in every observed culture, ethnomusicologists suggest that music is not the “universal language,” because of the tremendous variation between music of different cultures.  however, evidences from mathematics, psychoacoustics, neurobiology, cognitive science, and anthropology suggest an innate inclination of human beings toward western harmony.  the present study reviews literature from many disciplines to synthesize a theory of innate inclination for predilection of western harmony.  the mathematical structure of western harmony corresponds directly the physical phenomenon of the harmonic series. the subjective discernment of the consonance and dissonance of western music corresponds to the simplicity of the mathematical ratios of intervals.  deliberate patterns of consonance and dissonance produce expectancy generation and, in turn, emotional response.  therefore, if discernment of consonance and dissonance in western music is innately present in humans, then the emotional response to western music and, subsequently, its value is inherent to all humans regardless of culture.
in joint visual attention, the robot should not only follow a human's gaze but also identify the gaze target of the human. we believe that mutual adjustment based on the individuality of the robot  is a key to identify the gaze target of the human even if the human decides the target unilaterally. in the identification, mismatches of the gaze target are uncovered. in humans, the mismatches can be accepted as individuality , it is not the case for robots in which obedience to humans is expected. we examined the case of mismatches in gaze target, which could entail a change in the subjective evaluation of the robot. we found that when the mismatch became apparent, although the concordance rate of the gaze target was high, humans' evaluation of understanding of the gaze target by the robot tended to be worse. the impressions of "friendly," "kind," "cute," and "funny" were reduced, while those of "humanity" and "complexity" tended to increase.
previous work on the role of explanations in blame mitigation used an outdated distinction between “person” and “situation” causes and examined which causes better excuse a negative behavior.  this approach fails with intentional behaviors, which are explained by reasons, not causes.  a recent model of blame (malle, guglielmo, & monroe 2012) suggests that reason explanations function as justifications for negative intentional behaviors—reducing blame by citing socially acceptable beliefs or desires.  but which reason types—beliefs or desires—are most effective in reducing blame?  participants recounted an offense they had committed, provided a blame rating, explained the behavior, and provided a second blame rating.  offenders’ explanations contained far more belief reasons than desire reasons. however, at high levels of initial blame, even belief reasons ceased to be effective.       
adults process others’ actions with apparent ease, despite the complexity involved. expertise seems key, yet little is known about how expertise alters action processing.  perhaps expertise reshapes how attention is allocated as actions unfold.  we investigated this possibility using hard, recchia, & tversky’s (2011) “dwell-time paradigm:” viewers advance through slideshows extracted from a digitized video of an activity sequence, typically displaying a “boundary advantage” (longer dwelling at segment boundaries than mid-segment action) that predicts memory. participants in our study advanced through slideshows varying in familiarity of action depicted (high, moderate, low) but equated on other dimensions. systematic dwell-time differences emerged in relation to familiarity: a stronger boundary advantage arose when action was moderately familiar relative to either highly familiar or unfamiliar, pointing to specific expertise-driven changes in how attention is allocated as action unfolds. a theoretical account of these changes offers new insight into fundamental processes subserving fluent action processing.
we present an experimental tool that tests the effect of emotionality (psychological valence, arousal and dominance) of a word meaning or a picture content on the approach-avoidance motivational systems. a participant is presented with a slider with a schematic human figure in the middle and a word/picture at the top or bottom of the slider. the instruction is to use the computer mouse to move the figure as close to or as far from the stimulus as the person wishes: the distance of the figure from the stimulus, the duration and the number of mouse clicks serve as behavioral indices of the bodily state. by manipulating the figure (child or adult of the same/opposite sex, animal, shape), and emotionality of the word/picture, we were able to replicate both the effects of valence and arousal on approach-avoidance, as well as uncover gender and individual differences in perception of emotion. 
it is well established that spontaneous transfer of relevant abstract knowledge (i.e., a principle) occurs relatively rarely. there are techniques such as active comparison of co-presented analogous cases that improve performance markedly, but these treatments typically result in a majority negative outcome under optimal conditions and fall off drastically otherwise. our recent research testing undergraduate participants in a laboratory setting has shown significant success in promoting spontaneous transfer using a category construction technique based on sorting a set of six unlabeled cases into two groups (three of the cases instantiate the target principle). the present work investigates the category construction technique for improving student learning and transfer of principles of evolution in 7th grade science classrooms. we report results showing the general promise of the approach and identify implementation options that improve outcomes for delivering effective category construction training in an authentic instructional setting.
while comparison is clearly a powerful tool for promoting learning and transfer of relational knowledge, it has been less well explored in the domain of relational category learning. it is actually not straightforward to elicit the expected advantage of giving learners two members of a category to classify on each trial as opposed to one. nor has it been clear, as predicted by structural alignment theory, that same-category pair types are better for relational category learning than cross-category pairs. the present investigation follows up prior results demonstrating a comparison advantage (versus twice as many single-item trials) when learners made separate classification judgments for training items presented in an equal mix of same- or cross-category pairs (kurtz, bourkina, & gentner, 2013). it remains unclear what exactly underscored the comparison advantage. we report two experiments that help pinpoint the roles of task engagement and pair type in driving comparison-based category learning.
although in computational models of judgment and decision making evidence is generally assigned a single value denoting its quality, it can often be dissociated into its extremeness or strength (sample proportion) and its reliability or weight (sample size). we show that by independently manipulating each of these dimensions, we can examine how each one contributes to decisions and judgments. using 2 simple perceptual tasks, we show that while people tend to give equal credence to both strength and weight when making decisions – reflected by choice response times – they overemphasize the strength of incoming evidence relative to its weight when making confidence judgments. in addition, we analyze the decision rules of sequential sampling models and show that stopping conditions for choice depend on the strength and weight of incoming evidence, suggesting that they are dynamically adjusted during a trial rather than set prior to a trial as most models assume.
the predictive processing principle has gained considerable interest as a strong candidate for explaining the unifying principles that underlie the brain’s activity, spanning the entire range of cortical activity from perception and motor control to social cognition and theory of mind. yet, the current mathematical framework that supports predictive processing heavily relies on the laplace assumption, i.e., stochastic dependencies are assumed to be (multivariate) gaussian densities. this assumption becomes problematic when scaling the predictive processing principle to higher cognition, that is, when we “depart further and further from the safe shores of basic perception and motor control?” (clark, 2013, p. 201). in order to be scalable to higher cognition, the mathematical framework underlying predictive processing should be able to represent structured, unordered, discontinuous, and non-monotone information and relations. we introduce a formulation of predictive processing in terms of structured bayesian networks that overcomes the limitations of gaussian densities.
in a recent study a strong congruency-effect has been shown between processing numbers (high/low) and nouns with an implicit up or down directional cue (e.g. roof/root). on this basis, the present study investigates the impact of grammatical number on this effect. subjects processed number cues (2,3,8,9) followed by singular nouns with either up, down or none oriented cue in one condition and the same nouns in plural in the other. the results first replicate the congruency effect between number value (high/low) and implicit directional cue of the words (up/down). second we observed a strong main effect of grammatical number with faster rt in the singular condition in all noun-categories. third, we found no evidence for an influence of grammatical number on the congruency-effect. we conclude that number cues facilitate the processing of nouns with implicit up or down oriented cue, but do not influence the simulation of their references’ number.
logical reasoning is at the heart of math courses. wason’s selection task has been widely investigated to examine students’ reasoning; however, previous studies found that few participants could correctly solve wason’s tasks. this study adopted a modified format of the selection task, context-embedded problems, as well as the standard selection tasks to look into high school and college students’ reasoning process using eye tracking technology. results showed that neither the high school nor the college students correctly solved the standard selection tasks, while about half of these participants correctly solve the context-embedded problems. typically, these participants were only trying to prove the rule true rather than proving the rule false and these two groups did not differ in either accuracy or rt. additionally, while looking at how participants examined the choices for each question, we found that longer inspection times were more related to selected choices than to rejected choices.
people can create impressive new objects: an architect designs new houses, a cook designs new recipes, and an entrepreneur designs new companies. on the other hand, computers are better known for consistency than creativity, and thus the computational basis of creativity remains mysterious. recent work suggests that probabilistic generative models can capture how people generate simple types of new artificial objects [jern & kemp (2013). cognitive psychology]. we show how this idea can work for more complex, natural domains by learning a non-parametric hierarchical bayesian model that re-uses parts of related objects to design new ones. the model is an extension of recent computational work with handwritten characters [lake, salakhutdinov, & tenenbaum (2013). nips], and we test it by providing a small set of characters from a shared alphabet and then generating a new character in that style. a comparison with people reveals the model can generate compelling new characters. 
despite its widespread use, disagreement remains about whether the cognitive reflection test (crt) measures the ability to inhibit an intuitively appealing but incorrect response to a problem, or simply numeracy skills. we administered chinese-language versions of the extended seven-item crt, two widely-used numeracy scales and a set of decision-making tasks (risk preferences, ratio bias and framing) to 186 students at a university in taiwan. higher levels of parental education significantly predicted higher crt scores (p &lt; .001) but not higher numeracy scores; males outperformed females on both, but differences were not significant. in contrast to earlier studies, no pattern of significant relations between crt, numeracy and risk preferences emerged. higher numeracy – but not crt – scores were associated with better choices on the ratio bias task. higher numeracy – but not crt scores – were associated with lower susceptibility to framing, but differences did not reach significance. overall, results suggest two distinct constructs.
heart rate (hr) variability is a physiological marker of an individual’s emotional, behavioral and cognitive reactions (segerstrom & nes 2007). strength of inhibition (si) is a stable trait referring to the ability to control behavior, suppressing the impulse to react (strelau 2008). the aim of this study was to determine the extent to which physiological effort (hrv) and personality trait were related during the execution of a difficult cognitive task.following assessment of si with the strelau temperament inventory, 52 participants performed the stroop task with simultaneous recording of hr with a pulsometer. there was no difference in hr variability between high and low stroop task performers, but there was a significant rise in hr in those with higher si scores — even though levels of performance remained comparable. although findings are limited to stroop performance, they highlight the contribution of personality to physiological states in cognition.spsu grant № 8.38.303.2014
the mechanisms underlying perceptual learning--how our brain changes as we gain competence in a perceptual task--remain a heavily debated topic. since the early 2000's, a number of authors have proposed competing theories on the loci of change for visual perceptual learning, ranging from v1, v4, to areas beyond the visual cortex associated with decision making processes (dosher and lu, 1998; schoups, vogels, et al., 2001).instead of positing one loci of change in the brain, we argue that gradient descent can serve as an explicit learning rule to determine the loci of change. we show that a deep neural network trained with error-correcting backpropagation can reproduce a variety of results from neurobiology experiments, explaining both the detailed changes in neural representations in each layer, and the relative magnitude of changes seen in different levels of the visual hierarchy.
it was hypothesized that acculturative anxiety would be represented in the dream contents of immigrants’ nighttime dreams in the usa. according to “lee acculturation dream scale” (sang bok lee, 2005: psychological reports, 96, 454-456), korean-americans’ dreams represented their acculturation processes. also, a simple t-test on “lee cross-cultural anxiety dream scale” means showed significant difference between korean and korean-american groups (lee, 2010). dreaming cognition needs to be recapitulated in the light of acculturative anxiety. in this report, the authors articulate cross-cultural coding systems of "anxiety dream" and pinpoint two implications for the future research direction. first of all, dream scales to measure acculturation rate and acculturative anxiety need to be utilized when cognitive scientists delineate “anxiety domain-specific” interpretation of dreaming cognition. secondly, dreaming brain (fmri data), dreaming mind (acculturative anxiety), and cultural-affective neuroscience are interconnected in the inter-disciplinary, empirical, and experiential perspectives on the theory of mind (tom).   
the true intention, i.e. positive and negative, of shoppers was identified from conversational dialogue speech between shoppers and salesperson. since the speech characteristics have subtle difference only, it is important to learn discriminant features from speech signals. starting from statistical features of speech pitch, amplitude envelop, and their temporal changes, the discriminant non-negative matrix factorization (dnmf) algorithm successfully extracted the discriminant features. then, a support vector machine (svm) classifier was trained to result in above 80% classification accuracy for the test data. the careful analysis of the discriminant features showed that the temporal changes of the pitch and amplitude envelop are closely related to the hidden shoppers’ intention.
verbo-pictorial humor advertisement induces deeper thinking and invokes the feeling of amusement. present study aimed to investigate the influence of types of verbo-pictorial ads and humor by the analysis of eye movement. participants were 67 undergraduates, experimental design was 2 (advertisement type: humor and literality)  2 (stimulus type: slogan and pictorial information) within-subject design. every participant received 8 stimuli of ads. results revealed that among the ads with pictorial region, humor ads was more fixation count than literal ones; it represented that participants felt funniness after deeper thinking with pictorial information. furthermore, the run counts of humor ads in slogan (textual) and pictorial information were obviously more than those of literal ones; it’s required more processes of comprehension while watching humor ads. implications for how viewers integrate pictorial and textual information and applied research and ad development by eye movement are discussed. techniques of fmri, meg, and eeg are suggested for brain mechanism of ads in different humor skills.
unlike conventional activation-based brain mapping, multivariate (or multi-voxel) pattern analysis (mvpa) has been widely used to accurately predict behavioral variables encoded in a neuronal system. our research based on mvpa attempts to prove whether it is possible to identify the semantic neural representation when performing language switching. five early korean-chinese bilinguals participated in our fmri experiments where trials consisted simultaneously of semantic difference (mammal /tool) and language switching (korean /chinese). the participants were requested to do a property generation task in l1 (l2) for each orthographic stimulus in l2 (l1) presented as caption for the picture stimulus. it turned out that the semantic identification accuracy was significantly high and immune to the effect of the language switching, but the language as a target was not identified as accurately. however, regions of interest in bilingualism were confirmed by important voxels with language identification accuracy considerably higher than semantic identification accuracy. 
wikisilo is a tool for theorizing across interdisciplinary fields such as cognitive science using a specific vocabulary and structure. it is designed to show if a particular cognitive theory is complete and coherent at multiple levels of discourse, and commensurable with and relevant to a wider domain of cognition. wikisilo is also a minimalist theory and methodology about effectively doing science, and is therefore a form of epistemizing. wikisilo theory provides for a disciplined exploration of explanatory space via an axiomatic hierarchy of epistemizing and ontologizing postulates. the wikisilo tool, via a software version control system, supports the long term goal of working toward coherent and unified theories. more generally, wikisilo facilitates self-organization leading to academic silos with well-defined conceptual frameworks that are vertically related as compared to poorly related ad-hoc academic fiefdoms.
different external representations support different conceptual aspects of the fraction concept. to explore the effects of external representations on fraction understanding we designed a training experiment comparing the effects of pies and number lines. the participants in the experimental groups took three training sessions where they had to pair or create external and symbolic representations for fractions. the sessions were designed based on the explanatory frameworks for the development of the fraction concept described by stafylidou and vosniadou, (2004). the results show that the participants who trained using the number line had significantly better learning gains than the control group.  the pie external representation enhanced the interpretation of fractions as part-whole relationship. the number line external representation enhanced both the interpretation of fractions as part-whole relationship and as a measure and it also promoted the understanding of fraction equivalence. 
previous studies found that eye movements of geometry problem-solving process were different between experts and novices. 3d spatial problems are more complicated and advanced. present study aimed to investigate the cue effects in 3d spatial problem solving between successful and unsuccessful problem-solvers. experimental design was 2 (cue: present/absent)  2 (group: successful/unsuccessful problem-solvers). there were four experimental conditions: successful problem-solvers on the problem with non-cue (s-nc), unsuccessful problem-solvers on the problem with non-cue (us-nc), successful problem-solvers on the problem with cue (s-c) and unsuccessful problem-solvers on the problem with cue (us-c). participants were 52 undergraduates. results revealed that us-nc was more fixation counts than in the other conditions. however, there was no significant difference in the four conditions in the gaze duration. the technique of fmri is suggested for studying the brain mechanism in the future. in pedagogical aspect, animations of keys and procedure of problem solving can help unsuccessful problem-solvers to acquire 3d spatial concepts.
the relationship between approximate number system (ans) acuity and math performance has recently received a lot of attention. it is still unclear, however, whether the ans is a prerequisite for math performance or whether training in mathematics could improve ans acuity. the present study investigated the extent to which mathematics training influences ans acuity. participants’ ans acuity was measured before and after six 45-minute sessions of solving arithmetic problems. participants improved substantially in both the speed and accuracy (i.e., in arithmetic fluency) with which they solved the problems. there was, however, no accompanying change in ans acuity, suggesting that mathematics training may not affect ans acuity. further, in line with previous research we found that arithmetic fluency was strongly related to working memory capacity. with improved arithmetic fluency the relationship, however, became weaker, indicating that practice with arithmetic problems may give rise to strategies that can circumvent working memory constraints.
speakers show sensitivity to the sound patterns possible in their language (phonotactics patterns). these patterns can involve specific sound sequences (e.g. bb) or more general classes of sequences (e.g. two identical consonants). in some bottom-up models of phonotactic learning, generalizations can only be formed once some of their specific instantiations have been acquired. to test this assumption, we designed an artificial language with both general and specific phonotactic patterns, and gave participants different amounts of exposure to the language. contrary to the predictions of bottom-up models, the general pattern required less exposure to be learned than did its specific instantiations. we model our results by adapting a bayesian rule-learning model, in which specific and general patterns are learned simultaneously. in addition to explaining our results, we use this framework to analyze several other studies from the literature.
the theme of motor representation was initiated by merleau-ponty (1962).  grush (2004) and pezzulo (2008, 2011) attempt to explain it by highlighting the role of internal models in simulation of motor effectors.  simulation represents facts of external states without accurately directing the motor system to its goal-state.  the present paper explains motor representation in an alternative way, specificially in terms of clark’s (2013) thesis of hierarchical predictive processing models: representation of cognition rests on the recurrent processing of error-correction, and motor representation is a particular case of it.  this is an account of representation that is not based on a standing-for (or, referring-to) relation.  
  this study examined the dai, wa, jino ethnic minority chinese developmental dyslexia children's processing defects of linguistics cognitive level and non-linguistic cognitive level by two experiments. experiment 1 used the pronunciation repeat, orthography true and false judgment and sentence comprehension tasks to investigate the linguistic cognitive processing defects of different ethnic chinese developmental dyslexia children. we found the formation of chinese dyslexia is not affected by ethnic mother tongue. a dual-task for working memory, calculation as task one and speech pronunciation as task two, was employed in experiment 2. when the chinese developmental dyslexia children did the two tasks simultaneously, their performances were significantly lower than the normal children. the results indicate that all ethnic chinese developmental dyslexic children have working memory defects. the central executive system of working memory defects may be the chinese developmental dyslexia underlying causes.
can human-normed personality scales alone give us a full picture of the attribution of personality to virtual agents? in humans, personality traits are often immediately ascribed: first impressions, influenced by posture and gesture, can be strong, lasting and accurate. is there a similar immediate attribution of personality for virtual agents that can be similarly influenced by posture and gesture? our study uses an open-ended question alongside a traditional big five personality inventory to probe the perceived personality of agents programmed to demonstrate extroversion and emotional stability through gesture. though inventory scores show that considered impressions are in line with the agent’s intended personality trait, we also show a mismatch between initial and considered impressions in virtual agent personality perception. we suggest that first impressions derived from open-ended questions provide information complementary to the traditional personality inventory. 
representations and symbols are present in artificial intelligence since its origin, but it is still an open debate in cognitive science community. we present peirce’s philosophy of sign as a theoretical framework to study representations, their varieties and processes in artificial intelligence. his theory has been brought forth as a theoretical start point for discussing such processes in ai, but as we will argue, only partially or imprecisely, limiting the full extent of possible contributions. this is an initial work on bringing forward this framework, yet we provide possible contributions to the debate on representation. we believe that a more extensive application of concepts and models from peirce’s semiotics can in fact aid in a wider understanding of representation processes and in the conception of cognitive architectures.
studies have shown that visual perception is pliable and that perceptual estimations can be affected by factors such as an individual’s current eye height. it has been shown that perception of slope, distance, and height are subject to the influence of physiological and social variables. the studies conducted and outlined here investigated the impact of an individual’s height on estimations of object size with both pictures and written words. results presented here suggest a pattern opposite from those found in eye height studies, where an individual will instead estimate the size of an object as larger, the taller they are.
people often have attitudes and biases of which they may not be consciously aware. the implicit association test (iat) is one of the key tools used to investigate such attitudes, especially when it comes to controversial topics (e.g., racial prejudice). in an iat, participants categorise stimuli (words/pictures) that are paired with either positive or negative attributes. the differences in response times to the positive/negative pairings provide a measure of the participant's overall implicit bias. we collated dozens of iats from the literature, incorporating the data of over 10,000 participants and investigated whether the linguistic co-occurrence patterns of the lexical stimuli used in iats could be used to predict the level of bias exhibited by participants. we used the lexical co-occurrence frequencies extracted from a large-scale corpus to construct a range of models which were then compared to the reported effect sizes of the iats. we found that relatively simple models based on raw frequencies and conditional probabilities provided significant correlations with implicit effect sizes, while models incorporating log likelihood estimates yielded much poorer performance. it is possible that individuals' sensitivity to linguistic distributional information may influence responding in the iat.
existing models of the evolution of social behavior typically involve innate strategies such as tit-for-tat.  yet, both behavioral and neural evidence indicates a substantial role for learned social behavior.  we explore the evolutionary dynamics of two simple social behaviors among learning agents: theft and punishment.  in our simulation, agents employ q-learning, a common reinforcement learning algorithm.  agents reproduce in proportion to the objective rewards they accrue, but the subjective reward function that guides learning and action evolves by natural selection.  we find that agents typically evolve a bias to punish thieves that is sufficiently strong that it cannot be unlearned.  agents also typically evolve a bias to abstain from theft, but this is weak enough to permit rapid learning.  this flexibility allows would-be thieves to exploit non-punishers. finally, we show qualitatively similar results in a behavioral experiment on human participants: flexible theft, but resolute punishment.
this paper deals with the emergence of aggressive deceptivebehaviors in animal cognition. the adopted framework is anabductive/semiotic one. the first section frames animal cognitionas more than “merely” instinctual, making room forthe possibility of some kind of mental representations in nonhumancognition. the second section proposes a case of insectcommunication where it is possible to individuate a kind ofdeception. the third section argues for the understanding ofdeception, a ultimately morally-laden concept, as an emergingphenomenon where the growing semiotic complexity plays afundamental role.
the aim of this paper is to briefly illustrate how the theoreticalframework of coalition enforcement can prove useful to framenot only the the moral cognitive role of fallacies, but the naturalizationof morality as well, also taking advantage of thom’stheory of catastrophes. a basic aspect of the human fallacioususe of language, as far as its military effects are concerned, isthe softness and gentleness granted by the constitutive capacityof fallacies to conceal errors – especially when they involveabductive hypothesis guessing. being constitutively and easilyunaware of our errors is very often intertwined with theself-conviction that we are not at all violent and aggressive inthe argumentation we perform (and in our eventual related actions):i will introduce the concept of moral bubble to addressvarious cognitive effects, which are often disregarded in thecurrent literature.
grossberg and kazerounian (2011) present a novel model of sequence representation for spoken word recognition, cartword. they claim cartword can simulate key patterns of phoneme restoration in human perception (replacing phonemes with noise yields restoration, replacement with silence does not), but trace (mcclelland & elman, 1986) cannot. i show that their trace simulations used flawed stimuli. with proper analogs to noise-replaced stimuli, restoration occurs for noise replacement but not silence replacement in trace. i rebut other criticisms of trace, and argue cartword is implausible because it cannot distinguish sequences with repeated elements (/tot/ "tote") from sequences with the same elements but no repetitions (/to/ "toe"). until this fundamental issue is resolved, and cartword is tested on more phenomena than just phoneme restoration, the model is simply not comparable to trace or other models that have been tested on a wide variety of phenomena from human speech processing.
a crucial problem in cognitive science, especially for speech processing, is sequence encoding. models of spoken word recognition either ignore the problem (e.g., norris et al., 2000), posit solutions incapable of representing repeated elements (e.g., grossberg & kazerounian, 2011), or "spatialize" time in possibly unrealistic ways (trace; mcclelland & elman, 1986). an alternative that has not been deeply explored for spoken word recognition is the simple recurrent network (elman, 1990). i trained srns on the trace lexicon with pseudo-spectral inputs, and used regression to compare fundamental effects (neighborhood, cohort, length, etc.) in srns vs. trace and tisk (hannagan, magnuson, & grainger, 2013), and the fine-grained time course of those effects. in general, srn predictions converge with trace and tisk, and are consistent with human behavior. however, some attested effects (e.g., short-word bias) do not emerge naturally in srns, calling into question their adequacy as models of human spoken word recognition.
we report the results of tasks that measured whether the syllable is a frequency-modulated prelexical and segmental unit available in french dyslexic children. thirty-three french dyslexic children were compared to 66 chronological age-matched and reading-level-matched controls. we designed a visual syllable detection task (exp. 1), a visual masked priming paradigm (exp. 2), and a revisited illusory conjunction paradigm (exp. 3). our results showed that dyslexic children exhibited robust frequency-modulated syllable effects; high-frequency syllables had facilitatory effects (syllable-based processing), while low-frequency syllables had inhibitory effects (letter-by-letter processing) whether the tasks did or did not tap the processes of lexical access. furthermore, in a feasible task (exp. 1), dyslexics' performance was drastically higher than in tasks with cognitive or temporal constraints (exp. 2 and 3), suggesting impaired phonological procedures. we propose that dyslexic children do not systematically have obvious degraded phonological representations but rather compensated phonological representations with degraded access to them.
present research investigated whether and how regularities in exemplars affect reasoning based on category, such as generation of initial hypothesis and categorization. participants in hypothesis generation task were presented with one of three item sets, and asked to guess a rule. uni-dimensional items shared a single feature, and conjunctive items shared two features with all category members. items in family resemblance condition shared a single feature and, besides that, were very similar with each other in terms of the other (not common) features. result showed that regularity structure in items was reflected in generated hypothesis, however, overall similarity were not. another participants were asked to classify target object to one of two competing categories, or to judge whether target were similar to either of them. in this case, half of participants relied their judgment on overall similarity between target and category. the differences between these tasks were discussed.
some individuals automatically and involuntarily “see” mental images of numbers in spatial arrays when they think of numbers (number forms). makioka (2009) proposed a theoretical framework called self-organizing learning account of number forms (sola), which argues that number forms are generated by self-organizing learning between numerical and spatial representation. this framework explains three important properties of number forms: (a) within-individual consistency, (b) between-individual variation, and (c) mixture of regularity and randomness. this study aims to examine whether sola can explain the interaction between numerical and spatial representations in non-synaesthetes. participants viewed pairs of numerals and reported vocally which numeral was larger. the two numerals were presented in various spatial configurations, and mean reaction times (rts) were calculated for each configuration of each individual. we have found significant interactions between numeral pairs and spatial configuration in some participants, which suggests that they have irregular mental number lines.
recently, starns et al. (2008) collected source judgments for old items, which participants had claimed to be new, and found residual source discriminability depending on the old-new response bias. the finding was interpreted as evidence in favor of the multivariate signal-detection model but against the high-threshold model of source memory. according to the latter, “new” responses only follow from the state of old-new uncertainty for which no source discrimination is possible, and the probability of entering this state is independent from the old-new bias. however, when unrecognized items were presented for source discrimination, starns et al.’s participants knew that the items had been studied. to test whether this implicit feedback leads to further retrieval attempts and thus to source memory of presumably unrecognized items, we compared starns et al.’s task to tasks without implicit feedback. our results challenge the original finding and lend support to discrete processing in source memory.
volitional control matters greatly for moral judgment: agents lacking control over their behavior receive less condemnation for the harms they cause. a reasonable interpretation is that this is because a lack of control indicates a lack of harmful intent, but this has never been tested. here, we dissociate control from intent in a novel experimental paradigm. our results show a unique effect of control that cannot be explained in terms of intent. specifically, we find that agents receive greater punishment when they choose to act prosocially but accidentally cause harm, and lesser punishment when they are forced to act prosocially but accidentally cause harm. this surprising effect does not depend upon perceptions of intent, but rather upon perceptions of causal responsibility. moreover, it is unique to judgments of punishment, but absent for judgments of moral character. these results clarify how, when and why control influences moral judgment. 
structure-mapping theory asserts that analogical comparison involves a process of structural alignment based on finding common relational structure (gentner, 1983). during this process, correspondences are established between the aligned components of the analogs—both relations and objects. in the present experiment, we show that this alignment process is strikingly more efficient when the "correspondence lines" between matching components are maximally direct—that is, when they run perpendicular to the principal axes of the two structures. when asked to make same/different judgments across two shape sequences (e.g., circle-square-circle vs. circle-square-square), judgments are faster when horizontal sequences are placed vertically (one on top of another), than horizontally (one next to the other), and vice versa. perpendicular arrangement is still more efficient even when correspondence lines do not cross other objects, as revealed by an advantage over diagonal arrangement. these findings suggest an embodied aspect for structural alignment between visual images.
in this study, we focused on the influence of indoor thermal comfort on the mere exposure effect while manipulating the predicted mean vote (pmv). we used neutral random shapes as the stimuli and controlled exposure frequency (0, 1, 5, 10, and 15 times) and pmv (+2=hot,+1=warm,0,-1=cool -2=cold). after the acclimation phase, participants were exposed to each stimulus, and 5 min later, were asked to rate preference, familiarity, novelty, and thermal comfort using a 7-point scale as well as recognition of old and new items. the result showed that, only in a slightly warmer environment, the mere exposure effect occurred definitely. as the number of stimulus presentations increased, the preference for the stimuli did not increased so much during the cold and normal environment condition and showed unstable tendency during the hottest background condition. these results suggested the importance of the control of thermal environment treated as an external noise.
how does social presence influence the perception of energy expenditure? people often think about social relationships in terms of space. for instance, when drawing routes on maps they draw paths closer to friends than strangers (matthews & matlock, 2011). how does the mere presence of a friend influence reasoning about caloric expenditure? here, participants who imagined working for an outdoor magazine viewed photos of walking bridges that one might encounter while hiking in groups. some participants were told they preferred crossing first. others were told they preferred crossing them last. all participants estimated how many calories they would burn while crossing the bridge. those who imagined their friends on the far side of the bridge estimated fewer calories than those who imagined their friends standing immediately behind them. these results provide new insights into how social presence can influence our perceptions of predicted energy expenditure. 
in the michotte task, a ball x moves towards a resting ball y. in the moment of contact, x stops und y starts moving. although, according to newtonian mechanics, the force launching y is equal to the force stopping x, previous research has shown that subjects tend to view x and not y as the agent, and that x tends to be attributed more force than y. force dynamic theories interpret these findings as evidence for the view that agents are generally attributed more force than patients (i.e., y). our experiment contradicts this view. we manipulated the strength of agency intuitions by varying the type of movements of x and y prior to the collision. although this manipulation shifted agency intuitions about x and y, the force attributions stayed invariant. this result confirms the view that theories of causal process representations and of causal agency assignment need to be separated.
recent studies (e.g., graesser et al., 2011; mcnamara, 2013) have used coh-metrix, an automated text analyzer, to assess differences in language use across different academic disciplines. mcnamara (2013) reported that texts in the natural sciences were characterized by lower narrativity and word concreteness than texts in the language arts, while being higher in syntactic simplicity and referential cohesion and suggested that this pattern reflected a kind of compensation where text difficulty on one dimension (e.g., concreteness) was compensated for simplifying text difficulty on another dimension (e.g., syntax). in the present study we provide a test of this idea by analyzing language use across humanities and natural science lectures. results are consistent with the idea that decreases in word concreteness in lectures are compensated for by increases in narrativity, syntactic simplicity and deep cohesion. discussion focuses on the potential mechanisms underlying this putative compensation behavior and its implications for instruction.
in the classic telephone game, the content of a spoken message evolves as it passes from player to player. beyond its entertainment value, the telephone game may have consider- able scientific utility: here we investigate the nature of the linguistic knowledge people use to comprehend language by tracking the evolution of a set of visually-presented sentences in a web-based version of the telephone game. initial sentences are selected from a range of probabilities according to n-gram language models. both unigram and trigram probabilities of responses increase over the course of iterated transmission for sentences with the lowest initial probabilities, suggesting that edits are conditioned on participants’ implicit probabilistic knowledge of their native language. further investigations of word-level changes reveal not all words and sequences are subject to edits; rather, participants are more likely to change lower probability words and sequences, and replace them with higher probability content.
we investigated the effects of "personalness" in moral decision-making by examining judgments about moral dilemmas involving damage to owned property that varied in terms of their sentimental (i.e. personal) importance or monetary value. participants responded to trolley-style dilemmas where an agent could save five objects from destruction by sacrificing a sixth object, either as a means or as a side-effect. in experiment 1 (n =315), participant's judgments of acceptability depended on the means/side-effect distinction for sentimentally important objects. however, this difference did not occur for objects without sentimental value. in experiment 2 (n = 361), acceptability depended on the means/side-effect distinction for items regardless of their monetary value. these findings suggest that ownership violations are processed similarly to acts causing harm to human victims, and that this effect depends on the sentimental, but not the monetary, value of the objects.  
spatial language has been shown to be an important predictor of spatial development. however, little is known about the underlying mechanisms through which language facilitates spatial development. the current study examines how the selectivity and flexibility by which preschool aged children use spatial language is related to their spatial skills. children were asked to describe the location of a target object when properties of the referent objects changed (manipulating availability of size, color, and location information) and when the target object changed positions relative to the referent objects. children were also administered a battery of spatial tasks and vocabulary assessments (through parental questionnaire and ppvt) to capture experience and skill level in both domains. the results of this on-going investigation are indicating that the selectivity and flexibility by which children use language to describe spatial scenes is associated with children’s performance in spatial tasks beyond their knowledge of spatial words. 
one of the central findings in research on the emergence of communication systems is that interlocutors rapidly converge on a shared set of contracted referring expressions (krauss and weinheimer, 1966; clark, 1996; galantucci, 2005).to investigate in closer detail how referential coordination develops, we report a variant of the “maze task” (pickering and garrod, 2004). participants communicate with each other via an experimental chat tool (healey and mills, 2006), which interferes with the unfolding dialogue by inserting artificial signals of miscommunication that appear, to participants as if they originate from each other.participants who received these signals performed better at the task, and converged more rapidly on more abstract and more systematized referring expressions. we demonstrate how this beneficial effect is due to the amplification of naturally occurring signals of miscommunication, 
induction is an essential aspect of human learning and reasoning, yet there is no consensus regarding the underlying mechanisms. one view holds, early in development, induction is similarity-based, utilizing perceptual features, possibly allowing increased encoding therefore higher memory accuracy. while another view posits that across development induction requires identifying category membership, possibly limiting encoding of perceptual detail thus decreased memory. this experiment assessed attention allocation during category learning, induction, and recognition. adults were presented with categories having one defining dimension and multiple probabilistic dimensions. participants with higher attention to defining features exhibited lower memory accuracy following induction than those with higher attention to probabilistic features. results implicate similarity-based induction (induction based on distributed attention across multiple dimensions) as associated with more accurate encoding of multiple features thus more accurate memory. while induction based on selective attention to defining features results in encoding primarily these features and thus less accurate memory. 
understanding story is interpretive activity, and there are diversities of story comprehension among students. the present study investigated how these diversities appear among students in the lesson. thirty-two sixth-grade elementary school students have done recalling task and interpretation task after listening to a short story in moral-education class. though all the students listened to same story, half of them recalled the endings that differ from original one. analyses showed that which scene to be recalled as ending was related to how much student interpreted character’s feeling in the first scene. this scene included significant event, and was a peak of the story. these results suggest that the ways of interpreting the peak scene differed among students. interpretation of the peak scene became a base for them to attach meanings to the following story, and leaded them to choose different suitable scenes for ending. the peak scene was a diverging point.
in daily life, voice qualities are often harmonized to word meanings. to investigate effects of harmonization, psychological experiments manipulating harmonization between word meanings and voice qualities were conducted using four different voices. half the test items were presented in an (incidental) learning phase, then an auditory word-fragment completion (wfc) and auditory recognition tasks were executed. guessing in the wfc was better in the harmonized condition than neutral, which in turn better than in the non-harmonized condition. they imply the mood-congruency effect led by voice qualities, where access to words in lexicon was facilitated by use voice quality cues.　looking at memory tests, the harmonized condition showed less priming in wfc but higher recognition, while the non-harmonization condition showed larger priming and less explicit memory, maybe because of access difficulties and/or harder estimation of speaker’s intention. the connotative meanings of voice qualities facilitate word’s retrieval, resulting some interacting effects on memory. 
children spontaneously produce speech as they learn a language, which raises the question of whether articulation of words is necessary for language acquisition. while one side argues that it is not essential (gathercole et al., 1999), the other propounds for a perception-production link (keren-portnoy et al., 2010). this research explores the impact of production on the development of lexical representations. adults were trained on non-words with visual referents, with half produced by the participants and half just heard. using a visual world paradigm, participants then saw two trained images and were asked to look at a target. as hypothesized, results indicated faster processing speed and accuracy of the new words that were produced at training. participants recognized produced words 200 ms faster than heard words, consistent with the hypothesis that production impacts newly formed lexical representations.
bilingual children are regularly exposed to code-switching, a linguistic phenomenon consisting of mixing two languages within the same context (byers-heinlein, 2013a). studies have demonstrated that adults are slower to process code-switched language (grainger & o'regan, 1992), and preliminary studies testing intra-sentential switches (“where is the chien?”) found similar results with toddlers (byers-heinlein, 2013b). here, we investigated 20-month-olds’ processing of code-switching across a sentence boundary (inter-sentential switching). in a preferential looking paradigm, 10 english-french bilinguals viewed a target and a distractor image on an eyetracking screen. contrary to the predictions, children showed similar accuracy in looking at the labeled referent in code-switched contexts (e.g. "that one looks fun! le chien!") as in single-language contexts (e.g. "that one looks fun! the dog!"). the outcome suggests that code-switching does not always accrue a processing cost, and that the impact of a code-switch on processing depends on the location of the switch.
developmental, neuropsychological, and computational studies have suggested the importance of both relational knowledge and working memory in analogical reasoning. in this study, we investigated the extent to which individual differences in working memory (wm) and crystallized knowledge (gc) predicted accuracies on a visual analogy verification task. in the task participants were asked to compare geometric shapes varying in several parametric dimensions (sweis, bharani, & morrison, 2012). across problems we varied the problem difficulty by factorially manipulating relational complexity and relational distraction. as in many studies of matrix reasoning, both wm and gc composite measures were reliably correlated with overall visual analogy performance. however, only wm, but not gc, predicted the effect of relational complexity on visual analogy performance. we believe these results further confirm the importance of working memory as a distinct neurocognitive resource necessary for processing relationally complex analogies.
cross-language differences in spatial language are not always reflected in nonlinguistic spatial representations. for example, the distinction between support and non-support relations among objects is obligatorily marked by basic spatial terms in english ("on" vs. "above"), but not in korean – yet spatial memory is sensitive to this distinction for speakers of both languages. here, we provide preliminary evidence that this pattern extends to the relation between spatial language and spatial perception, not just memory. in a visual search task, english speakers showed categorical perception (cp) for the support/non-support distinction. initial data suggest that korean speakers likewise show cp for this distinction. these results imply that certain spatial properties are sufficiently salient to affect perceptual discrimination, even when not captured by the basic spatial terms of one's native language. we discuss the implications of these findings for accounts of the role of language in perception.
party music is an important contextual factor for decisions to partake in risky alcohol consumption, yet few studies have examined its role in this decision-making process. recent dual-process models of decision-making emphasize the critical influence of context and associations on behavior. in the current study, we exploit the ability of party music to capture social context and alcohol-related associations in order to create a more situated and relevant environment in the lab. we utilize two groups – women with alcohol use disorder (aud) and women without aud (controls) – to investigate how specific cues and contexts interact with individualized personal associations and preferences to affect decisions. we report an experiment that suggests that type of music acts selectively to influence the decision-making behavior of people with aud in an ecological decisions task involving visual alcohol cues and risk information. 
computational models of the prefrontal cortex and its interactions with the basal ganglia have suggested that a reinforcement learning process involving dopamine drives the adaptation of frontal working memory circuits, determining when information should be actively maintained in working memory and when it should be released. the key mechanisms of these models have been translated into an open source software library called the working memory toolkit (wmtk), which has been used to provide an adaptive working memory to robot control systems. we present a demonstration of the fidelity of the wmtk to its biological inspiration by using it to learn a task used to assess frontal function in humans and non-human primates: the delayed saccade task. a camera on a motorized pan-tilt head learns, from simulated rewards, to remember the location of a peripheral visual target, demonstrating its knowledge by looking at that location long after the target is gone.
a substantial amount of recent research has focused on whether children can learn from pictures books. however, no previous research has characterized the learning potential of fictional picture books that are widely available and read to children. in the present study, we coded 50 bestselling and 50 randomly-selected children’s picture books for their learning potential along a number of dimensions. borrowing from children’s literary theory to create the coding scheme, we found that 79.5% of books had didactic intent; 62.5% contained moral lessons and 17% contained natural facts. of those books containing morals, the majority were implicit. impossible events were more common than ordinary or improbable ones, whereas settings and characters were predominately realistic. sitting at the intersection of cognitive development, education, and literary theory, this work provides an important characterization of what is available in naturalistic input. we discuss the implications of book content and format of presentation for different types of learning. 
in some cases, children perform better in tasks that allow them to make active choices. however, the cognitive mechanisms underlying this facilitation remain uninvestigated. one possibility is that choice aids children’s cognitive flexibility, which develops rapidly during the preschool period. in experiment 1, we assessed whether 5-year-olds more flexibly switched tasks when allowed to choose when to switch. overall, there was little evidence of facilitation. however, children who chose strategically (i.e., chose to stay with the same task rather than switch) outperformed children who were not allowed to choose. experiment 2 assessed whether children’s ability to benefit from choice was related to their ability to monitor task difficulty and control task demands. for only those children allowed to choose between tasks, flexibility performance correlated with sensitivity to task difficulty in a separate measure. these findings suggest a possible association between children’s metacognitive ability and their ability to benefit from choice. 
adults’ linguistic backgrounds influence their sequential statistical learning in an artificial language characterized by conflicting forward-going and backward-going transitional probabilities. english-speaking adults favor backward-going transitional probabilities, consistent with the head-initial structure of english, while korean-speaking adults favor forward-going transitional probabilities, consistent with the head-final structure of korean. we further found that english-learning infants develop this directional bias by 13 months, indicating that statistical learning rapidly adapts to the predominant syntactic structure of the native language. such adaptation possibly facilitates subsequent learning by highlighting statistical structures that are likely to be informative. subsequent testing on adults revealed the possibility to retrain monolinguals towards parsing preferences that are not consistent with their native language, suggesting training interventions to improve second language learning. these infant and adult findings highlight the importance of experience-dependent learning and plasticity across one's lifespan.
my-side bias is the tendency to ignore or exclude evidence against one’s position. the present study investigated ways of encouraging students to reduce my-side bias and generate more counterarguments in writing argumentative essays. fifth-grade students (n=90) from elementary school in japan wrote persuasive essays about school rule topics under three different conditions. 1) strategy condition: students were given a text outlining strategies to generate more counterarguments. 2) role condition: students were given the same strategies plus instructions to write like a journalist. 3) control condition: students were simply told to write persuasive essays. students in the strategy and role condition generated more counterarguments than the control condition. in addition, students in the role condition referenced evidence against one’s position and included a greater number of rebuttals than the strategy condition. these results suggest that role assignment reinforce usage of writing strategies and reduce my-side bias in writing arguments.
this study investigated the interaction effect between a mood and an implicit hint on insight problem solving. a total of 60 undergraduate students participated in a 3 (mood: happy, sad, neutral) × 2 (subliminal priming: hint, no-hint) factorial between-participants experiment. in the happy and sad conditions, they described a life event that had made them feel happy or sad. in the neutral condition, they drew a map of their campus. next, participants engaged in an insight problem solving task for 10 minutes. two minutes after starting the task, they watched “an irrelevant movie” for one minute. in the hint condition, the movie included a hint image (exposed 33 ms × 60 times). the hint raised the solution rate only in the happy condition. this result suggests that a positive mood facilitate the acceptance of information available in the environment. people also seem to unconsciously assimilate the information into their thinking.
a converging body of work suggests that cognitive control operates via two distinct operating modes – proactive control and reactive control, dissociable on a number of dimensions, such as computational properties, neural substrates, temporal dynamics, and consequences for information processing. at the same time, two forms of reinforcement learning (rl), called model-based and model-free rl, which are theorized to operate and parallel and jointly control behavior, are dissociable along similar dimensions, and thus suggest that individual differences in proactive versus reactive control (which are well documented in the literature) should map onto expression of the two forms of rl. we test this hypothesis by revealing how expression of proactive control in a well-established cognitive control task predicts usage of model-based reinforcement learning in a sequential choice task. in short, we find that expression of proactive control rather strongly predicts expression of model-based, but not model-free choice.
impulsivity is one of the primary drivers of decision-making when gambling. it has been shown that the magnitude of impulsiveness is linked to gambling severity, though it is unclear which facets of impulsivity shape gambling behaviour. here, we model data from 48 healthy male volunteers playing a naturalistic, virtual slot-machine gambling task. we use a hierarchical bayesian belief-updating model, the hierarchical gaussian filter (hgf), to estimate the processes guiding individual gambling behavior. we then perform a factorially-structured model comparison and post-hoc multiple regression analysis of individual barratt impulsiveness scale (bis) scores on model parameters. the uncertainty-encoding parameters of the winning model significantly explain bis scores, particularly the motor and non-planning impulsiveness subscales, suggesting a strong tie between individual uncertainty and these elements of impulsivity. this mechanistic explaination of gambling unmasked during actual play, not self-report, may be useful in prevention measures for at-risk players and clinical assessments of gambling disorders
exposure to media violence has been associated with decreased empathy and increased aggressive behavior.  one possible mediator for this relationship may be emotional face processing; however, little is known about how media violence may influence the neural correlates of emotional face processing.  twenty-six participants were shown violent and nonviolent movie clips during separate testing sessions and then had their brain waves recorded while completing a stop-signal gender discrimination task using happy and fearful faces. results showed that media violence exposure influences the processing of emotional faces as reflected in the p200 and p250 event-related potentials (erps).  inhibitory control was also influenced by media violence exposure as reflected in the p300 erp.  these results indicate that even relatively short-term passive exposure to media violence can modulate the processing of emotional faces offering a possible mechanism by which media violence could modulate empathy and possibly aggression. 
medin et al (2003) proposed that relevance is crucial for property induction. two experiments were conducted to test the effects of instructing the relevance and processing efforts. in both experiments, the relevance of causality or the diversity was manipulated by giving different instructions. processing efforts were manipulated differently in the two experiments. in experiment 1, processing effort was manipulated by setting time limits. giving instruction about the relevance did not affect performance when participants had to answer in less than four seconds. however, instructing the relevance of causality increased the believability of the conclusion when participants were allowed to respond in 10 seconds. in experiment 2, two premises and the conclusion were presented either simultaneously or successively. instructing the relevance of diversity or causality increased the believability of the conclusion when the two premises and the conclusion were presented successively. the results gave partial support for the relevance theory.
probabilistic inference models (e.g. bayesian models) are often cast as being rational and at odds with simple heuristic approaches. we show that prominent decision heuristics, take-the-best and tallying, are special cases of bayesian inference. we developed two bayesian learning models by extending two popular regularized regression approaches, lasso and ridge regression. the priors of these bayesian models match the environmental structures necessary for tallying and take-the-best to succeed. provably, the bayesian models become equivalent to the heuristics as their priors become more extreme; hence they subsume heuristics and standard linear regression. in a re-analysis of datasets favouring heuristic approaches, we show that our bayesian extension of ridge regression outperforms tallying and linear regression. a similar result holds for our bayesian extension of lasso regression and the take-the-best heuristic. this indicates that true environmental structure and potentially psychological processing often lie somewhere between the assumptions of heuristic and standard regression approaches.
while substantial evidence has demonstrated the effectiveness of peer assessment, how peer assessment—more specifically, providing feedback—contributes to learning is unclear. to explain why providing feedback improved kindergarten students’ letter writing ability, we examined whether teaching students how to provide specific feedback drew their attention to key features of letter formation and thus resulted in fewer errors. students participated in a 16-week intervention where they were taught to provide specific feedback relating to the place, size, and shape of the letters. data from 62 students (22 who received whole-class instruction, 22 who received small-group instruction, and 18 control) were coded. the amount and types of errors made on a letter writing task at pretest and posttest were analyzed to determine whether providing feedback decreased the amount of specific errors, and whether improvement in letter writing was positively related to the cognitive processes of problem identification and diagnosis. 
there is debate over whether the horizontal segment of the intraparietal sulcus (hips) houses a domain-specific number module (ansari, 2008). here, we address the debate in two ways. first, using cross-domain modeling (penner-wilger & anderson, 2011) we show that bilaterally the hips shows activation across a wide range of non-numerical tasks in diverse domains including perception, action, cognition and emotion. second, using methods similar to those used in anderson, kinnison and pessoa (2013), we compared the functional diversity of the hips and domain-general rois that contribute to number processing – the left ag and pspl bilaterally. we show that the functional diversity of all five of these rois is near or above the whole-brain average. moreover, right and left hips and left pspl are significantly more diverse than the whole-brain average (&gt;2 sd). thus, our results support the view that the hips does not house a domain-specific number module.
research has demonstrated that deception is more cognitively demanding than truthful communication. furthermore, evidence suggests when put under certain cognitive constraints interlocutors exhibit more disfluencies during production planning. one common emotion regulation strategy involving deception is emotion suppression. recent research indicated emotion suppression can lead to maladaptive threat responses in both members of a dyadic interaction. the current study juxtaposed research on communication and emotion regulation by having two participants watch and discuss an emotionally evocative video. before engaging in the conversation, one participant (the agent) was asked to express or suppress non-verbal affective displays while the other person (the target) received no special instruction. we hypothesized that targets’ perception of suppression would affect their production system. results supported our hypothesis, disfluencies increased for suppressive agents but decreased for targets of suppression, suggesting that the social constraints may have lead dyads to expend more cognitive resources on speaking appropriate utterances. 
previous research has demonstrated that basic visual processing is enhanced when stimuli are presented near the hands. it has also been suggested that this preference for processing stimuli presented hand-proximal extends to higher-order cognitive processes, such as executive control (i.e., greater control for hand-proximal stimuli). executive control, however, is associated with a number of different functions and as such we need a deeper understanding of which functions are and are not influenced. in the present study, we explored whether or not this preference for processing hand-proximal information influences the ability to sustain attention, a process closely associated with executive control. participants completed a sustained attention task, with hands either near or at a distant from the stimulus. in a series of experiments, we found no evidence for preferential processing for hand-proximal information in a sustained attention task. implications for a developing theory of the influence of hand-proximity will be discussed.
short term memory (stm) is the ability of the brain to maintain a perceived stimulus even after the stimulus has disappeared. stm is assumed to be implemented in the sustained activity observed in the prefrontal cortex (pfc) during diverse tasks, like visual memory, object labelling, identity or other cognitive tasks.  we here suggest that this  activity can be explained as the result of changes in  recurrent activation in the pfc. we use  a linear neural field model with inhomogeneous connections to explain activity during a visual perception task. in this task, the subject is asked to remember the value of a cue (angle) during a delay period.  this bypasses expensive computational costs of nonlinear (e.g. conductance-based) models that have previously been used to implement synaptic modulation. we show that  population’s internal state  encodes a parameterization of the presented  stimulus and consider activity-dependent synaptic efficacy. we show that the pfc population exhibits tuning sensitivity reaching different attractors for different stimulus values that maintain persistent activity during the delay. we also study qualitative changes of pfc connections induced by input from the sensory cortex and compare  connectivity strengths before, during and after visual cue.
how do we process complex sentences like the dog the man walks barks? how are hierarchical grammars actually learned?  and what is actually learned? syntactical rule knowledge or the skill to use the  hierarchical system for communicating meaning? 	three artificial grammar learning experiments investigated this question. the first experiment tested learning after exposure to exemplars of a complex center embedded grammar. the test task was grammaticality judgments of new sentences. in two subsequent experiments, participants were exposed to the same artificial sentences, now with pictures displaying their meaning. a sentence-picture matching task tested their comprehension of new sentences of the complex grammar. no learning was found in the first experiment. however, participants did learn to ‘understand’ the meaning of the same test sentences (in experiment 2 and 3) that participants in experiment 1 were unable to judge the grammaticality of. 
the possibility of automatic analogies is still debated. while people can perform analogies unintentionally and unconsciously in some complex structures like interpretation of ambiguous stories, yet, they seem not to benefit from relational similarity between simple structures in a lexical decision task (ldt). moreover, automaticity supporting studies have used lack of analogy-orienting instructions and awareness debriefing to determine automaticity. we tested whether analogies can operate in simple structures under high executive load conditions in a dual-task paradigm. participants were faster in a ldt on pairs of words preceded by analogically related pairs of words compared to ones preceded by unrelated pairs, while performing a random interval generation task, which is known to interfere with executive functioning. they were neither told about the connection between pairs, nor did they report noticing it. participants performed analogies not only unintentionally and without awareness, but efficiently as well.
it would appear that the concepts newspaper, doctor, bus, and bank have nothing in common that distinguish them from concepts like magazine, surgeon, car, and hotel. nevertheless, definite noun phrases containing words corresponding to the two sets of concepts are interpreted differently. for example, "john went to the surgeon and bill did too" is interpreted as involving a specific surgeon who is seen by both john and bill. in contrast, "john went to the doctor and bill did too" allows for the possibility that john and bill saw different doctors (weak definite interpretation). we propose that weak definite interpretations are possible for nouns that name kinds that are simultaneously conceived of in concrete and abstract terms and provide principles of individuation and non-individuation. three experiments provide support for this non-obvious characteristic of conceptual structure distinguishing the two sets of concepts and licensing the possibility of weak definite interpretations.
dynamic decision-making (ddm) is interested in the study of complex decision-making involving dynamic systems and problem spaces. through the use of human in the loop experimentation in an interactive learning environment, we endeavour to observe the impact of complexity on human performance. our research presents some preliminary efforts in determining objective models and metrics of complexity to measure the impact of system complexity on comprehension and performance, drawing on research in applied cognitive psychology, cognitive informatics, and complexity theory. by using serious games scenarios of varying degrees of complexity, psychophysical measures have been collected and benchmarked, such as prediction and decision performances, subjective measures of confidence and assessment of problem complexity, etc., according to a number of objective measures of complexity. additional critical factors of ddm are modeled, such as the goal distance to reach objectives, in order to establish criteria for an objective measure of difficulty, beyond problem complexity.
interactive learning environments provide new opportunities for fine-grained tracking of student performance. these environments typically provide progressions of related problems, and allow students to make multiple attempts at solving each problem as well as access hints or other resources. we explore how students' understanding of chemical reactions changes based on their interactions with chemvlab+. chemvlab+ (chemvlab.org) is a series of online activities that allow students to explore real world chemistry questions through problem solving exercises and virtual chemistry labs. thirteen teachers used four stoichiometry activities in their high school classrooms, and administered pre- and post-test assessments. using balancing chemical reactions as a case study, we analyze how student performance changed during and after their interactions with chemvlab+. we find that students' proposed solutions can be characterized by a small number of features, and that assessing understanding using these features demonstrates improvements not revealed by examining only solution correctness. 
how are body representations updated when we perform joint rhythmic actions, such as when a jazz player synchronizes with other musicians in the ensemble? we investigated this question using a continuous tapping task where musicians and non-musicians were instructed to imitate bimanual hand movements presented in the egocentric and the mirror orientation. the observed movements increased in tempo (from 3.5 hz to 4.2 hz). results showed that participants were more accurate in imitating the timing and spatial parameters of observed movements in the egocentric than the mirror orientation. however, the pattern of performance in the mirror orientation varied depending on rhythmic ability: musicians mapped the observed movements anatomically (e.g., left-hand was aligned with the observed left-hand) and non-musicians aligned their responses spatially to the stimuli (e.g., left-hand was aligned with the observed right-hand). these results suggest that temporal coordination mechanisms play an important role in updating of the body schema.  
the emerging research interest on neural oscillation in neuroscience has resulted in an ever-increasing number of studies on various cognitive and neuro-developmental phenomena. there is, now, evidence linking brain physiological descriptions with certain phenotypes in normal and atypical behavior, involving neural oscillation. case studies include brain disorders, such as autism and schizophrenia, as well as limitations in working memory capacity and its executive control.there is research under way, conducted principally by the author, to establish an exegetic framework, under which neural oscillation can be implemented in neurocomputational models by using self-organizing maps (soms). it is claimed that the mechanism of biological lateral inhibition in brain cortical maps, central to a number of neuropsychological theories, could be implemented with higher biological plausibility using a som network with an oscillating -rather than a standard- topological neighborhood. computational models and simulations demonstrate a significant functional equivalence between oscillating and standard som implementations.
in non-stationary environments, the outcomes of certain choices may change over time. therefore, people need to balance between the exploitation of presumably superior choices in order to maximize their outcomes and the exploration of seemingly inferior alternatives in order to observe environmental changes. recent research suggests that people actually follow this principle and exploit choices they currently prefer while once in a while systematically exploring alternatives in order to update their beliefs about the environment. the present study follows up on this by extending the scope to the numerous choice options that people face in a retail store. we investigate choices from over 10,000 customers of a major uk supermarket chain over five years and find evidence that people systematically exploit and explore product choices. furthermore, we are able to describe how their explorative behavior varies across different product categories.
research in cognitive and developmental psychology scrutinizes causal concepts predominantly from a domain-specific perspective. in particular, natural and supernatural concepts are frequently subordinated to incompatible and mutually exclusive domains. the profound ethnographic knowledge of cultural anthropology and recent psychological work suggest, however, that causal concepts can easily incorporate both of these and other domains. previous results from tonga also hint at the use of cross-domain explanations. to reconstruct boundaries of cognitive domains in tonga, we collected pile-sorting data on how causal entities from different content areas are sorted into groups. based on clusteranalysis and multidimensional scaling, distinct groups of items emerged that partially correspond to prevailing domain-specific classifications. in addition, we found data patterns that also indicate culture-specific representations of knowledge and an overlap of domains. 
there are numerous findings in the literature supporting an association between bodily states and other cognitive and social processes. for example, glenberg and kaschak (2003) found that verbs with a movement component (e.g., give) are faster recognized when participants perform a congruent movement (extending an arm) than an incongruent one (flexing an arm). in the present experiment, we wanted to examine whether arm movements commonly associated with give (extend an arm) or take (flex an arm) could have an influence on participants’ prosocial behaviour. participants were required to distribute an amount of coins into two boxes - one box assigned themselves, the other assigned to another unknown participant - either by performing an arm extension or an arm flexion on a multi touch screen. results show that the distribution of the coins was affected by the movement performed, and also movement times differed depending on the movement and the targeted box. 
the ratio of iris width to eye width is roughly 0.6 during infancy, falls to about 0.42 in young adulthood and middle age, and then increases again after age 50. thus the iris-to-eye ratio (ier) is a nonlinear, probabilistic signal of age. has natural selection shaped our judgments of facial attractiveness to be sensitive to the ier? here we present an experiment suggesting that, for male observers, the answer is yes. on each trial, observers viewed two adult faces that were identical except for ier, and indicated which face was more attractive. male observers preferred the larger ier (which signals youth) in all faces, suggesting that males have indeed been shaped by natural selection to be sensitive to the ier in their judgments of facial attractiveness, and to prefer iers indicative of youth. females showed no preference for larger or smaller iers, a result that invites further exploration.
among the key cognitive abilities that separate humans from artifacts is the ability to understand, generate and use social emotions underlying behavior. the recently developed emotional biologically inspired cognitive architecture (ebica: samsonovich, 2013) fills this gap, allowing for the design of emotionally intelligent agents. the approach is based on several new elements in the architecture, including appraisals, moral schemas, drives, desires and value systems. the main objective of this study is to validate and further develop the model using behavioral experiments with undergrads. settings include a simplistic virtual presence of agents that interact with human participants and with each other by performing a limited repertoire of emotionally laden actions. results indicate that the model allows us to describe and reproduce certain aspects of human social behavior that determine lasting emotional relationships. the question of episodic vs. semantic nature of emotional memories underlying the emergence of social relations is also addressed.
conventional model-free reinforcement learning algorithms are limited to performing only one task, such as navigating to a single goal location in a maze, or reaching one goal state in the tower of hanoi block manipulation problem. it has been thought that only model-based algorithms could perform goal-directed actions, optimally adapting to new reward structures in the environment. in this work, we develop a new model-free algorithm capable of learning about many different tasks simultaneously, and mixing these together to perform novel, never-before-seen tasks. our algorithm has the crucial property that, when performing a blend of previously learned tasks, it provably performs optimally. the algorithm learns a distributed representation of tasks, thereby avoiding the curse of dimensionality afflicting other hierarchical reinforcement learning approaches like the options framework that cannot blend subtasks. this result forces a reevaluation of experimental paradigms that use goal-directed behavior to argue for model-based algorithms.
are you feeling up today, or down in the dumps? spatial metaphors that connote affective valence are common in english, where up in space=happy/positive and down in space=sad/negative. past research suggests that these metaphors have some measure of psychological reality: people are faster to respond to words with an emotional connotation in metaphor-congruent regions of space (meier & robinson, 2004), and simply making motor movements upwards/downwards can bias memory retrieval towards positive/negative events, respectively (casasanto & dijkstra, 2010). while most research has dealt with relatively abstract items/measures, we asked whether space could actually bias perceptual judgments of non-ambiguous visual stimuli. participants viewed images of happy and sad profile faces in different orientations and had to identify the emotion depicted in each face. results indicated an interaction between spatial orientation and response time: participants were significantly slower to respond to sad faces that were facing upwards as compared to happy faces. 
current ‘embodied simulation’ approaches to emotion perception suggest that individuals classify another person’s emotions in a three-step process: (i) observers automatically mimic a target’s facial expression, (ii) this motor activation generates the corresponding emotion in the observer, and (iii) the observer attributes his or her current emotional state to the target. in this study, we argue that this ‘observer as mirror’ model is either currently incomplete or misleading. results in an ingroup-outgroup emotion perception task suggest that embodied states can lead to ‘convergent’, ‘divergent’, or no changes to emotion recognition at all. 
computational modeling of how people maintain beliefs and make decisions has become increasingly popular for understanding the dynamic of social interaction. in this work, we create a computational model for different parenting styles -- authoritative, authoritarian, and permissive -- and simulate their impact on children’s emotional experiences and academic performances.  this model is created within a larger decision-theoretic framework for social simulation. our model is capable of reproducing the classical cases of children’s academic performances dropping because their parents either pushing them either too much or too little in their school work. through fine adjustment of the parameters, we are experimenting how fine distinctions in parenting style affect children’s long term academic performances and mental health. 
tetris has been used as a research tool more often than any other video game (mayer, in press). however, perhaps due to the game's complex combination of visual features, rapid changes, and real-time decision-making, research and understanding of the strategies used by human players has languished. we use cross-entropy reinforcement learning (cerl) to explore the space of features and feature weights that predict or do not predict fine details of human performance. as cerl models operate without human constraints (e.g., all possible placements are evaluated on each episode of play without any cost of time) an important part of our project is to identify the fine details of play that distinguish human judgement from cerl judgement and to relate these differences to human cognitive strengths (such as goal hierarchies) and weaknesses (such as movement time and time to consider and weigh alternative moves)
general recognition theory (grt) provides a powerful framework for modeling interactions between perceptual dimensions in identification-confusion data. the linear ballistic accumulator (lba) model provides powerful methods for analyzing multi-choice (2+) response time (rt) data as a function of evidence accumulation and response thresholds. we extend (static) grt to the domain of rts by fitting lba models to rts collected in two auditory grt experiments. although the mapping between the constructs of grt (e.g., perceptual separability, perceptual independence) and the components of the lba (e.g., drift rates, response thresholds) is complex, the dimensional interactions defined in grt can be indirectly addressed in the lba framework by testing for invariance of lba parameters across appropriate subsets of the data. the present work focuses on correspondences between (invariance of) parameters in lba and perceptual separability and independence in grt.
the activation of conceptual metaphors has always been studied one mapping at a time. what happens when various conceptual metaphors are processed at the same time is still unknown. the experimental design used here enabled the activation of three conceptual metaphors at the same time (past-left/future-right, negative-left/positive-right and negative-past/positive-future). participants had to make temporal or valence judgments with their left or right hand on negative or positive verbs conjugated to the past (e.g. “he cried”) or to the future (“she will smile”). our results showed that the three conceptual metaphors were processed in parallel: the processing of one conceptual metaphor did not interfere with the processing of the other metaphors, even if they shared a conceptual domain. we also tested whether participant’s mood could bias the perception of the concepts used here. depressive participants showed a past-oriented bias that changed towards the future after a therapy session.
while still the dominant method of statistical inference, the null hypothesis significance test (nhst) is controversial. recently, it has been suggested to replace the traditional nhst with a bayesian alternative using bayes factors. while bayesian tests resolve many of the problems that plague the traditional nhst, they still suffer from the issue that in rejecting the null hypothesis, one effectively rejects full knowledge in favour of (near) complete ignorance. determining whether a parameter is likely to have a particular (null) value may be better served by bayesian estimation and credibility intervals. hypothesis testing may be more valuable after reformulating of the null hypothesis. this work explores a bayesian hypothesis testing procedure in which the null hypothesis reflects a state of complete ignorance or lack of knowledge. the procedure has some useful properties, amongst which the imperative to develop informative hypotheses and an associated drive towards cumulative theory development.
traditionally, negation has been viewed as a symbolic process. in this two-step account, a negation operator is applied to the affirmative version of a sentence to construct the negated form. however, a recent model (huette and anderson 2012) has demonstrated that negation can be processed by a simple recurrent network trained to simulate sensory information when given linguistic input. while the model serves as an existence proof that shows the ability of negation to be processed without symbols, the exact behavior of negation within the network remains relatively unexplored. we extend the analysis of the model and pay particular attention to how information from the negation word ‘not’ integrates with other information in the network to convey particular sensory features. further, we show how the model is consistent with the current body of experimental work on negation. 
color naming across languages has generally been held to be shaped either by universal constraints, or by local linguistic convention. however, another possibility is that color naming may be influenced by local environmental factors, such as the relative frequency of different colors (color diet). this study investigates that possibility. color diet correlates with the köppen-geiger climate classification system, which divides the earth’s surface into climate categories. each language in the world color survey, a large body of cross-language color naming data, was categorized according to the climate category for the location where that language is spoken. rainforest and monsoon languages, both of which have green-heavy color diets, were found to have color naming systems that differ significantly from those of savanna languages, which have relatively little green in their diets. these results suggest a link between climate-driven color diet and color naming.
do voters really hold their political attitudes so firmly that they are unreceptive to persuasion? we asked our participants to state their voter intention, and presented them with a political survey of wedge issues between the two coalitions. using a sleight-of-hand we then altered their replies to place them in the opposite political camp, and invited them to reason about their attitudes on the manipulated issues. finally, we summarized their survey score, and asked for their voter intention again. the results showed that no more than 22% of the manipulated replies were detected, and that a full 92% of the participants accepted and endorsed our altered political survey score. furthermore, the final voter intention question indicated that as many as 48% were willing to consider a left-right coalition shift. this can be contrasted with the established polls tracking the swedish election, which registered maximally 10% voters open for a swing.
between the first and second year, toddlers’ word learning accelerates. explanations for this “vocabulary spurt” include the emergence of domain-specific constraints and a change from associative to referential learning. what these and other accounts share is that the proposed mechanism is in the toddler’s head. here, we propose a different explanation: the input during the spurt changes in ways that promotes learning. we observed, through toddler-perspective head cameras, the visual input to 13- (pre-spurt) and 20-month-old (mid-spurt) toddlers as their parents named objects in an object-play session. results suggest that the named object was more likely to dominate the older toddlers’ view. coding of toddlers’ and parents’ holding behavior suggests that this increase in dominancy is due to an increase in 20-month-olds’ holding during naming. interestingly, we also observed an increase in parents’ holding during naming. implications for the cascading effects of motor development on language development will be discussed. 
the present study investigated the effect of ceiling height on the symbolic distance effect (sde). we hypothesized that a high/low ceiling height would produce a small/large sde through divergent/convergent thinking. we prepared three sde tasks: numerical, spatial, and temporal. participants conducted these tasks in both high and low ceiling conditions. results showed that in the spatial and temporal tasks, a high ceiling height produced smaller sdes, and a low ceiling produced larger sdes (but not in the numerical task). these results suggest that the environment affects not only cognitive performance but also the nature of mental representations.
advisors are a fundamental part of contemporary financial decision-making, corporate development, and legal matters - for better or worse. we examined the factors that influence people's reliance on and willingness-to-pay for advisors in two experiments. unknown to the participants, the advisor’s advice was random. the factors we investigated include set size and advisor payment schemes (e.g., fixed price or commission). in general, our results suggest that people with larger set sizes are more willing to ask for and pay more for advice. however, they were not necessarily willing to take the advice. this suggests that when people had more alternatives, they face a need to seek help but not necessarily follow the requested help. additionally, those who had larger set sizes made more choices for alternatives without sampling or advisor suggestion.  this may indicate a further influence of information overload (‘let fate decide’).
our model of action selection and postcompletion error in two form filling tasks extends to skip errors in a story telling task. we also discuss how it explains perseverations in one of the aforementioned form filling tasks. finally we discuss a predictive classifier application we built from the model’s data. the classifier could allow an autonomous agent to know when it is a bad time to interrupt a human, when a human is about to err, and how to help.
although there has been much interest in inferring mental representations from similarity data, there have been no attempts at inferring representations directly from generalization data. we develop an approach in which a hypothesis space can be inferred from human generalization data. by defining the likelihood function relating human generalization data to a bayesian generalization model, we are able to infer the most likely hypothesis space(s) humans used to produce the generalization data. one of the advantages is that, unlike with similarity based approaches, we can explore the effect of semantic context on the hypothesis spaces people use when generalizing.
we conducted a series of studies on the implied causal structure of metaphors. some metaphors are “systemic” and highlight the complexity of relationships. for example, describing a national park as the “backbone” of the park system situates the park in a larger body of national parks, specifying a set of relationships between that park and the whole system. other metaphors don't enforce the same level of relational structure, instead highlighting a particular element of a scene or event. for example, describing a national park as a “pearl” of the park system emphasizes the beauty of the park, but leaves the relationship between this park and the rest of the elements in the system only weakly specified. we contrasted metaphors that implied more or less systemic relational structure and found that they influenced how people construed an event like the designation of a national park.
what is required for an individual a at an earlier time to be the same person as an individual b at a later time? the philosophical literature on personal identity is rich, but here i present experimental evidence demonstrating that the ordinary concept of personal identity differs from that assumed by many of these philosophical discussions. specifically, i challenge three common assumptions about the concept of personal identity: that moral judgment is irrelevant to personal identity, that personal identity is a necessary or sufficient condition for the application of moral concepts like just desert, and that the personal identity relationship is necessarily symmetric. in contrast, i find moral judgment does influence attributions of personal identity, for many personal identity is neither a necessary nor sufficient condition for desert, and in some cases an individual a is judged as identical to b, but b is judged as not identical to a.
taking a test during learning enhances later retention more than spending equivalent time restudying the same materials (roediger & karpicke, 2006). in the study, we first recorded participants’ eye movements in a paired-associate learning task while they were re-studying or tested for immediate cue recall. testing prompted final item memory but not memory for its associated location. participants’ proportions of fixation duration were analyzed within the roi : areas covered the cue word and two possible locations of the associated test words. larger fixation proportions at the cue word area were found in the testing than the re-study conditions. fixation proportions in the area covering the cue-associated word were larger in the re-study than the testing conditions. moreover, eye movements recorded during the final cue recall didn’t show significant differences between the two learning conditions. the eye movement measures revealed some differences between the testing and re-study conditions during the initial learning.
previous studies on the structure of emotion concepts often use multidimensional scaling (mds) or other clustering methods to plot different emotion words upon 2d space or dendrogram, representing each emotion as a point or branch within the structure, and the categories of emotions are determined accordingly. although there seems to offer the conceptual representations of typical or atypical emotion words categorically, above approaches merely classified an emotion into a single category. hence, this study is aimed at using self-organize map (som) algorithm to explore the semantic structures of chinese emotion words and reason what indexes would profile typical and atypical emotion words in each semantic category properly. the som, an unsupervised artificial neural network, is able to cluster data based on hidden nonlinear relations between information processing nodes. the present study adopts words from a linguistic corpus of chinese emotion words, and relevant emotional attribute ratings as input for training and testing the som model. results showed that some emotion words were clustered into different categories while repeating the construction of the models. differences in quantization error of attribute distances in the map between emotion words might also reflect their differences of semantic features. according to the findings, theoretical implications on representing the semantic structure of chinese emotion words are discussed.
via questionnaires, uchida & mori (2013) found “fake math phobias” among roughly one-fifth of a japanese 7th grade sample who claimed they disliked math although they performed positively on an implicit association test. they should be rescued before they develop genuine math phobias. this study explores one possible way to do this. we examined 204 other 7th graders and found that 38 of them had fake math phobias. we divided them randomly into target and control groups, matching their math achievement scores pairwise, and informing only the target students of their implicit positive attitudes toward math. no such information was provided to the control students. one year later, 15 of the 16 target students showed improved math achievement while only 8 of the 18 control students did. the simple practice of informing students that their math phobias were fake seems to have prevented them from developing real math phobias.
a series of studies carried out over the last two decades have shown that those people who allow themselves to be immersed in a story are more likely to experience its persuasive effects (green, sasota & jones 2010). a number of studies carried out by cognitive scientists of religion have shown that people better remember counterintuitive ideas embedded in stories (upal et al. 2007). this paper reports on a study carried out to test the hypothesis that narrative transportation facilitates memory for counterintuitive concepts i.e., more someone is transported into a story, the better memory they will have for counterintuitive concepts embedded in the story. participants read 3 stories (each containing 6 counterintuitive concepts) with different narrative transportation levels and completed the narrative transportation scale. responses were coded for recall.  the results were mixed with the transportation facilitating recall but only for concepts that were critical to the story plot.
in previous work we have shown that when children hear the name of a target object prior to search they are faster at finding that target amidst distractors. the results suggested that words influence the encoding of the target in working memory, which then drives visual selection (vales & smith, 2014).however, this facilitation could be due to words enhancing the encoding of the specific objects presented, or words activating knowledge about the category features. we will present a theoretical analysis of this distinction and new experimental data. in the current experiment we ask children to search for the same object category within a block, and across trials children either search for the same or a different object.by specifying how precise the working memory representation of a labeled target is, the current results clarify the processes by which words organize children’s attention. 
 the full meaning of a word takes years to be learned, and we want to find the minimum that needs to be learned in order to efficiently read a text. we used latent semantic analysis (lsa), neural networks (nn), and semantic graphs to model word acquisition and reading comprehension. we modeled word learning using a corpus -wikipedia- to train the nn and lsa; in the case of semantic graphs, each time a an unknown word appears it is probabilistically linked to the words in the passage. comprehension in lsa and nn occurs when passage to passage cosine is over an adjustable threshold. in semantic graphs, comprehension occurs when a moving window of the text is connected in time through an adjustable number of direct links. we matched amount of learning of a word with comprehension. we plan to validate the parameters in the lab to devise educational interventions.
according to the syntactic bootstrapping hypothesis, language learners use structural cues in the linguistic context to infer the meaning of novel words. many studies support this hypothesis by showing that structure knowledge facilitates learning new words in a familiar language, but few have investigated the concurrent acquisition of word meaning and syntactic structure in a new language. in an artificial language learning experiment, we studied the interaction between learning word meaning and sentence structure. dutch participants (n=120) observed a series of animated scenes, each with an accompanying three-word sentence, and were subsequently tested on their linguistic knowledge. our results showed no bootstrapping effect at the early stages of learning. however, learners who acquired the underlying structure in the later stages performed significantly better on both word and sentence-level tests. moreover, participants learning an svo or sov language performed significantly better than participants learning a vso or unstructured language.
explanation is a critical component of higher cognitive functioning. we investigated whether some explanations are inherently appealing, or whether their appeal depends on context. to do so we presented statements (e.g., “ducks have property x”) coupled with formal, causal, or teleological explanations (“because property x helps them float”), and asked participants to evaluate the explanations. to assess effects of context, we asked some participants to perform an inductive inference (e.g., “what else has property x?”) in addition to evaluating the explanations. performing an inference influenced the appeal of the explanations. specifically, participants found formal explanations more satisfying when generating a related inference than when merely evaluating the explanation. the effect was reversed for causal or teleological explanations. this suggests that the appeal of an explanation depends both on the type of explanation and the cognitive purpose for which the explanation is sought, and demonstrates an important linkage between explanation and induction.
implicit learning research has generally examined form-level regularities with little work being directed at learning abstract rules of the kind underlying language. we constructed an artificial analogue of french in which the verb agreed in gender with the object in object-extracted sentences but not in subject-extracted sentences. we tested whether english native speakers (n = 25) could learn that verb agreement was conditioned by extraction type. after reading grammatical sentences in a segment-by-segment reading task, verbs with gender marking were read more slowly in subject-extracted (ungrammatical) than in object-extracted (grammatical) sentences. the effect was also significant for a subset (n = 11) of participants who were classified as being unaware on the basis of confidence whilst making grammaticality judgements. the results show implicit learning of an abstract syntactic rule and that self-paced reading can provide online evidence of developing sensitivity to syntactic violations.
categorization forms a primary cognitive ability.  recent models/theoriesof categorization propose that there are multiple systems underlying thisability: an implicit learning system and an explicit, verbal, system.  onesuccessfull neurocomputational model of categorization is covis (ashby,1998), which is used to explain eg categorization deficits in parkinson'spatients (hélie, 2012).  here we study categorization in children and usecovis simulations to explain developmental differences.  using changes inthe rule-selection and perseveration parameters, we were able to explaindevelopmental differences in a rule-based vs a family-resemblance task fromminda (2008).
a computerized phenomena explanation task designed with e-prime was used to investigate changes in explanations about natural phenomena happening after exposure to science instruction. one hundred and four (104) elementary school children and 43 college undergraduates verified 4 different explanations for each of 60 different phenomena belonging to 3 subject matter areas: physics, biology and mathematics. two of the 4 explanations for each phenomenon were consistent with both an initial and a scientific explanation while the remaining 2 were inconsistent with either an initial or a scientific explanation. it was hypothesized that the participants will be more accurate and faster to verify the explanations in the consistent condition compared to the inconsistent condition.  the results confirmed the hypotheses across the 3 subject matter areas, indicating that initial explanations remain entrenched and inhibit access to scientific explanations even in adults. the results are also consistent with dual process theories.
recent research suggests that the ability to infer the abstract, relational concepts "same" and "different" in a causal learning task is in place as early as 18 months (walker & gopnik, 2013).  here we address whether infants’ developing linguistic abilities play a role in the acquisition of these concepts.  researchers have long proposed a close relationship between semantic and cognitive development, and a variety of connections have been found between specific linguistic and conceptual achievements.  in the current study, we examine 14- and 15-month olds’ relational inferences in a causal match-to-sample task, and assess performance as a function of relational word production.  infants’ use of relational words such as “more” was correlated with their success on this task after controlling for general language abilities.  findings strengthen the claim that relational reasoning is early developing, and provide evidence that abstract concepts are reflected in and linked to specific linguistic representations.
past research has shown that students use feedback such as exam scores to regulate achievement goal pursuit, and that achievement goals predict class performance. however, little is known about goal change in the time between exams. using college classroom data, we examined changes in achievement goals across six time points and how they relate to exam scores. we found that achievement goals assessed immediately before an exam or immediately after grades were given were most strongly predictive of exam scores. changes in mastery-approach goals between the start of a unit and immediately before the exam predicted exam performance. however, changes in achievement goals from the time immediately before one exam to the time immediately before the next exam were not predictive of scores. this suggests that the changes to achievement goals within exam units, and not between units, are most important in predicting achievement outcomes.  implications for results are discussed. 
in probabilistic inference, people choose between alternatives based on several cues, each of which is differentially associated with an alternative’s value. for example, an investor uses multiple indicators when deciding between two stocks. many strategies have been proposed for probabilistic inference (e.g., weighted-additive, take-the-best, and tally). these differ in how many cues they require to enact, and in how they weight each cue. but do people actually use these strategies? one way to answer this question is to consider people’s choices. but different strategies often predict the same decisions. another way is to consider the cues people reveal. but search behavior says nothing about how people use the information they acquire. here, we use a high-density performance measure, verbal protocols, to study probabilistic inference. the promise of verbal data lay in their use to test detailed information processing models. to that end, we apply protocol analysis along with computational simulations.
chinese has been recognized as one of most major languages in the world, and many people are learning chinese; thus a method for learning chinese characters is a significant issue. many studies have developed various approaches to learning chinese characters to demonstrate to learners how to read chinese characters. in chinese, the character components can offer learners with phonological and morphological meanings similar to those of the prefix and suffix in english. additionally, when the components have strong connections, learners are more capable of readily learning and recognizing the characters containing these components. however, very few studies have discussed or exploited the associations among components for this purpose. in this study, we have developed an effective and systematic approach of learning chinese characters based on the associations between character components. the purpose of the study is to propose a traditional chinese component learning metric and present a method for learning only a few components and then developing the ability to read characters made up of those components. using the characteristics of associations of components can provide an effective and systematic traditional chinese component learning order by which to learn chinese traditional characters.
problem solving is a core cognitive ability.  humanperformance varies widely in solving different types of problems.ideally, cognitive models of problem solving should explain thesevariations in two ways: (1) the model should reproduce the sequences of actions applied by humans during problem solving (empiricaladequacy), and (2) the time required by the model should match that required by humans, i.e., the model should be fast (slow) when humans are fast (slow) (computational adequacy). the former can be assessed by traditional psychological experiments; however, the latter requires the application of techniques from computational complexity theory. in this poster, we describe the first formal assessment of the computational adequacy of newell and simon's general problem solver model.we also discuss how our results can be used in both designing newpsychological experiments and refining models of human problem solving.
in experience-based choice, outcomes of choice options are learned from experience. in laboratory paradigms simulating experience-based choice, participants learn about options via repeated sampling. past research has revealed individual differences in sampling strategies (comprehensive vs. piecewise sampling). in the current study, we experimentally manipulated strategies to examine their effect on sampling effort and decision quality. participants were presented with two virtual bags of numbered marbles and were asked to a) choose the bag containing the greater proportion of marbles with a specific target number (requiring tracking of proportions), or b) choose the bag containing marbles with the higher average number (requiring tracking of proportions and values). sampling strategy (comprehensive vs. piecewise) was manipulated within-subjects. piecewise sampling led to greater accuracy than comprehensive sampling in both tasks, despite lower sampling effort. these findings confirm the importance of strategies in experience-based choice and have implications for the design of effective decision aids.
certain previous researches attempted to characterize how association memory works. the word meanings derived from lsa (latent semantic analysis) are usually showed highly related to the performance of forward association memory. a naïve postulation would assume that the mechanisms for that relationship are mainly due to the processes of semantic similarity. the present work not only validates that the lsa calculation outcome is related to the norm of association memory for both english and chinese, but also proposes that association memory could be constructed by considering the similar co-occurrences across situations for words from the perspective of lsa. the work further analyzes the constructed association bipartite nets and the results showed that the counts of afferent associations are proportional to the strength of association memory. it can be concluded that the words associated with many other words would have higher probability to have higher lsa values. finally, we suggest a possible mechanism of how association memory is formed and depicts how words emerging in many other situations would be more probable to be associated with other words, which can be predicted by lsa.
infants receive constant pairing of acoustic and visual stimuli across various contexts during their daily lives. in face of changing environmental experiences, disparate behavioral performance of infants mainly is not task-driven but mechanism-driven. however, the factual manner of how information is processed to develop cross-situational word learning is yet unclear. in the present study, som networks were firstly fed with the input of looking time for the learning phase and then the competitive layer of the som networks gradually formed recognizable clusters for the associations of acoustic and visual information. the study results showed that the simulations of som networks fit infants’ behavioral patterns observed in the experiments and the structures of the presentation are computationally presented. the well-modeled outcome to the behavioral data offers a possible mechanism for interpreting how infants build up their early cross-situational word meanings.
a notion of free will requires an understanding that an agent who performed a particular action could have acted otherwise. little is known about how young children reason about free will, and if this reasoning is affected by the surrounding cultural context.  in this study, u.s. and chinese 4- and 6-year-olds were asked if people could choose to inhibit or act against their desires.  u.s. children attributed more choice to people than chinese children for the inhibition question type but not the action question type.  there was a significant age by ethnicity interaction, with ethnicity differences significant at age 6, but not at age 4.  children from both cultures did attribute more choice to other people than they did to themselves.  these results suggest that folk intuitions of free will undergo change in early childhood and that this change is, at least in part, influenced by culturally variable factors.    
computational-level theories of cognition often postulate functions that are computationally intractable (e.g., np-hard or worse). this seems to render such theories computationally and cognitively implausible. one account of how humans may nevertheless compute intractable functions is that they exploit parameters of the input of these functions to compute the functions efficiently under conditions where those parameters are small. previous work has established the existence of such algorithms for various cognitive functions. however, whether or not these algorithms can evolve in a cognitively plausible manner remains an open question. in this poster, we describe the first formal investigation of this question relative to the constraint satisfaction model of coherence. in our investigation, we evolved neural networks for computing coherence under this model. our simulation results show that such evolved networks indeed exploit parameters in the same way as known tractable algorithms for this model.
causal illusions are situations in which a causal relationship is inferred even though a physical mechanism is not possible. we offer an explanation of such illusions in terms of a two-process account of causal understanding. according to this view, judgments of causation involve two processes: an initial fast process involving the sensation of force that gives rise to the impression of causation, and a second, more strategic process that determines whether there exists a mechanism for the transmission of force. this account was tested in two lines of research in which participants were shown near-photorealistic animations of possible and impossible causal events. experiment 1 showed that people attribute causation in the absence of legitimate mechanisms. experiment 2 showed that impressions of causation, even those without possible mechanisms, are associated with the sensation of force, as measured by people’s sensitivity to physical forces imparted on their hand.
most of the theoretical debate concerning the processes involved in inflectional morphology has been based on data acquired using a task that involves presentation of the stem. it is not universally accepted, however, that this kind of task accurately approximates more naturalistic speech production. indeed, work with adults reveals quite different results when inflection proceeds instead from meaning. the extent to which such task differences also occur during inflectional development has not been explored. here we consider for the first time the impact of task type upon inflectional development in a group of 900 children aged between 2;6-5;5. across all ages, the robust regularity effect observed in the standard “wug”-task was reduced when children were required to produce the past tense from an action video. connectionist models have captured a similar pattern of task differences in adults, and the children’s data provide a target for simulations of inflectional development. 
a key goal for participants in language communication is to bring about a mutually shared experience of ideas, event narratives, and emotional responses. this goal is achieved not only through the exchange of lexical meaning, but also through interactive signaling to coordinate information status, expressed in both verbal and nonverbal forms. this study presents our results on prosodic interactive alignment in spoken dialogues, drawing from extended conversational data in english and chinese. our results show that global prosodic synchrony (alignment)and dissynchrony both occur in conversation, and that synchrony is achieved gradually as participants interactively cooperate to build up a shared information and involvement state. detailed analysis of our data further indicates that participant feedback responses are a critical component of cooperative adaptation to new information, and that the complementary distribution of feedback responses helps to bring about the synchronous prosodic patterns associated with convergent speaker states.
learning a new l2/l3 will undoubtedly be affected by the l1/l2 knowledge of the language learners. the present study examined the lexical interplay among l1, l2 and l3. two different types of l3 (german and japanese) were used to evaluate how the bilingual learners’ knowledge of l1 (chinese) and l2 (english) would impact on the learning of l3 in terms of their different types of lexical relationship (syntactic similarity vs. graphemic similarity). two groups of chinese-english bilingual participants (one is german l3 group and the other one is japanese l3 group) were recruited to participate in a translation task. results (translation time and accuracy of translation) partially support that the effects of graphemic similarity of languages are larger than the effects of syntactic similarity in learning a new l3.
a linear representation of number predicts children’s arithmetic abilities and mathematical achievement scores (booth and siegler, 2008), and this connection is mediated by children’s spatial skills (gunderson et al. 2012). to evaluate the relation of early spatial and numerical skills to mathematical abilities we administered a battery of mathematical and spatial tasks to kindergarten and 3rd graders. we found that a significant amount of variance in math ability is predicted by knowledge of place value and calculation ability as well as the ability to estimate magnitudes along a number line and to mentally rotate symbols, even controlling for verbal ability. we also show that number line linearity is predicted by children’s knowledge of digits and how to order numbers left to right. this work has important implications for developing children’s early spatial transformation abilities and providing children with a linear representation of magnitude.
the discussion of whether the role information encoded by verbs is anticipatorily used in sentence comprehension apart from the world knowledge in the context has been a while. however, in head-initial languages like english, it is difficult to tell apart the use of lexical information like verbs from that of world knowledge information because roles associated with role fillers are mostly encoded by verbs. contrarily, head-final languages like korean provide chances to distinguish the use of lexical information triggering the prediction of roles (role predictability) from that of world knowledge triggering the prediction of role fillers (role filler predictability). using korean dative sentences, we examined the relationship between role predictability and role filler predictability in sentence processing. the results of our erp study revealed that the effect of role filler predictability was observed as n400 effect when roles were strongly expected,  whereas that of role filler predictability was observed as p600 effect when roles were weakly expected. 
research on the cognitive consequences of bilingualism suggests a bilingual advantage: early experience with more than one language predicts better inhibitory control of attention. the mechanisms responsible for this advantage, however, are not well understood. we ask whether depth and time-course of memory encoding may be responsible. we measured bilingual and monolingual adults’ memory for non-linguistic stimuli processed during three tasks. the first paradigm, modeled after richter and yeung (2013), assessed participants’ memories of stimuli processed during an attentional control task, providing a measure of attentional selection abilities. the second paradigm primed participants’ recognition of faces at different durations, yielding a temporal measure of memory representations and their effect on stimuli recognition. the third, a false memory paradigm modeled after koutstaal and schacter(1997), measured spreading activation across the semantic networks of monolinguals and bilinguals. results from all three paradigms provide insight into the mechanisms that underlie the bilingual advantage.
 logical metonymies (begin the book → reading) involve the understanding of covert events. lexicalist approaches claim that the metonymy arises from a type clash (event-selecting verb + entity-denoting object), and place (limited) covert event information in the noun’s lexical entry. recent work suggests that people exploit generalized knowledge about typical events and their participants (quantifiable as thematic fit) to generate expectations about upcoming input. covert events should then be events with the best fit with the whole sentence context (not limited to what is assumed by lexicalist approaches). we present a probe recognition experiment showing effects of thematic fit on logical metonymies (the baker began the icing → spread / eat) and a self-paced reading experiment crossing type and thematic fit (the child began with the toy[entity] / scuffle[event] / medicine[entity] / therapy[event]). our results indicate that both type and thematic fit play a role in logical metonymy interpretation.
we investigate the compositional properties of metonymy through self-paced reading (spr) and erp.  we examine lexical metonymy (novel producer-for-product: all freshmen read/meet wickstrom) and circumstantial/pragmatic metonymy (a waitress says to another: “table-13/that couple asked for more wine”).  we test the hypothesis that both metonymic types are instantiated by the same interpretive mechanism, a referential dependency between the named and intended entities similar to a pronoun-antecedent relation (e.g., jackendoff, 1997), and that their real-time implementation is modulated by degree of contextualization (circumstantial &gt;&gt; lexical).  whereas spr results show cost of implementation only for the circumstantial metonymy contrast and only at the segment directly following the metonymy trigger, erp results show identical latency and polarity properties for both metonymies (p500) in left anterior electrodes exclusively.  these results support metonymy as a unified, computationally isolable reference transfer process whose composition exerts visible cost which increases as demands for contextualization increase. 
people can adopt someone else’s spatial perspective and judge whether an object is on the person’s left or right. such level-2 perspective taking has been considered effortful, but our studies find evidence for automatic perspective taking and reveal some conditions of this automaticity.participants watched videos showing four objects on a square table and an agent sitting somewhere around the table. agents were either (1) merely present, (2) gazed at, or (3) reached for a random object. encouraged to ignore the agent, participants made speeded judgments of whether an object was on their own left/right. on congruent trials the correct answer was the same for self and other; on incongruent trials it was opposite. self-perspective judgments were slower and more erroneous on incongruent trials, indicating an other-to-self interference and thus automatic perspective taking—but most strongly for the reach condition, partially for the gaze condition, and not for the mere-presence condition.
